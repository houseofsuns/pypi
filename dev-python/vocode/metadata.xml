<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;div align=&quot;center&quot;&gt;![Hero](https://user-images.githubusercontent.com/6234599/228337850-e32bb01d-3701-47ef-a433-3221c9e0e56e.png)[![Twitter](https://img.shields.io/twitter/url/https/twitter.com/vocodehq.svg?style=social&amp;label=Follow%20%40vocodehq)](https://twitter.com/vocodehq) [![GitHub Repo stars](https://img.shields.io/github/stars/vocodedev/vocode-python?style=social)](https://github.com/vocodedev/vocode-python)[![Downloads](https://static.pepy.tech/badge/vocode/month)](https://pepy.tech/project/vocode)[Community](https://discord.gg/NaU4mMgcnC) | [Docs](https://docs.vocode.dev) | [Dashboard](https://app.vocode.dev)&lt;/div&gt;# &lt;span&gt;&lt;img style='vertical-align:middle; display:inline;' src=&quot;https://user-images.githubusercontent.com/6234599/228339858-95a0873a-2d40-4542-963a-6358d19086f5.svg&quot;  width=&quot;5%&quot; height=&quot;5%&quot;&gt;&amp;nbsp; vocode&lt;/span&gt;### **Build voice-based LLM apps in minutes**Vocode is an open source library that makes it easy to build voice-based LLM apps. Using Vocode, you can build real-time streaming conversations with LLMs and deploy them to phone calls, Zoom meetings, and more. You can also build personal assistants or apps like voice-based chess. Vocode provides easy abstractions and integrations so that everything you need is in a single library.We're actively looking for community maintainers, so please reach out if interested!# ‚≠êÔ∏è Features- üó£ [Spin up a conversation with your system audio](https://docs.vocode.dev/python-quickstart)- ‚û°Ô∏è üìû [Set up a phone number that responds with a LLM-based agent](https://docs.vocode.dev/telephony#inbound-calls)- üìû ‚û°Ô∏è [Send out phone calls from your phone number managed by an LLM-based agent](https://docs.vocode.dev/telephony#outbound-calls)- üßëüíª [Dial into a Zoom call](https://github.com/vocodedev/vocode-python/blob/main/vocode/streaming/telephony/hosted/zoom_dial_in.py)- ü§ñ [Use an outbound call to a real phone number in a Langchain agent](https://docs.vocode.dev/langchain-agent)- Out of the box integrations with:  - Transcription services, including:    - [Deepgram](https://deepgram.com/)    - [AssemblyAI](https://www.assemblyai.com/)    - [Google Cloud](https://cloud.google.com/speech-to-text)    - [Whisper.cpp](https://github.com/ggerganov/whisper.cpp)    - [Microsoft Azure](https://azure.microsoft.com/en-us/products/cognitive-services/speech-to-text)    - [Whisper](https://openai.com/blog/introducing-chatgpt-and-whisper-apis)    - [RevAI](https://www.rev.ai/)  - LLMs, including:    - [ChatGPT](https://openai.com/blog/chatgpt)    - [GPT-4](https://platform.openai.com/docs/models/gpt-4)    - [Anthropic](https://www.anthropic.com/)    - [GPT4All](https://github.com/nomic-ai/gpt4all)  - Synthesis services, including:    - [Rime.ai](https://rime.ai)    - [Microsoft Azure](https://azure.microsoft.com/en-us/products/cognitive-services/text-to-speech/)    - [Google Cloud](https://cloud.google.com/text-to-speech)    - [Play.ht](https://play.ht)    - [Eleven Labs](https://elevenlabs.io/)    - [Coqui](https://coqui.ai/)    - [Coqui (OSS)](https://github.com/coqui-ai/TTS)    - [gTTS](https://gtts.readthedocs.io/)    - [StreamElements](https://streamelements.com/)    - [Bark](https://github.com/suno-ai/bark)Check out our React SDK [here](https://github.com/vocodedev/vocode-react-sdk)!# ü´Ç Contribution and RoadmapWe're an open source project and are extremely open to contributors adding new features, integrations, and documentation! Please don't hesitate to reach out and get started building with us.For more information on contributing, see our [Contribution Guide](https://github.com/vocodedev/vocode-python/blob/main/contributing.md).And check out our [Roadmap](https://github.com/vocodedev/vocode-python/blob/main/roadmap.md).We'd love to talk to you on [Discord](https://discord.gg/NaU4mMgcnC) about new ideas and contributing!# üöÄ Quickstart (Self-hosted)```bashpip install 'vocode'``````pythonimport asyncioimport loggingimport signalfrom vocode.streaming.streaming_conversation import StreamingConversationfrom vocode.helpers import create_streaming_microphone_input_and_speaker_outputfrom vocode.streaming.transcriber import *from vocode.streaming.agent import *from vocode.streaming.synthesizer import *from vocode.streaming.models.transcriber import *from vocode.streaming.models.agent import *from vocode.streaming.models.synthesizer import *from vocode.streaming.models.message import BaseMessageimport vocode# these can also be set as environment variablesvocode.setenv(    OPENAI_API_KEY=&quot;&lt;your OpenAI key&gt;&quot;,    DEEPGRAM_API_KEY=&quot;&lt;your Deepgram key&gt;&quot;,    AZURE_SPEECH_KEY=&quot;&lt;your Azure key&gt;&quot;,    AZURE_SPEECH_REGION=&quot;&lt;your Azure region&gt;&quot;,)logging.basicConfig()logger = logging.getLogger(__name__)logger.setLevel(logging.DEBUG)async def main():    (        microphone_input,        speaker_output,    ) = create_streaming_microphone_input_and_speaker_output(        use_default_devices=False,        logger=logger,    )    conversation = StreamingConversation(        output_device=speaker_output,        transcriber=DeepgramTranscriber(            DeepgramTranscriberConfig.from_input_device(                microphone_input,                endpointing_config=PunctuationEndpointingConfig(),            )        ),        agent=ChatGPTAgent(            ChatGPTAgentConfig(                initial_message=BaseMessage(text=&quot;What up&quot;),                prompt_preamble=&quot;&quot;&quot;The AI is having a pleasant conversation about life&quot;&quot;&quot;,            )        ),        synthesizer=AzureSynthesizer(            AzureSynthesizerConfig.from_output_device(speaker_output)        ),        logger=logger,    )    await conversation.start()    print(&quot;Conversation started, press Ctrl+C to end&quot;)    signal.signal(        signal.SIGINT, lambda _0, _1: asyncio.create_task(conversation.terminate())    )    while conversation.is_active():        chunk = await microphone_input.get_audio()        conversation.receive_audio(chunk)if __name__ == &quot;__main__&quot;:    asyncio.run(main())```# üìû Phone call quickstarts- [Telephony Server - Self-hosted](https://docs.vocode.dev/telephony)- [Inbound calls - Hosted](https://docs.vocode.dev/telephony#inbound-calls)- [Outbound calls - Hosted](https://docs.vocode.dev/telephony#outbound-calls)# üå± Documentation[docs.vocode.dev](https://docs.vocode.dev/)</longdescription>
</pkgmetadata>