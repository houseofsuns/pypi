<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;h4 align=&quot;center&quot;&gt;  &lt;a href=&quot;https://uptrain.ai&quot;&gt;    &lt;img width=&quot;300&quot; src=&quot;https://user-images.githubusercontent.com/108270398/214240695-4f958b76-c993-4ddd-8de6-8668f4d0da84.png&quot; alt=&quot;uptrain&quot;&gt;  &lt;/a&gt;&lt;/h4&gt;&lt;h2&gt;  &lt;p align=&quot;center&quot;&gt;    &lt;p align=&quot;center&quot;&gt;An open-source framework to evaluate and monitor LLM applications&lt;/p&gt;  &lt;/p&gt;&lt;/h2&gt;&lt;p align=&quot;center&quot;&gt;&lt;!-- -&lt;a href=&quot;https://colab.research.google.com/drive/1ZIITMB7XYotvhg5CNvGPFnBdM4SR2w4Q?usp=sharing/&quot; rel=&quot;nofollow&quot;&gt;&lt;strong&gt;Try it out&lt;/strong&gt;&lt;/a&gt; --&gt;&lt;a href=&quot;https://demo.uptrain.ai/evals_demo/&quot; rel=&quot;nofollow&quot;&gt;&lt;strong&gt;Try out Evaluations&lt;/strong&gt;&lt;/a&gt;-&lt;!-- &lt;a href=&quot;https://docs.uptrain.ai/docs/&quot; rel=&quot;nofollow&quot;&gt;&lt;strong&gt;Docs&lt;/strong&gt;&lt;/a&gt;- --&gt;&lt;a href=&quot;https://uptrain.ai/~demo/&quot; rel=&quot;nofollow&quot;&gt;&lt;strong&gt;UpTrain in Action&lt;/strong&gt;&lt;/a&gt;-&lt;a href=&quot;https://join.slack.com/t/uptraincommunity/shared_invite/zt-1yih3aojn-CEoR_gAh6PDSknhFmuaJeg&quot; rel=&quot;nofollow&quot;&gt;&lt;strong&gt;Slack Community&lt;/strong&gt;&lt;/a&gt;-&lt;!-- &lt;a href=&quot;https://github.com/uptrain-ai/uptrain/issues/new?assignees=&amp;labels=bug&amp;template=bug_report.md&amp;title=&quot; rel=&quot;nofollow&quot;&gt;&lt;strong&gt;Bug Report&lt;/strong&gt;&lt;/a&gt;- --&gt;&lt;a href=&quot;https://github.com/uptrain-ai/uptrain/issues/new?assignees=&amp;labels=enhancement&amp;template=feature_request.md&amp;title=&quot; rel=&quot;nofollow&quot;&gt;&lt;strong&gt;Feature Request&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&lt;h4 align=&quot;center&quot;&gt;  &lt;a href=&quot;https://github.com/uptrain-ai/uptrain/graphs/contributors&quot;&gt;    &lt;img src=&quot;https://img.shields.io/badge/Prebuilt-Evaluations-violet.svg?style=shields&quot;&gt;  &lt;/a&gt;  &lt;a href=&quot;https://github.com/uptrain-ai/uptrain/graphs/contributors&quot;&gt;    &lt;img src=&quot;https://img.shields.io/badge/UpTrain-Demo-indigo.svg?style=shields&quot;&gt;  &lt;/a&gt;  &lt;a href='https://github.com/uptrain-ai/uptrain/blob/main/CONTRIBUTING.md'&gt;    &lt;img alt='PRs Welcome' src='https://img.shields.io/badge/PRs-welcome-blue.svg?style=shields'/&gt;  &lt;/a&gt;  &lt;a href=&quot;https://github.com/uptrain-ai/uptrain/graphs/contributors&quot;&gt;    &lt;img src=&quot;https://img.shields.io/github/contributors/uptrain-ai/uptrain&quot;&gt;  &lt;/a&gt;  &lt;a href=&quot;https://docs.uptrain.ai/docs/&quot;&gt;    &lt;img src=&quot;https://img.shields.io/badge/Read-Docs-yellow&quot; alt=&quot;Docs&quot; /&gt;  &lt;/a&gt;  &lt;a href=&quot;https://join.slack.com/t/uptraincommunity/shared_invite/zt-1yih3aojn-CEoR_gAh6PDSknhFmuaJeg&quot;&gt;    &lt;img src=&quot;https://img.shields.io/badge/Slack-Community-orange&quot; alt=&quot;Community&quot; /&gt;  &lt;/a&gt;  &lt;a href=&quot;https://uptrain.ai/&quot;&gt;    &lt;img src=&quot;https://img.shields.io/badge/UpTrain-Website-red&quot; alt=&quot;Website&quot; /&gt;  &lt;/a&gt;  &lt;!-- &lt;a href=&quot;https://colab.research.google.com/drive/1ZIITMB7XYotvhg5CNvGPFnBdM4SR2w4Q?usp=sharing/&quot;&gt;    &lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg&quot; alt=&quot;Open In Colab&quot;/&gt;  &lt;/a&gt; --&gt;&lt;/h4&gt;&lt;!-- https://user-images.githubusercontent.com/43818888/229681912-a1d9733d-0c41-4be1-83cf-408d5271518e.mp4 --&gt;&lt;!-- **Read this in other languages**: &lt;kbd&gt;[&lt;img title=&quot;English&quot; alt=&quot;English language&quot; src=&quot;https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/us.svg&quot; width=&quot;22&quot;&gt;](/README.md)&lt;/kbd&gt;&lt;kbd&gt;[&lt;img title=&quot;German&quot; alt=&quot;German language&quot; src=&quot;https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/de.svg&quot; width=&quot;22&quot;&gt;](/i18n/README.de.md)&lt;/kbd&gt;&lt;kbd&gt;[&lt;img title=&quot;Chinese&quot; alt=&quot;Chinese language&quot; src=&quot;https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/cn.svg&quot; width=&quot;22&quot;&gt;](/i18n/README.zh-CN.md)&lt;/kbd&gt;&lt;kbd&gt;[&lt;img title=&quot;Hindi&quot; alt=&quot;Hindi language&quot; src=&quot;https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/in.svg&quot; width=&quot;22&quot;&gt;](/i18n/README.hi.md)&lt;/kbd&gt;&lt;kbd&gt;[&lt;img title=&quot;Spanish&quot; alt=&quot;Spanish language&quot; src=&quot;https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/es.svg&quot; width=&quot;22&quot;&gt;](/i18n/README.es.md)&lt;/kbd&gt;&lt;kbd&gt;[&lt;img title=&quot;French&quot; alt=&quot;French language&quot; src=&quot;https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/fr.svg&quot; width=&quot;22&quot;&gt;](/i18n/README.fr.md)&lt;/kbd&gt;&lt;kbd&gt;[&lt;img title=&quot;Japanese&quot; alt=&quot;Japanese language&quot; src=&quot;https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/jp.svg&quot; width=&quot;22&quot;&gt;](/i18n/README.ja.md)&lt;/kbd&gt;&lt;kbd&gt;[&lt;img title=&quot;Russian&quot; alt=&quot;Russian language&quot; src=&quot;https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/ru.svg&quot; width=&quot;22&quot;&gt;](/i18n/README.ru.md)&lt;/kbd&gt; --&gt;**[UpTrain](https://uptrain.ai)** is a Python framework that ensures your LLM applications are performing reliably by allowing users to check aspects such as correctness, structural integrity, bias, hallucination, etc. UpTrain can be used to:## ExperimentationUpTrain framework can be used to experiment across multiple prompts, model providers, chain configurations, etc. and get quantitative scores to compare them. Check out the [experimentation tutorial](https://github.com/uptrain-ai/uptrain/blob/main/examples/prompt_experiments_tutorial.ipynb) to learn more.&lt;img width=&quot;500&quot; src=&quot;https://github.com/uptrain-ai/uptrain/assets/108270398/12c93f96-fe2a-45d0-8394-4faf1b64af0c&quot; alt=&quot;uptrain experimentation&quot;&gt;## ValidationYou can use the UpTrain Validation Manager to define checks, retry logic and validate your LLM responses before showing it to your users. Check out the [tutorial here](https://github.com/uptrain-ai/uptrain/blob/main/examples/validation_tutorial.ipynb).&lt;img width=&quot;500&quot; src=&quot;https://github.com/uptrain-ai/uptrain/assets/108270398/09bcdd2b-28cc-4b39-9cf8-78df47a3b297&quot; alt=&quot;uptrain validation&quot;&gt;## MonitoringYou can use the UpTrain framework to continuously monitor your model's performance and get real-time insights on how well it is doing on a variety of evaluation metrics. Check out the monitoring tutorial to learn more.&lt;img width=&quot;500&quot; src=&quot;https://github.com/uptrain-ai/uptrain/assets/108270398/0ede5648-d1c3-44ff-af65-a1b688792888&quot; alt=&quot;uptrain monitoring&quot;&gt;# Get started üôå&lt;!-- You can quickly get started with [Google Colab here](https://colab.research.google.com/drive/1ZIITMB7XYotvhg5CNvGPFnBdM4SR2w4Q?usp=sharing%2F). --&gt;To run it on your machine, checkout the [Quickstart tutorial](https://docs.uptrain.ai/getting-started/quickstart):### Install the package through pip:```bashpip install uptrain```Note: Uptrain uses commonly used python libraries like openai-evals and sentence-transformers. To make sure, all the functionalities work, use the `uptrain-add` command to install the full version of the package.```bashuptrain-add --feature full```### How to use UpTrain:#### Using UpTrain's builtin evaluation sets:UpTrain provides a variety of checks like response relevance, response completeness, factual accuracy, retrieved-context quality, etc. which can be accessed using UpTrain's API key. [Learn more](https://demo.uptrain.ai/evals_demo/) about these evaluations.Get your free UpTrain API Key [here](https://demo.uptrain.ai/api/login/).```pythondata = pl.DataFrame({  &quot;question&quot;: [&quot;What is the meaning of life?&quot;],  &quot;response&quot;: [&quot;Who knows ü§î&quot;]})check = CheckResponseCompleteness()output = check.setup(Settings(uptrain_access_token=&quot;up-9g....&quot;)).run(data)```#### Configuring your own evaluation sets:Say we want to plot a line chart showing whether our model's responses contain any grammatical mistakes or not.```python# Step 1: Choose and create the appropriate operator from UpTraingrammar_score = GrammarScore(  col_in_text = &quot;model_response&quot;,       # input column name (from dataset)  col_out = &quot;grammar_score&quot;             # desired output column name)# Step 2: Create a check with the operators and the required plots as arguments grammar_check = Check(  operators = [grammar_score],  plots = LineChart(y = &quot;grammar_score&quot;))# Step 3: Create a CheckSet with the checks and data source as argumentscheckset = CheckSet(    checks = [grammar_check]    source = JsonReader(fpath = '...'))# Step 4: Set up and run the CheckSetcheckset.setup(Settings(openai_api_key = '...'))checkset.run(dataset)```&lt;!-- For a quick walkthrough of how UpTrain works, check out our [quickstart tutorial](https://docs.uptrain.ai/docs/uptrain-examples/quickstart-tutorial). --&gt;&lt;h4&gt; &lt;/h4&gt;# Key Features üí°- **[ChatGPT Grading](https://uptrain-ai.github.io/uptrain/operators/language/OpenAIGradeScore/)** - Utilize LLMs to grade your model outputs.- **[Custom Grading Checks](https://uptrain-ai.github.io/uptrain/operators/language/ModelGradeScore/)** - Write your custom grading prompts.- **[Embeddings Similarity Check](https://uptrain-ai.github.io/uptrain/operators/CosineSimilarity/)** - Compute cosine similarity between prompt and response embeddings- **[Output Validation](https://github.com/uptrain-ai/uptrain/blob/main/examples/validation_tutorial.ipynb)** - Safeguard your users against inappropriate responses- **[Prompt A/B Testing](https://github.com/uptrain-ai/uptrain/blob/main/examples/prompt_experiments_tutorial.ipynb)** - Experiment across multiple prompts and compare them quantatively.- **[UMAP Visualization and Clustering](https://uptrain-ai.github.io/uptrain/operators/UMAP/)** - Visualize your embedding space using tools like UMAP and t-SNE.- **[Hallucination Checks]()** - Use metrics like custom grading, text similarity, and embedding similarity to check for hallucinations.- **[Toxic Keywords Checks]()** - Make sure your model outputs are not biased or contain toxic keywords.- **[Feature Slicing]()** - Built-in pivoting functionalities for data dice and slice to pinpoint low-performing cohorts.- **[Realtime Dashboards]()** - Monitor your model's performance in realtime.# Integrations| Eval Frameworks  | LLM Providers | LLM Packages | Serving frameworks | | ------------- | ------------- | ------------- | ------------- | | OpenAI Evals ‚úÖ | GPT-3.5-turbo ‚úÖ | Langchain üîú | HuggingFace üîú || EleutherAI LM Eval üîú | GPT-4 ‚úÖ  | Llama Index üîú |  Replicate üîú || BIG-Bench üîú | Claude üîú | AutoGPT üîú || | Cohere üîú | # Why UpTrain ü§î?Large language models are trained over billions of data points and perform really well over a wide variety of tasks. But one thing these models are not good at is being deterministic. Even with the most well-crafted prompts, the model can misbehave for certain inputs, be it hallucinations, wrong output structure, toxic or biased response, irrelevant response, and error modes can be immense. To ensure your LLM applications work reliably and correctly, UpTrain makes it easy for developers to evaluate the responses of their applications on multiple criteria. UpTrain's evaluation framework can be used to:1) Validate (and correct) the response of the model before showing it to the user2) Get quantitative measures to experiment across multiple prompts, model providers, etc.3) Do unit testing to ensure no buggy prompt or code gets pushed into your production4) Monitor your LLM applications in real time and understand when they are going wrong in order to fix them before users complain.We are constantly working to make UpTrain better. Want a new feature or need any integrations? Feel free to [create an issue](https://github.com/uptrain-ai/uptrain/issues) or [contribute](https://github.com/uptrain-ai/uptrain/blob/main/CONTRIBUTING.md) directly to the repository.# License üíªThis repo is published under Apache 2.0 license. We are also working towards adding a hosted offering to make setting off eval runs easier - please fill **[this form](https://docs.google.com/forms/d/e/1FAIpQLSf9h_SXoU0rJP2MUc4NIKOmOCqJ5J0xgephN1xgeoXscSHUSA/viewform?usp=sf_link)** to get a waitlist slot.# Stay Updated ‚òéÔ∏èWe are continuously adding tons of features and use cases. Please support us by giving the project a star ‚≠ê!# Provide feedback (Harsher the better üòâ) We are building UpTrain in public. Help us improve by giving your feedback **[here](https://docs.google.com/forms/d/e/1FAIpQLSezGUkkC0JoEvx-0gCrRSmGutA-jqyb7kl2lomXv302_C3MnQ/viewform?usp=sf_link)**.# Contributors üñ•Ô∏èWe welcome contributions to UpTrain. Please see our [contribution guide](https://github.com/uptrain-ai/uptrain/blob/main/CONTRIBUTING.md) for details.&lt;a href=&quot;https://github.com/uptrain-ai/uptrain/graphs/contributors&quot;&gt;  &lt;img src=&quot;https://contrib.rocks/image?repo=uptrain-ai/uptrain&quot; /&gt;&lt;/a&gt;</longdescription>
</pkgmetadata>