<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>![image](https://img.shields.io/pypi/v/llm4gpt.svg) ![image](https://img.shields.io/travis/yuanjie-ai/llm4gpt.svg) ![image](https://readthedocs.org/projects/llm4gpt/badge/?version=latest)&lt;h1 align = &quot;center&quot;&gt;ğŸ”¥LLM4GPT ä¸ºå¤§æ¨¡å‹è€Œç”ŸğŸ”¥&lt;/h1&gt;---# Install```pythonpip install -U llm4gpt```# [Docs](https://jie-yuan.github.io/llm4gpt/)# Usages```pythonfrom llm.qa import QAfrom llm.kb import FaissANNfrom llm.chatllm import ChatLLMfrom llm.utils import llm_loadfrom meutils.pipe import *# è§£æçŸ¥è¯†åº“texts = []metadatas = []for p in Path('data').glob('*.txt'):    texts.append(p.read_text())    metadatas.append({'source': p})# æ–‡æ¡£å‘é‡åŒ–faissann = FaissANN(model_name_or_path=&quot;shibing624/text2vec-base-chinese&quot;)faissann.add_texts(texts, metadatas)# æ„å»ºpipelinemodel, tokenizer = llm_load(model_name_or_path=&quot;THUDM/chatglm-6b&quot;, device='cpu')glm = ChatLLM()glm.chat_func = partial(model.chat, tokenizer=tokenizer)qa = QA(glm, faiss_ann=faissann.faiss_ann)qa.get_knowledge_based_answer('å‘¨æ°ä¼¦åœ¨å¹²å—')qa.get_knowledge_based_answer('å§šæ˜ä½å“ªé‡Œ')```---# TODO- [ ] å¢åŠ UI- [x] å¢åŠ æœ¬åœ°çŸ¥è¯†åº“ç»„ä»¶- [ ] å¢åŠ äº’è”ç½‘æœç´¢ç»„ä»¶- [ ] å¢åŠ çŸ¥è¯†å›¾è°±ç»„ä»¶- [ ] å¢åŠ å¾®è°ƒæ¨¡å—- [ ] å¢åŠ æµå¼è¾“å‡º=======History=======0.0.0 (2023-04-11)------------------* First release on PyPI.</longdescription>
</pkgmetadata>