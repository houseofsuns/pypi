<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># Nkululeko* [Overview](#overview)* [Installation](#installation)* [Usage](#usage)* [Hello World](#hello-world-example)* [Licence](#licence)## OverviewA project to detect speaker characteristics by machine learning experiments with a high-level interface.The idea is to have a framework (based on e.g. sklearn and torch) that can be used by people not being experienced programmers as they mainly have to adapt an initialization parameter file per experiment.* The latest features can be seen in [the ini-file](./ini_file.md) options](./ini_file.md) that are used to control Nkululeko* Below is a [Hello World example](#helloworld) that should set you up fastly.* [Here's a blog post on how to set up nkululeko on your computer.](http://blog.syntheticspeech.de/2021/08/30/how-to-set-up-your-first-nkululeko-project/)* [Here's a slide presentation about nkululeko](docs/nkululeko.pdf)* [Here's a video presentation about nkululeko](https://www.youtube.com/playlist?list=PLRceVavtxLg0y2jiLmpnUfiMtfvkK912D)* [Here's the 2022 LREC article on nkululeko](http://felix.syntheticspeech.de/publications/Nkululeko_LREC.pdf)Here are some examples of typical output:### Confusion matrixPer default, Nkululeko displays results as a confusion matrix using binning with regression.&lt;img src=&quot;images/conf_mat.png&quot; width=&quot;500px&quot;/&gt;### Epoch progressionThe point when overfitting starts can sometimes be seen by looking at the results per epoch:&lt;img src=&quot;images/epoch_progression.png&quot; width=&quot;500px&quot;/&gt;### Feature importanceUsing the *explore* interface, Nkululeko analyses the importance of acoustic features: &lt;img src=&quot;images/feat_importance.png&quot; width=&quot;500px&quot;/&gt;### Feature distributionAnd can show the distribution of specific features per category:&lt;img src=&quot;images/feat_dist.png&quot; width=&quot;500px&quot;/&gt;### t-SNE plotsA t-SNE plot can give you an estimate wether your acoustic features are useful at all:&lt;img src=&quot;images/tsne.png&quot; width=&quot;500px&quot;/&gt;### Data distributionSometimes you only want to take a look at your data:&lt;img src=&quot;images/data_plot.png&quot; width=&quot;500px&quot;/&gt;## InstallationCreate and activate a virtual Python environment and simply run```pip install nkululeko```Some examples for *ini*-files (which you use to control nkululeko) are in the [tests folder](https://github.com/felixbur/nkululeko/tree/main/tests).## UsageBasically, you specify your experiment in an &quot;ini&quot; file (e.g. *experiment.ini*) and then call one of the Nkululeko interfaces to run the experiment like this:  * ```python -m nkululeko.nkululeko --config experiment.ini```A basic configuration looks like this:```[EXP]root = ./name = exp_emodb[DATA]databases = ['emodb']emodb = ./emodb/emodb.split_strategy = speaker_splittarget = emotionlabels = ['anger', 'boredom', 'disgust', 'fear'][FEATS]type = ['praat'][MODEL]type = svm[EXPL]model = treeplot_tree = True[PLOT]combine_per_speaker = mode```Read the [Hello World example](#hello-world-example) for initial usage with Emo-DB dataset.Here is an overview of the interfaces:* **nkululeko.nkululeko**: doing experiments* **nkululeko.demo**: demo the current best model on command line* **nkululeko.test**: predict a series of files with the current best model* **nkululeko.explore**: perform data exploration* **nkululeko.augment**: augment the current training dataAlternatively, there is a central &quot;experiment&quot; class that can be used by own experimentsThere's my [blog](http://blog.syntheticspeech.de/?s=nkululeko) with tutorials:* [Introduction](http://blog.syntheticspeech.de/2021/08/04/machine-learning-experiment-framework/)* [Nkulueko FAQ](http://blog.syntheticspeech.de/2022/07/07/nkululeko-faq/)* [How to set up your first nkululeko project](http://blog.syntheticspeech.de/2021/08/30/how-to-set-up-your-first-nkululeko-project/)* [Setting up a base nkululeko experiment](http://blog.syntheticspeech.de/2021/10/05/setting-up-a-base-nkululeko-experiment/)* [How to import a database](http://blog.syntheticspeech.de/2022/01/27/nkululeko-how-to-import-a-database/) * [Comparing classifiers and features](http://blog.syntheticspeech.de/2021/10/05/nkululeko-comparing-classifiers-and-features/)* [Use Praat features](http://blog.syntheticspeech.de/2022/06/27/how-to-use-selected-features-from-praat-with-nkululeko/)* [Combine feature sets](http://blog.syntheticspeech.de/2022/06/30/how-to-combine-feature-sets-with-nkululeko/)* [Classifying continuous variables](http://blog.syntheticspeech.de/2022/01/26/nkululeko-classifying-continuous-variables/) * [Try out / demo a trained model](http://blog.syntheticspeech.de/2022/01/24/nkululeko-try-out-demo-a-trained-model/) * [Perform cross database experiments](http://blog.syntheticspeech.de/2021/10/05/nkululeko-perform-cross-database-experiments/)* [Meta parameter optimization](http://blog.syntheticspeech.de/2021/09/03/perform-optimization-with-nkululeko/)* [How to set up wav2vec embedding](http://blog.syntheticspeech.de/2021/12/03/how-to-set-up-wav2vec-embedding-for-nkululeko/)* [How to soft-label a database](http://blog.syntheticspeech.de/2022/01/24/how-to-soft-label-a-database-with-nkululeko/) * [Re-generate the progressing confusion matrix animation wit a different framerate](demos/plot_faster_anim.py)* [How to limit/filter a dataset](http://blog.syntheticspeech.de/2022/02/22/how-to-limit-a-dataset-with-nkululeko/)* [Specifying database disk location](http://blog.syntheticspeech.de/2022/02/21/specifying-database-disk-location-with-nkululeko/) * [Add dropout with MLP models](http://blog.syntheticspeech.de/2022/02/25/adding-dropout-to-mlp-models-with-nkululeko/)* [Do cross-validation](http://blog.syntheticspeech.de/2022/03/23/how-to-do-cross-validation-with-nkululeko/)* [Combine predictions per speaker](http://blog.syntheticspeech.de/2022/03/24/how-to-combine-predictions-per-speaker-with-nkululeko/)* [Run multiple experiments in one go](http://blog.syntheticspeech.de/2022/03/28/how-to-run-multiple-experiments-in-one-go-with-nkululeko/)* [Compare several MLP layer layouts with each other](http://blog.syntheticspeech.de/2022/04/11/how-to-compare-several-mlp-layer-layouts-with-each-other/)* [Import features from outside the software](http://blog.syntheticspeech.de/2022/10/18/how-to-import-features-from-outside-the-nkululeko-software/)* [Explore feature importance](http://blog.syntheticspeech.de/2023/02/20/nkululeko-show-feature-importance/)* [Plot distributions for feature values](http://blog.syntheticspeech.de/2023/02/16/nkululeko-how-to-plot-distributions-of-feature-values/)* [Show feature importance](http://blog.syntheticspeech.de/2023/02/20/nkululeko-show-feature-importance/)* [Augment the training set](http://blog.syntheticspeech.de/2023/03/13/nkululeko-how-to-augment-the-training-set/) * [Visualize clusters of acoustic features](http://blog.syntheticspeech.de/2023/04/20/nkululeko-visualize-clusters-of-your-acoustic-features/) * [Visualize your data distribution](http://blog.syntheticspeech.de/2023/05/11/nkululeko-how-to-visualize-your-data-distribution/)The framework is targeted at the speech domain and supports experiments where different classifiers are combined with different feature extractors.Here's a rough UML-like sketch of the framework.![sketch](images/class_diagram.png)Currently, the following linear classifiers are implemented (integrated from sklearn):* SVM, SVR, XGB, XGR, Tree, Tree_regressor, KNN, KNN_regressor, NaiveBayes, GMM  and the following ANNs* MLP, CNN (tbd)Here's [an animation that shows the progress of classification done with nkululeko](https://youtu.be/6Y0M382GjvM)### Initialization fileYou could * use a generic main python file (like my_experiment.py), * adapt the path to your nkululeko src * and then adapt an .ini file (again fitting at least the paths to src and data)  Here's [an overview of the ini-file options](./ini_file.md)### &lt;a name=&quot;helloworld&quot;&gt;Hello World example&lt;/a&gt;* NEW: [I made a video to show you how to do this on Windows](https://www.youtube.com/playlist?list=PLRceVavtxLg0y2jiLmpnUfiMtfvkK912D)* Set up Python on your computer, version &gt;= 3.6* Open a terminal/commandline/console window* Test python by typing ```python```, python should start with version &gt;3 (NOT 2!). You can leave the Python Interpreter by typing *exit()** Create a folder on your computer for this example, let's call it `nkulu_work`* Get a copy of the [Berlin emodb in audformat](https://tubcloud.tu-berlin.de/s/LfkysdXJfiobiEG) and unpack the same folder (`nkulu_work`)* Make sure the folder is called &quot;emodb&quot; and does contain the database files directly (not box-in-a-box)* Also, in the `nkulu_work` folder:   * Create a Python environment    * ```python -m venv venv```  * Then, activate it:    * under Linux / mac      * ```source venv/bin/activate```    * under Windows      * ```venv\Scripts\activate.bat```    * if that worked, you should see a ```(venv)``` in front of your prompt  * Install the required packages in your environment    * ```pip install nkululeko```    * Repeat until all error messages vanished (or fix them, or try to ignore them)...* Now you should have two folders in your *nkulu_work* folder:  * *emodb* and *venv** Download a copy of the file [exp_emodb.ini](demos/exp_emodb.ini) to the current working directory (```nkulu_work```)* Run the demo  * ```python -m nkululeko.nkululeko --config exp_emodb.ini```* Find the results in the newly created folder exp_emodb   * Inspect ```exp_emodb/images/run_0/emodb_xgb_os_0_000_cnf.png```  * This is the main result of you experiment: a confusion matrix for the emodb emotional categories* Inspect and play around with the [demo configuration file](demos/exp_emodb.ini) that defined your experiment, then re-run.* There are many ways to experiment with different classifiers and acoustic features sets, [all described here](https://github.com/felixbur/nkululeko/blob/main/ini_file.md)  ### Features* Classifiers: Naive Bayes, KNN, Tree, XGBoost, SVM, MLP* Feature extractors: Praat, Opensmile, openXBOW BoAW, TRILL embeddings, Wav2vec2 embeddings, audModel embeddings, ...* Feature scaling* Label encoding* Binning (continuous to categorical)* Online demo interface for trained models ### Outlook* Classifiers: CNN* Feature extractors: mid-level descriptors, Mel-spectra## LicenseNkululeko can be used under the [MIT license](https://choosealicense.com/licenses/mit/)Changelog=========Version 0.46.0--------------* added warnings for non-existent parameters* added sample selection for scatter plottingVersion 0.45.4--------------* added version attribute to setup.cfgVersion 0.45.4--------------* added __version__ attributeVersion 0.44.1--------------* bugfixing: feature importance: https://github.com/felixbur/nkululeko/issues/23* bugfixing: loading csv database with filewise index https://github.com/felixbur/nkululeko/issues/24 Version 0.45.2--------------* bugfix: sample_selection in EXPL was required wronglyVersion 0.45.2--------------* added sample_selection for sample distribution plotsVersion 0.45.1--------------* fixed dataframe.append bugVersion 0.45.0--------------* added auddim as features* added FEATS store_format* added device use to feat_audmodelVersion 0.44.1--------------* bugfixesVersion 0.44.0--------------* added scatter functions: tsne, pca, umapVersion 0.43.7--------------* added clap featuresVersion 0.43.6--------------* small bugsVersion 0.43.5--------------* because of difficulties with numba and audiomentations importing audiomentations only when augmentingVersion 0.43.4--------------* added error when experiment type and predictor don't matchVersion 0.43.3--------------* fixed further bugs and added augmentation to the test runsVersion 0.43.2--------------* fixed a bug when running continuous variable as classification problemVersion 0.43.1--------------* fixed test_runsVersion 0.43.0--------------* added augmentation module based on audiomentationVersion 0.42.0--------------* age labels should now be detected in databasesVersion 0.41.0--------------* added feature tree plotVersion 0.40.1--------------* fixed a bug: additional test database was not label encodedVersion 0.40.0--------------* added EXPL section and first functionality* added test module (for test databases)Version 0.39.0--------------* added feature distribution plots* added  plot formatVersion 0.38.3--------------* added demo mode with list argumentVersion 0.38.2--------------* fixed a bug concerned with &quot;no_reuse&quot; evaluationVersion 0.38.1--------------* demo mode with file argumentVersion 0.38.0--------------* fixed demo modeVersion 0.37.2--------------* mainly replaced pd.append with pd.concatVersion 0.37.1--------------* fixed bug preventing praat feature extraction to workVersion 0.37.0--------------* fixed bug cvs import not detecting multiindex Version 0.36.3--------------* published as a pypi moduleVersion 0.36.0--------------* added entry nkululeko.py scriptVersion 0.35.0--------------* fixed bug that prevented scaling (normalization)Version 0.34.2--------------* smaller bug fixed concerning the loss_stringVersion 0.34.1--------------* smaller bug fixes and tried Soft_f1 lossVersion 0.34.0--------------* smaller bug fixes and debug ouputsVersion 0.33.0--------------* added GMM as a model typeVersion 0.32.0--------------* added audmodel embeddings as featuresVersion 0.31.0--------------* added models: tree and tree_reg  Version 0.30.0--------------* added models: bayes, knn and knn_regVersion 0.29.2--------------* fixed hello world exampleVersion 0.29.1--------------* bug fix for 0.29Version 0.29.0--------------* added a new FeatureExtractor class to import external dataVersion 0.28.2--------------* removed some Pandas warnings* added no_reuse function to database.load()Version 0.28.1--------------* with database.value_counts show only the data that is actually usedVersion 0.28.0--------------* made &quot;label_data&quot; configuration automatic and added &quot;label_result&quot;Version 0.27.0--------------* added &quot;label_data&quot; configuration to label data with trained model (so now there can be train, dev and test set)Version 0.26.1--------------* Fixed some bugs caused by the multitude of feature sets* Added possibilty to distinguish between absolut or relative pathes in csv datasetsVersion 0.26.0--------------* added the rename_speakers funcionality to prevent identical speaker names in datasetsVersion 0.25.1--------------* fixed bug that no features were chosen if not selectedVersion 0.25.0--------------* made selectable features universal for feature setsVersion 0.24.0--------------* added multiple feature sets (will simply be concatenated)Version 0.23.0--------------* added selectable features for Praat interfaceVersion 0.22.0--------------* added David R. Feinberg's Praat features, praise also to parselmouthVersion 0.21.0--------------* Revoked 0.20.0* Added support for only_test = True, to enable later testing of trained models with new test dataVersion 0.20.0--------------* implemented reuse of trained and saved modelsVersion 0.19.0--------------* added &quot;max_duration_of_sample&quot; for datasetsVersion 0.18.6--------------* added support for learning and dropout rate as argumentVersion 0.18.5--------------* added support for epoch number as argument  Version 0.18.4--------------* added support for ANN layers as argumentsVersion 0.18.3--------------* added reuse of test and train file sets* added parameter to scale continous target values: target_divide_byVersion 0.18.2--------------* added preference of local dataset specs to global ones  Version 0.18.1--------------* added regression value display for confusion matricesVersion 0.18.0--------------* added leave one speaker group outVersion 0.17.2--------------* fixed scaler, added robustVersion 0.17.0--------------* Added minimum duration for test samplesVersion 0.16.4--------------* Added possibility to combine predictions per speaker (with mean or mode function)Version 0.16.3--------------* Added minimal sample length for databasesVersion 0.16.2--------------* Added k-fold-cross-validation for linear classifiersVersion 0.16.1--------------* Added leave-one-speaker-out for linear classifiersVersion 0.16.0--------------* Added random sample splits</longdescription>
</pkgmetadata>