<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># chitra[![CodeFactor](https://www.codefactor.io/repository/github/aniketmaurya/chitra/badge)](https://www.codefactor.io/repository/github/aniketmaurya/chitra)[![Maintainability Rating](https://sonarcloud.io/api/project_badges/measure?project=aniketmaurya_chitra&amp;metric=sqale_rating)](https://sonarcloud.io/dashboard?id=aniketmaurya_chitra)[![Reliability Rating](https://sonarcloud.io/api/project_badges/measure?project=aniketmaurya_chitra&amp;metric=reliability_rating)](https://sonarcloud.io/dashboard?id=aniketmaurya_chitra)[![Security Rating](https://sonarcloud.io/api/project_badges/measure?project=aniketmaurya_chitra&amp;metric=security_rating)](https://sonarcloud.io/dashboard?id=aniketmaurya_chitra)[![Coverage](https://sonarcloud.io/api/project_badges/measure?project=aniketmaurya_chitra&amp;metric=coverage)](https://sonarcloud.io/dashboard?id=aniketmaurya_chitra)![GitHub issues](https://img.shields.io/github/issues/aniketmaurya/chitra?style=flat)[![Documentation Status](https://readthedocs.org/projects/chitra/badge/?version=latest)](https://chitra.readthedocs.io/en/latest/?badge=latest)[![Discord](https://img.shields.io/discord/848469007443165184?style=flat)](https://discord.gg/TdnAfDw3kB)## What is chitra?**chitra** (**‡§ö‡§ø‡§§‡•ç‡§∞**) is a multi-functional library for full-stack Deep Learning. It simplifies Model Building, API development, and Model Deployment.### Components&lt;img src=&quot;https://ik.imagekit.io/aniket/chitra/chitra-arch_Vw9AdA4aC.svg&quot; alt=&quot;arch&quot; style=&quot;width: 80%&quot;&gt;Load Image from Internet url, filepath or `numpy` array and plot Bounding Boxes on the images easily.Model Training and Explainable AI.Easily create UI for Machine Learning models or Rest API backend that can be deployed for serving ML Models in Production.### üìå Highlights:- [New] [Auto Dockerization of Models](https://chitra.readthedocs.io/en/latest/source/cli/builder/builder-create/) üê≥- [New] [Framework Agnostic Model Serving &amp; Interactive UI prototype app](https://chitra.readthedocs.io/en/latest/source/api/serve/model_server/) ‚ú®üåü- [New] [Data Visualization, Bounding Box Visualization](https://chitra.readthedocs.io/en/latest/source/api/image/chitra-class/) üê∂üé®- Model interpretation using GradCAM/GradCAM++ with no extra code üî•- Faster data loading without any boilerplate ü§∫- Progressive resizing of images üé®- Rapid experiments with different models using `chitra.trainer` module üöÄ### üöò Implementation Roadmap- One click deployment to `serverless` platform.&gt; If you have more use case please [**raise an issue/PR**](https://github.com/aniketmaurya/chitra/issues/new/choose) with the feature you want.&gt; If you want to contribute, feel free to raise a PR. It doesn't need to be perfect.&gt; We will help you get there.## üìÄ Installation[![Downloads](https://pepy.tech/badge/chitra)](https://pepy.tech/project/chitra)[![Downloads](https://pepy.tech/badge/chitra/month)](https://pepy.tech/project/chitra)![GitHub License](https://img.shields.io/github/license/aniketmaurya/chitra?style=flat)### Using pip (recommended)1. Minimum installation`pip install -U chitra`1. Full Installation`pip install -U 'chitra[all]'`1. Install for Training`pip install -U 'chitra[nn]'`1. Install for Serving`pip install -U 'chitra[serve]'`### From source```pip install git+https://github.com/aniketmaurya/chitra@master```Or,```git clone https://github.com/aniketmaurya/chitra.gitcd chitrapip install .```## üßëüíª Usage### Loading data for image classificationChitra `dataloader` and `datagenerator` modules for loading data. `dataloader` is a minimal dataloader thatreturns `tf.data.Dataset` object. `datagenerator` provides flexibility to users on how they want to load and manipulatethe data.```pythonimport numpy as npimport chitrafrom chitra.dataloader import Clfimport matplotlib.pyplot as pltclf_dl = Clf()data = clf_dl.from_folder(cat_dog_path, target_shape=(224, 224))clf_dl.show_batch(8, figsize=(8, 8))```![Show Batch](https://raw.githubusercontent.com/aniketmaurya/chitra/master/docs/assets/images/output_3_1.png)## Image datageneratorDataset class provides the flexibility to load image dataset by updating components of the class.Components of Dataset class are:- image file generator- resizer- label generator- image loaderThese components can be updated with custom function by the user according to their dataset structure. For example theTiny Imagenet dataset is organized as-```train_folder/.....folder1/    .....file.txt    .....folder2/           .....image1.jpg           .....image2.jpg                     .                     .                     .           ......imageN.jpg```The inbuilt file generator search for images on the `folder1`, now we can just update the `image file generator` andrest of the functionality will remain same.**Dataset also support progressive resizing of images.**### Updating component```pythonfrom chitra.datagenerator import Datasetds = Dataset(data_path)# it will load the folders and NOT imagesds.filenames[:3]```&lt;details&gt;&lt;summary&gt;Output&lt;/summary&gt;    No item present in the image size list    ['/Users/aniket/Pictures/data/tiny-imagenet-200/train/n02795169/n02795169_boxes.txt',     '/Users/aniket/Pictures/data/tiny-imagenet-200/train/n02795169/images',     '/Users/aniket/Pictures/data/tiny-imagenet-200/train/n02769748/images']&lt;/details&gt;```pythondef load_files(path):    return glob(f'{path}/*/images/*')def get_label(path):    return path.split('/')[-3]ds.update_component('get_filenames', load_files)ds.filenames[:3]```&lt;details&gt;&lt;summary&gt;Output&lt;/summary&gt;    get_filenames updated with &lt;function load_files at 0x7fad6916d0e0&gt;    No item present in the image size list    ['/Users/aniket/Pictures/data/tiny-imagenet-200/train/n02795169/images/n02795169_369.JPEG',     '/Users/aniket/Pictures/data/tiny-imagenet-200/train/n02795169/images/n02795169_386.JPEG',     '/Users/aniket/Pictures/data/tiny-imagenet-200/train/n02795169/images/n02795169_105.JPEG']&lt;/details&gt;### Progressive resizing&gt; It is the technique to sequentially resize all the images while training the CNNs on smaller to bigger image sizes. Progressive Resizing is described briefly in his terrific fastai course, ‚ÄúPractical Deep Learning for Coders‚Äù. A great way to use this technique is to train a model with smaller image size say 64x64, then use the weights of this model to train another model on images of size 128x128 and so on. Each larger-scale model incorporates the previous smaller-scale model layers and weights in its architecture.~[KDnuggets](https://www.kdnuggets.com/2019/05/boost-your-image-classification-model.html)```pythonimage_sz_list = [(28, 28), (32, 32), (64, 64)]ds = Dataset(data_path, image_size=image_sz_list)ds.update_component('get_filenames', load_files)ds.update_component('get_label', get_label)# first call to generatorfor img, label in ds.generator():    print('first call to generator:', img.shape)    break# seconds call to generatorfor img, label in ds.generator():    print('seconds call to generator:', img.shape)    break# third call to generatorfor img, label in ds.generator():    print('third call to generator:', img.shape)    break```&lt;details&gt;&lt;summary&gt;Output&lt;/summary&gt;    get_filenames updated with &lt;function load_files at 0x7fad6916d0e0&gt;    get_label updated with &lt;function get_label at 0x7fad6916d8c0&gt;    first call to generator: (28, 28, 3)    seconds call to generator: (32, 32, 3)    third call to generator: (64, 64, 3)&lt;/details&gt;### tf.data supportCreating a `tf.data` dataloader was never as easy as this one liner. It converts the Python generatorinto `tf.data.Dataset` for a faster data loading, prefetching, caching and everything provided by tf.data.```pythonimage_sz_list = [(28, 28), (32, 32), (64, 64)]ds = Dataset(data_path, image_size=image_sz_list)ds.update_component('get_filenames', load_files)ds.update_component('get_label', get_label)dl = ds.get_tf_dataset()for e in dl.take(1):    print(e[0].shape)for e in dl.take(1):    print(e[0].shape)for e in dl.take(1):    print(e[0].shape)```&lt;details&gt;&lt;summary&gt;Output&lt;/summary&gt;    get_filenames updated with &lt;function load_files at 0x7fad6916d0e0&gt;    get_label updated with &lt;detn get_label at 0x7fad6916d8c0&gt;    (28, 28, 3)    (32, 32, 3)    (64, 64, 3)&lt;/details&gt;## TrainerThe Trainer class inherits from `tf.keras.Model`, it contains everything that is required for training. It exposestrainer.cyclic_fit method which trains the model using Cyclic Learning rate discoveredby [Leslie Smith](https://arxiv.org/abs/1506.01186).```pythonfrom chitra.trainer import Trainer, create_cnnfrom chitra.datagenerator import Datasetds = Dataset(cat_dog_path, image_size=(224, 224))model = create_cnn('mobilenetv2', num_classes=2, name='Cat_Dog_Model')trainer = Trainer(ds, model)# trainer.summary()``````pythontrainer.compile2(batch_size=8,    optimizer=tf.keras.optimizers.SGD(1e-3, momentum=0.9, nesterov=True),    lr_range=(1e-6, 1e-3),    loss='binary_crossentropy',    metrics=['binary_accuracy'])trainer.cyclic_fit(epochs=5,    batch_size=8,    lr_range=(0.00001, 0.0001),)```&lt;details&gt;&lt;summary&gt;Training Loop...&lt;/summary&gt;    cyclic learning rate already set!    Epoch 1/5    1/1 [==============================] - 0s 14ms/step - loss: 6.4702 - binary_accuracy: 0.2500    Epoch 2/5    Returning the last set size which is: (224, 224)    1/1 [==============================] - 0s 965us/step - loss: 5.9033 - binary_accuracy: 0.5000    Epoch 3/5    Returning the last set size which is: (224, 224)    1/1 [==============================] - 0s 977us/step - loss: 5.9233 - binary_accuracy: 0.5000    Epoch 4/5    Returning the last set size which is: (224, 224)    1/1 [==============================] - 0s 979us/step - loss: 2.1408 - binary_accuracy: 0.7500    Epoch 5/5    Returning the last set size which is: (224, 224)    1/1 [==============================] - 0s 982us/step - loss: 1.9062 - binary_accuracy: 0.8750    &lt;tensorflow.python.keras.callbacks.History at 0x7f8b1c3f2410&gt;&lt;/details&gt;## ‚ú® Model InterpretabilityIt is important to understand what is going inside the model. Techniques like GradCam and Saliency Maps can visualizewhat the Network is learning. `trainer` module has InterpretModel class which creates GradCam and GradCam++visualization with almost no additional code.```pythonfrom chitra.trainer import InterpretModeltrainer = Trainer(ds, create_cnn('mobilenetv2', num_classes=1000, keras_applications=False))model_interpret = InterpretModel(True, trainer)image = ds[1][0].numpy().astype('uint8')image = Image.fromarray(image)model_interpret(image)print(IMAGENET_LABELS[285])```    Returning the last set size which is: (224, 224)    index: 282    Egyptian Mau![png](https://raw.githubusercontent.com/aniketmaurya/chitra/master/docs/assets/images/output_22_1.png)## üé® Data Visualization### Image annotationBounding Box creation is based on top of `imgaug` library.```pythonfrom chitra.image import Chitraimport matplotlib.pyplot as pltbbox = [70, 25, 190, 210]label = 'Dog'image = Chitra(image_path, bboxes=bbox, labels=label)plt.imshow(image.draw_boxes())```![png](https://raw.githubusercontent.com/aniketmaurya/chitra/master/docs/assets/images/preview-bounding-box.png)See [Play with Images](https://chitra.readthedocs.io/en/latest/examples/chitra-class/chitra-class.html) for detailedexample!## üöÄ Model Serving (Framework Agnostic)Chitra can Create Rest API or Interactive UI app for Any Learning Model -ML, DL, Image Classification, NLP, Tensorflow, PyTorch or SKLearn.It provides `chitra.serve.GradioApp` for building Interactive UI app for ML/DL modelsand `chitra.serve.API` for building Rest API endpoint.```pythonfrom chitra.serve import create_apifrom chitra.trainer import create_cnnmodel = create_cnn('mobilenetv2', num_classes=2)create_api(model, run=True, api_type='image-classification')```&lt;details&gt;&lt;summary&gt;API Docs Preview&lt;/summary&gt;![Preview Model Server](https://raw.githubusercontent.com/aniketmaurya/chitra/master/docs/examples/model-server/preview.png)&lt;/details&gt;See [Example Section](https://chitra.readthedocs.io/en/latest/source/api/serve/model_server/) for detailedexplanation!## üõ† UtilityLimit GPU memory or enable dynamic GPU memory growth for Tensorflow.```pythonfrom chitra.utility.tf_utils import limit_gpu, gpu_dynamic_mem_growth# limit the amount of GPU required for your traininglimit_gpu(gpu_id=0, memory_limit=1024 * 2)```    No GPU:0 found in your system!```pythongpu_dynamic_mem_growth()```    No GPU found on the machine!## ü§ó ContributeContributions of any kind are welcome. Please check the [**ContributingGuidelines**](https://github.com/aniketmaurya/chitra/blob/master/CONTRIBUTING.md) before contributing.## Code Of ConductWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.Read full [**Contributor Covenant Code of Conduct**](https://github.com/aniketmaurya/chitra/blob/master/CODE_OF_CONDUCT.md)## Acknowledgement*chitra* is built with help of awesome libraries like [Tensorflow 2.x](https://github.com/tensorflow/tensorflow),[imgaug](https://github.com/aleju/imgaug), [FastAPI](https://github.com/tiangolo/fastapi) and [Gradio](https://gradio.app).</longdescription>
</pkgmetadata>