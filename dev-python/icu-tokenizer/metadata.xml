<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>**ICU-tokenizer** is a python package used to perform universal languagenormalization and tokenization using the International Components forUnicode.- [Install](#install)- [Usage (Python)](#usage-python)  - [Sentence splitter](#sentence-splitter)  - [Normalizer](#normalizer)  - [Tokenizer](#tokenizer)## InstallSee [./INSTALL.md](./INSTALL.md)## Usage (Python)### Sentence splitter```py# To split a paragraph into multiple sentences&gt;&gt;&gt; from icu_tokenizer import SentSplitter&gt;&gt;&gt; splitter = SentSplitter('zh')&gt;&gt;&gt; paragraph = &quot;&quot;&quot;美国最高法院（英语：Supreme Court of the United States），一般是指美国联邦最高法院，是美国最高级别的联邦法院，为美国三权继总统、国会后最为重要的一环。根据1789年《美国宪法第三条》的规定，最高法院对所有联邦法院、州法院和涉及联邦法律问题的诉讼案件具有最终（并且在很大程度上是有斟酌决定权的）上诉管辖权，以及对小范围案件的具有初审管辖权。在美国的法律制度中，最高法院通常是包括《美国宪法》在内的联邦法律的最终解释者，但仅在具有管辖权的案件范围内。法院不享有判定政治问题的权力；政治问题的执法机关是行政机关，而不是政府的司法部门。&quot;&quot;&quot;&gt;&gt;&gt; splitter.split(paragraph)[    '美国最高法院（英语：Supreme Court of the United States），一般是指美国联邦最高法院，是美国最高级别的联邦法院，为美国三权继总统、国会后最为重要的一环。',    '根据1789年《美国宪法第三条》的规定，最高法院对所有联邦法院、州法院和涉及联邦法律问题的诉讼案件具有最终（并且在很大程度上是有斟酌决定权的）上诉管辖权，以及对小范围案件的具有初审管辖权。',    '在美国的法律制度中，最高法院通常是包括《美国宪法》在内的联邦法律的最终解释者，但仅在具有管辖权的案件范围内。',    '法院不享有判定政治问题的权力；政治问题的执法机关是行政机关，而不是政府的司法部门。']```### Normalizer```py# To normalize text&gt;&gt;&gt; from icu_tokenizer import Normalizer&gt;&gt;&gt; normalizer = Normalizer(lang='en', norm_puncts=True)&gt;&gt;&gt; text = &quot;𝑻𝒉𝒆 𝒑𝒓𝒐𝒅𝒖𝒄𝒕𝒔 𝒚𝒐𝒖 𝒐𝒓𝒅𝒆𝒓𝒆𝒅 𝒘𝒊𝒍𝒍 𝒃𝒆 𝒔𝒉𝒊𝒑𝒑𝒆𝒅 𝒅𝒊𝒓𝒆𝒄𝒕𝒍𝒚 𝒇𝒓𝒐𝒎 𝑲𝒐𝒓𝒆𝒂.&quot;&gt;&gt;&gt; normalizer.normalize(text)&quot;The products you ordered will be shipped directly from Korea.&quot;&gt;&gt;&gt; text = &quot;【】（）&quot;&gt;&gt;&gt; normalizer.normalize(text)&quot;[]()&quot;```### Tokenizer```py&gt;&gt;&gt; from icu_tokenizer import Tokenizer&gt;&gt;&gt; tokenizer = Tokenizer(lang='th')&gt;&gt;&gt; text = &quot;ภาษาไทยเป็นภาษาที่มีระดับเสียงของคำแน่นอนหรือวรรณยุกต์เช่นเดียวกับภาษาจีน และออกเสียงแยกคำต่อคำ&quot;&gt;&gt;&gt; tokenizer.tokenize(text)['ภาษา', 'ไทย', 'เป็น', 'ภาษา', 'ที่', 'มี', 'ระดับ', 'เสียง', 'ของ', 'คำ', 'แน่นอน', 'หรือ', 'วรรณยุกต์', 'เช่น', 'เดียว', 'กับ', 'ภาษา', 'จีน', 'และ', 'ออก', 'เสียง', 'แยก', 'คำ', 'ต่อ', 'คำ']```</longdescription>
</pkgmetadata>