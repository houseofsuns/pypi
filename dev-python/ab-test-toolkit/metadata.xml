<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># ab-test-toolkit&lt;!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! --&gt;## Install``` shpip install ab_test_toolkit```## imports``` pythonfrom ab_test_toolkit.generator import (    generate_binary_data,    generate_continuous_data,    data_to_contingency,    contingency_from_counts,)from ab_test_toolkit.power import (    simulate_power_binary,    sample_size_binary,    simulate_power_continuous,    sample_size_continuous,)from ab_test_toolkit.plotting import (    plot_power,    plot_distribution,    plot_betas,    plot_binary_power,)from ab_test_toolkit.analyze import p_value_binary```## Binary target (e.g. conversion rate experiments)### Sample size:We can calculate the sample size required with the function“sample_size_binary”. Input needed is:- Conversion rate control: cr0- Conversion rate variant for minimal detectable effect: cr1 (for  example, if we have a conversion rate of 1% and want to detect an  effect of at least 20% relate, we would set cr0=0.010 and cr1=0.012)- Significance threshold: alpha. Usually set to 0.05, this defines our  tolerance for falsely detecting an effect if in reality there is none  (alpha=0.05 means that in 5% of the cases we will detect an effect  even though the samples for control and variant are drawn from the  exact same distribution).- Statistical power. Usually set to 0.8. This means that if the effect  is the minimal effect specified above, we have an 80% probability of  identifying it at statistically significant (and hence 20% of not  idenfitying it).- one_sided: If the test is one-sided (one_sided=True) or if it is  two-sided (one_sided=False). As a rule of thumb, if there are very  strong reasons to believe that the variant cannot be inferior to the  control, we can use a one sided test. In case of doubts, using a two  sided test is better.let us calculate the sample size for the following example:``` pythonn_sample = sample_size_binary(    cr0=0.01,    cr1=0.012,    alpha=0.05,    power=0.8,    one_sided=True,)print(f&quot;Required sample size per variant is {int(n_sample)}.&quot;)```    Required sample size per variant is 33560.``` pythonn_sample_two_sided = sample_size_binary(    cr0=0.01,    cr1=0.012,    alpha=0.05,    power=0.8,    one_sided=False,)print(    f&quot;For the two-sided experiment, required sample size per variant is {int(n_sample_two_sided)}.&quot;)```    For the two-sided experiment, required sample size per variant is 42606.### Power simulationsWhat happens if we use a smaller sample size? And how can we understandthe sample size?Let us analyze the statistical power with synthethic data. We can dothis with the simulate_power_binary function. We are using some defaultargument here, see [thispage](https://k111git.github.io/ab-test-simulator/power.html) for moreinformation.``` python# simulation = simulate_power_binary()```Note: The simulation object return the total sample size, so we need tosplit it per variant.``` python# simulation```Finally, we can plot the results (note: the plot function show thesample size per variant):``` python# plot_power(#     simulation,#     added_lines=[{&quot;sample_size&quot;: sample_size_binary(), &quot;label&quot;: &quot;Chi2&quot;}],# )```### Compute p-value``` pythonn0 = 5000n1 = 5100c0 = 450c1 = 495df_c = contingency_from_counts(n0, c0, n1, c1)df_c```&lt;div&gt;&lt;style scoped&gt;    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }&amp;#10;    .dataframe tbody tr th {        vertical-align: top;    }&amp;#10;    .dataframe thead th {        text-align: right;    }&lt;/style&gt;|       | users | converted | not_converted | cvr      ||-------|-------|-----------|---------------|----------|| group |       |           |               |          || 0     | 5000  | 450       | 4550          | 0.090000 || 1     | 5100  | 495       | 4605          | 0.097059 |&lt;/div&gt;``` pythonp_value_binary(df_c)```    0.11824221841149218### The problem of peakingwip## Contunious target (e.g. average)Here we assume normally distributed data (which usually holds due to thecentral limit theorem).### Sample sizeWe can calculate the sample size required with the function“sample_size_continuous”. Input needed is:- mu1: Mean of the control group- mu2: Mean of the variant group assuming minimal detectable effect  (e.g. if the mean it 5, and we want to detect an effect as small as  0.05, mu1=5.00 and mu2=5.05)- sigma: Standard deviation (we assume the same for variant and control,  should be estimated from historical data)- alpha, power, one_sided: as in the binary caseLet us calculate an example:``` pythonn_sample = sample_size_continuous(    mu1=5.0, mu2=5.05, sigma=1, alpha=0.05, power=0.8, one_sided=True)print(f&quot;Required sample size per variant is {int(n_sample)}.&quot;)```Let us also do some simulations. These show results for the t-test aswell as bayesian testing (only 1-sided).``` python# simulation = simulate_power_continuous()`````` python# plot_power(#     simulation,#     added_lines=[#         {&quot;sample_size&quot;: continuous_sample_size(), &quot;label&quot;: &quot;Formula&quot;}#     ],# )```## Data GeneratorsWe can also use the data generators for example data to analyze orvisualuze as if they were experiments.Distribution without effect:``` pythondf_continuous = generate_continuous_data(effect=0)# plot_distribution(df_continuous)```Distribution with effect:``` pythondf_continuous = generate_continuous_data(effect=1)# plot_distribution(df_continuous)```## VisualizationsPlot beta distributions for a contingency table:``` pythondf = generate_binary_data()df_contingency = data_to_contingency(df)# fig = plot_betas(df_contingency, xmin=0, xmax=0.04)```## False positives``` python# simulation = simulate_power_binary(cr0=0.01, cr1=0.01, one_sided=False)`````` python# plot_power(simulation, is_effect=False)`````` python# simulation = simulate_power_binary(cr0=0.01, cr1=0.01, one_sided=True)# plot_power(simulation, is_effect=False)```</longdescription>
</pkgmetadata>