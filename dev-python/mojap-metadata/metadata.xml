<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># mojap-metadataThis python package allows users to read and alter our metadata schemas (using the metadata module) as well as convert our metadata schemas to other schema definitions utilised by other tools (these are defined in the converters module and are defined as Converters).[Metadata](#metadata)[Converters](#converters)[Converter Systems](#converter-systems)## InstallationMake sure you are using a new version of pip (&gt;=20.0.0)```bashpip install git+https://github.com/moj-analytical-services/mojap-metadata```To install additional dependencies that will be used by the converters (e.g. `etl-manager` and `arrow` extras)```bashpip install 'mojap-metadata[etl-manager,arrow] @ git+https://github.com/moj-analytical-services/mojap-metadata'```&lt;hr&gt;# Metadata This module creates a class called `Metadata` which allows you to interact with our agnostic metadata schemas. The `Metadata` class deals with parsing, manipulating and validating metadata json schemas.## The SchemaOur metadata schemas are used to define a table. The idea of these schemas are to define the contexts of a table with generic metadata schemas. If you want to use this schema to interact with Oracle, PyArrow or AWS Glue for example, then you can create a Converter class to take the metadata and converter it to a schema that works with that tool (or vice versa).When adding a parameter to the metadata config first thing is to look if it exists in [json-schema](https://json-schema.org/understanding-json-schema/index.html). For example `enum`, `pattern` and `type` are parameters in our column types but come from json schema naming definitions.An example of a basic metadata schema:```json{    &quot;$schema&quot; : &quot;$schema&quot;: &quot;https://moj-analytical-services.github.io/metadata_schema/mojap_metadata/v1.0.0.json&quot;,    &quot;name&quot;: &quot;employees&quot;,    &quot;description&quot;: &quot;table containing employee information&quot;,    &quot;file_format&quot;: &quot;parquet&quot;,    &quot;columns&quot;: [        {            &quot;name&quot;: &quot;employee_id&quot;,            &quot;type&quot;: &quot;int64&quot;,            &quot;type_desc&quot;: &quot;integer&quot;,            &quot;description&quot;: &quot;an ID for each employee&quot;,            &quot;minimum&quot;: 1000,            &quot;maximum&quot;: 9999        },        {            &quot;name&quot;: &quot;employee_name&quot;,            &quot;type&quot;: &quot;string&quot;,            &quot;type_string&quot;: &quot;string&quot;,            &quot;description&quot;: &quot;name of the employee&quot;        },        {            &quot;name&quot;: &quot;employee_dob&quot;,            &quot;type&quot;: &quot;date64&quot;,            &quot;type_desc&quot;: &quot;date&quot;,            &quot;description&quot;: &quot;date of birth for the employee in ISO format&quot;,            &quot;pattern&quot;: &quot;^\\d{4}-([0]\\d|1[0-2])-([0-2]\\d|3[01])$&quot;        }    ]}```### Schema Properties- **name:** String that can be whatever you want to name the table. Best to avoid spaces as most systems do not like that but it will let you do this.- **file_format:** String denoting the file format.- **columns:** List of objects where each object descibes a column in your table. Each column object must have at least a `name` and a (`type` or `type_description`).    - **name:** String denoting the name of the column.    - **type:** String specifing the type the data is in. We use data types from the [Apache Arrow project](https://arrow.apache.org/docs/python/api/datatypes.html). We use their type names as it seems to comprehensively cover most of the data types we deal with. _Note: In our naming convention for types we allow `bool` (which is equivalent to `bool_`) and `list` (which is equivalent to `list_`)._    - **type_category:** These group different sets of `type` properties into a single superset. These are: `integer`, `float`, `string`, `timestamp`, `bool`, `list`, `struct`. For example we class `int8, int16, int32, int64, uint8, uint16, uint32, uint64` as `integer`. It allows users to give more generic types if your data is not coming from a system or output with strict types (i.e. data exported from Excel or an unknown origin). The Metadata class has default type values for each given `type_category`. See the `default_type_category_lookup` attribute of the `Metadata` class to see said defaults. This field is required if `type` is not set.    - **description:** Description of the column.    - **enum:** List of what values that column can take. _(Same as the standardised json schema keyword)._    - **pattern:** Regex pattern that value has to to match (for string type_categories only). _(Same as the standardised json schema keyword)._    - **minLength / maxLength:** The minimum and maximum length of the string (for string type_categories only). _(Same as the standardised json schema keyword)._    - **minimum / maximum:** The minumum and maximum value a numerical type can take (for integer and float type_categories only).- **partitions:** List of what columns in your dataset are partitions.- **table_location:** the location of the table. This is a string that can represent a file path, directory, url, etc.- **database_name:**  the name of the database this table belongs to.#### Additional Schema ParametersWe allow users to add addition parameters to the table schema object or any of the columns in the schema. If there are specific parameters / tags you want to add to your schema it should still pass validation (as long as the additional parameters are not the same name of ones already used in the schema).## Usage```pythonfrom mojap_metadata import Metadata# Generate basic Metadata Table from dictmeta1 = Metadata(name=&quot;test&quot;, columns=[{&quot;name&quot;: &quot;c1&quot;, &quot;type&quot;: &quot;int64&quot;}, {&quot;name&quot;: &quot;c2&quot;, &quot;type&quot;: &quot;string&quot;}])print(meta1.name) # testprint(meta1.columns[0]) # {&quot;name&quot;: &quot;c1&quot;, &quot;type&quot;: &quot;int64&quot;}print(meta1.description) # &quot;&quot;# Generate meta from dictd = {    &quot;name&quot;: &quot;test&quot;,    &quot;columns&quot;: [        {&quot;name&quot;: &quot;c1&quot;, &quot;type&quot;: &quot;int64&quot;},        {&quot;name&quot;: &quot;c2&quot;, &quot;type&quot;: &quot;string&quot;}    ]}meta2 = Metadata.from_dict(d)# Read / write to jsonmeta3 = Metadata.from_json(&quot;path/to/metadata_schema.json&quot;)meta3.name = &quot;new_table&quot;meta3.to_json(&quot;path/to/new_metadata_schema.json&quot;)```## Added Class methods and propertiesThe metadata class has some methods and properties that are not part of the schema but helps organise and manage the schema.### Column MethodsThe class has multiple methods to alter the columns list.- `column_names`: Get a list of column names- `update_column`: If column with name matches replace it otherwise add it to the end- `remove_column`: Remove column that matches the given name. Note if a name in the `partitions` property matches that name then it is also removed.```python    meta = Metadata(columns=[        {&quot;name&quot;: &quot;a&quot;, &quot;type&quot;: &quot;int8&quot;},        {&quot;name&quot;: &quot;b&quot;, &quot;type&quot;: &quot;string&quot;},        {&quot;name&quot;: &quot;c&quot;, &quot;type&quot;: &quot;date32&quot;},    ])    meta.column_names # [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]     meta.update_column({&quot;name&quot;: &quot;a&quot;, &quot;type&quot;: &quot;int64&quot;})    meta.columns[0][&quot;type&quot;] # &quot;int64&quot;    meta.update_column({&quot;name&quot;: &quot;d&quot;, &quot;type&quot;: &quot;string&quot;})    meta.column_names # [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;]    meta.remove_column(&quot;d&quot;)    assert meta.column_names == [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]```The metadata class is a subclass of MutableMappings, where keys are column names and values are column metadata. - A metadata column can be accessed using the column name as a key.- A new or existing column can be updated using the column name as a key. The key must match the column name. Calls update_column.- A column can be deleted. Calls remove_column.- Columns of metadata can be iterated over.- The length of metadata is defined as the number of columns.```python# Access a specific columnmeta[&quot;c1&quot;] # {&quot;name&quot;: &quot;c1&quot;, &quot;type&quot;: &quot;int64&quot;}# Add a new column (key must match name)meta[&quot;c3&quot;] = {&quot;name&quot;: &quot;c3&quot;, &quot;type&quot;: &quot;bool&quot;}# Delete a columndel meta[&quot;c3&quot;]# Iterate over all columnsfor col in meta:    print(f&quot;column name:{col[&quot;name&quot;]}, column type:{col[&quot;type&quot;]}&quot;)# Get the number of columnslen(meta) # 3```### force_partition_order PropertyBy default this is set to None. However can be set to `&quot;start&quot;` or `&quot;end&quot;`. When set to None the Metadata Class will not track column order relative to partitions.&gt; Note: For Athena we normally set partitions at the end.```pythonmeta = Metadata(columns=[        {&quot;name&quot;: &quot;a&quot;, &quot;type&quot;: &quot;int8&quot;},        {&quot;name&quot;: &quot;b&quot;, &quot;type&quot;: &quot;string&quot;},        {&quot;name&quot;: &quot;c&quot;, &quot;type&quot;: &quot;date32&quot;},    ])meta.partitions = [&quot;b&quot;]meta.column_names # [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]```If set to `&quot;start&quot;` or `&quot;end&quot;` then any changes to partitions will affect the column order.```pythonmeta.force_partition_order = &quot;start&quot;meta.column_names # [&quot;b&quot;, &quot;a&quot; ,&quot;c&quot;]```### Generating Metadata objects&lt;hr&gt;# ConvertersConverters takes a Metadata object and generates something else from it (or can convert something to a Metadata object). Most of the time your converter will convert our schema into another systems schema.## How to use the ConvertersFor example the `ArrowConverter` takes our schemas and converts them to a pyarrow schema:```pythonfrom mojap_metadata import Metadatafrom mojap_metadata.converters.arrow_converter import ArrowConverterd = {    &quot;name&quot;: &quot;test&quot;,    &quot;columns&quot;: [        {&quot;name&quot;: &quot;c1&quot;, &quot;type&quot;: &quot;int64&quot;},        {&quot;name&quot;: &quot;c2&quot;, &quot;type&quot;: &quot;string&quot;},        {&quot;name&quot;: &quot;c3&quot;, &quot;type&quot;: &quot;struct&lt;k1: string, k2:list&lt;int64&gt;&gt;&quot;}    ],    &quot;file_format&quot;: &quot;jsonl&quot;}meta = Metadata.from_dict(d)ac = ArrowConverter()arrow_schema = ac.generate_from_meta(meta)print(arrow_schema) # Could use this schema to read in data as arrow dataframe and cast it to the correct types```Another use for the arrow converter is to convert it back from an Arrow schema to our metadata. This is especially useful if you have nested data types that would be difficult to write out the full `STRUCT` / `LIST`. Instead you can let Arrow do that for you and then pass the agnostic metadata object into something like the Glue Converter to generate a schema for AWS Glue.```pythonimport pyarrow as paimport pandas as pdfrom mojap_metadata.converters.arrow_converter import ArrowConverterdata = {    &quot;a&quot;: [0,1],    &quot;b&quot;: [        {&quot;cat&quot;: {&quot;meow&quot;: True}, &quot;dog&quot;: [&quot;bone&quot;, &quot;fish&quot;]},        {&quot;cat&quot;: {&quot;meow&quot;: True}, &quot;dog&quot;: [&quot;bone&quot;, &quot;fish&quot;]},    ]}df = pd.DataFrame(data)arrow_df = pa.Table.from_pandas(df)ac = ArrowConverter()meta = ac.generate_to_meta(arrow_df.schema)print(meta.columns) # [{'name': 'a', 'type': 'int64'}, {'name': 'b', 'type': 'struct&lt;cat:struct&lt;meow:bool&gt;, dog:list&lt;string&gt;&gt;'}]```All converter classes are sub classes of the `mojap_metadata.converters.BaseConverter`. This `BaseConverter` has no actual functionality but is a boilerplate class that ensures standardised attributes  for all added `Converters` these are:- **generate_from_meta:** (function) takes a Metadata object and returns whatever the converter is producing .- **generate_to_meta:** (function) takes Any object (normally another schema for another system or package) and returns our Metadata object. (i.e. the reverse of generate_from_meta).- **options:** (Data Class) that are the options for the converter. The base options have a `suppress_warnings` parameter but it doesn't mean call converters use this. To get a better understanding of setting options see the `GlueConverter` class or the `tests/test_glue_converter.py` to see how they are set.## Further UsageSee the [mojap-aws-tools repo](https://github.com/moj-analytical-services/mojap-aws-tools-demo) which utilises the converters a lot in different tutorials.## Contributing and Design ConsiderationsEach new converter (if not expanding on existing converters) should be added as a new submodule within the parent `converters` module. This is especially true if the new converter has additional package dependencies. By design the standard install of this package is fairly lightweight. However if you needed the `ArrowConverter` you would need to install the additional package dependencies for the arrow converter:```bashpip install 'mojap-metadata[arrow] @ git+https://github.com/moj-analytical-services/mojap-metadata'```This means we can continuely add converters (as submodules) and add optional package dependencies ([see pyproject.toml](./pyproject.toml) ) without making the default install any less lightweight. `mojap_metadata` would only error if someone tries to import a converter subclass that with having the additional dependencies dependencies installed.## Converter systems### Glue ConverterThe `GlueConverter` takes our schemas and converts them to a dictionary that be passed to the glue_client to deploy a schema on AWS Glue.```pythonimport boto3from mojap_metadata import Metadatafrom mojap_metadata.converters.glue_converter import GlueConverterd = {    &quot;name&quot;: &quot;test&quot;,    &quot;columns&quot;: [        {&quot;name&quot;: &quot;c1&quot;, &quot;type&quot;: &quot;int64&quot;},        {&quot;name&quot;: &quot;c2&quot;, &quot;type&quot;: &quot;string&quot;},        {&quot;name&quot;: &quot;c3&quot;, &quot;type&quot;: &quot;struct&lt;k1: string, k2:list&lt;int64&gt;&gt;&quot;}    ],    &quot;file_format&quot;: &quot;jsonl&quot;}meta = Metadata.from_dict(d)gc = GlueConverter()boto_dict = gc.generate_from_meta(meta, )boto_dict = gc.generate_from_meta(meta, database_name=&quot;test_db&quot;, table_location=&quot;s3://bucket/test_db/test/&quot;)print(boto_dict) glue_client = boto3.client(&quot;glue&quot;)glue_client.create_table(**boto_dict) # Would deploy glue schema based on our metadata```included alongside `GlueConverter` is `GlueTable` that can overlay a metadata object, dictionary, or path to metadata file. it has one method:- **generate_from_meta:** generates a glue table from the metadata object, dict, or string path, takes the following arguments:    - _metadata:_ the metadata object, dict, or string path that is to be overlaid    - _table\_location:_ a kwarg, the location of the table data. This can also be a property of the metadata object, dict, or file    - _database\_name:_ a kwarg, the name of the glue database to put the table. This can also be a property of the metadata object, dict, or file### SQLAlchemy ConverterUses the [Inspector](https://docs.sqlalchemy.org/en/20/core/reflection.html#fine-grained-reflection-with-inspector) class to extract metadata from database dialects supported by [SQLAlchemy](https://docs.sqlalchemy.org/en/20/dialects/index.html#dialects).See [SQLAlchemy Converter](/mojap_metadata/converters/sqlalchemy_converter/) for more details.### Postgres ConverterPostgres Converter provides the following functionality1. Conenction to postgres database2. Extract the metadata from the tables3. Convert the extracted ouptut into Metadata object - **get_object_meta** (function) takes the table name, schema name then the extracts the metadata from postgres database and converts into Metadata object - **generate_to_meta:** (function) takes the database connection and returns a list of Metadata object for all the (non-system schemas) schemas and tables from the connection.NOTE: the sqlalchemy converter is more robust and should be the default method for most databases, but the postgres converter is retained for compatibility</longdescription>
</pkgmetadata>