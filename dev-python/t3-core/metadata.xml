<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>T3 Python Core Library======================.. image:: https://gitlab.t-3.com/t3-core/t3-core-python/badges/master/pipeline.svg   :target: https://gitlab.t-3.com/sunoco/t3-python-core/commits/master   :alt: pipeline status.. image:: https://gitlab.t-3.com/t3-core/t3-core-python/badges/master/coverage.svg   :target: https://gitlab.t-3.com/sunoco/t3-python-core/commits/master   :alt: coverage report.. image:: https://badge.fury.io/py/t3-core.svg   :target: https://badge.fury.io/py/t3-core   :alt: PyPI versionInstall-------Setup Virtualenv (optional)^^^^^^^^^^^^^^^^^^^^^^^^^^^.. code-block:: sh   python -m venv .venv   source .venv/bin/activate   # There is a bug in pip 9.x  go ahead and upgrade to make sure that you're pip 10.x   pip install --upgrade pipInstall^^^^^^^.. code-block:: sh   # Install from pypi   pip install t3-core   # Install in the `src` dir of your python environment   pip install -e git+ssh://git@gitlab.t-3.com:t3-core/t3-core-python.git   # Choose where the clone lives   git clone git@gitlab.t-3.com:t3-core/t3-core-python.git   pip install -e ./t3-python-coreTesting &amp; Linting-----------------Test &amp; Coverage Report^^^^^^^^^^^^^^^^^^^^^^.. code-block:: sh   pytestLint^^^^.. code-block:: sh   pylamaT3 Events---------In *t3-core*\ , we've a sub-module which is an event queue system used to connect microservices together, in an asynchronous manner, with built-in fault tolerance. It uses *RabbitMQ* as a messaging bus to accomplish this. Event queue system consists of 2 main parts, *consumer*\ , and *publisher*. A Consumer, as the name suggests, consumes the messages, by invoking a callback upon receiving the specified message, which is published by the Publisher. Separately running processes, commonly known as workers can consume messages, whereas, any process including web process can publish messages. If any process is unable to finish consuming the message, it gets requed in the system and is sent to a different consumer or stored until the consumer is available again. In *T3 Events*. *T3 Events*\ , is configured by setting up 2 key environment variables, ``T3_EVENTS``\ , and ``T3_EVENTS_AMQP_URL``\ , the first one is a boolean value of *true* or *false* on whether to use events or not, and the second one is a connection string for *rabbit-mq*. This env vars can be inserted into any system, and as long as different systems have same value for those env vars, they are part of the same message queue system. There are two main types of consumers and publishers, details below:Task^^^^Task consumer/publisher are dedicated to consuming or publishing Tasks, which by definition are consumed one at a time, for a given task, which means, the first available consumer will pick up the task and process it, then the next task in the list will go to the next available consumer, and so on. Below is an example of a sample task.**Consumer:**.. code-block:: python   from t3.events.consumers imoprt TaskConsumer   def message_callback(payload):       print(f'message callback task consumer: payload: {payload}')   # Start consumer   test = TaskConsumer()   test.set_task_name('test_task')   test.set_callback(message_callback)   test.run()**Publisher:**.. code-block:: python   from t3.events.publishers import TaskPublisher   # Use publisher   test = TaskPublisher()   test.set_task_name('test_task')   test.set_message('test message, could be in json too')   test.run()For the above example, the given example task name is ``test_task``\ , which is the same for a consumer and a publisher, which connects them together. Since this is a ``TaskConsumer``\ , and a ``TaskPublisher``\ , if you run more than 1 *Consumer*\ , and *Publish* several times, it'll be processed in a round-robin manner with the running *Consumers*\ , one at a time. Once 1 message is processed, then the system moves on to the next one, and so on.Topic^^^^^Topic consumer/publisher are dedicated to consuming or publishing *Topics*\ , which by definition are broadcasted to all subscribed *Consumers*\ , for a given *Topic*\ , which means, when a topic is published, all consumers signed up for this topic will receive the message. Below is an example of a sample topic.**Consumer:**.. code-block:: python   from t3.events.consumers import TopicConsumer   def message_callback(payload):       print(f'message callback topic consumer: payload: {payload}')   # Start consumer   test = TopicConsumer()   test.set_topic_name('test_topic')   test.set_callback(message_callback)   test.run()**Publisher:**.. code-block:: python   from t3.events.publishers import TopicPublisher   import json   # Use publisher   test = TopicPublisher()   test.set_topic_name('test_topic')   test.set_message(json.dumps({'json': 'object'}))   test.run()For the above example, the given topic name is ``test_topic``\ , which is the same for a consumer and a publisher, which connects them together. Since this is a ``TopicConsumer``\ , and a ``TopicPublisher``\ , if you run more than 1 *Consumer*\ , and *Publish*\ , it'll be processed by all running *Consumers*\ , at once.Running T3 Events^^^^^^^^^^^^^^^^^T3 events is composed of *Consumers*\ , and *Publishers*. Consumers must be run in a separate process, as they are independent of anything else that is going on in the system, for local development, you can run ``python name_of_consumer_file.py``\ , however in production environments, use ``nohup python name_of_consumer_file.py``\ , for fault tolerance purposes.Pubishers on the other hand, can be run as part of a process, as their main job is to publish an event to the message queue system. To use a *Publisher*\ , you can run the lines below ``# Use publisher`` from the above examples, provided the 2 required environment variables are present.</longdescription>
</pkgmetadata>