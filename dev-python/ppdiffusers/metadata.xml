<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;div align=&quot;center&quot;&gt;  &lt;img src=&quot;https://user-images.githubusercontent.com/11793384/215372703-4385f66a-abe4-44c7-9626-96b7b65270c8.png&quot; width=&quot;40%&quot; height=&quot;40%&quot; /&gt;&lt;/div&gt;&lt;p align=&quot;center&quot;&gt;    &lt;a href=&quot;https://pypi.org/project/ppdiffusers/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/pyversions/ppdiffusers&quot;&gt;&lt;/a&gt;    &lt;a href=&quot;&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-yellow.svg&quot;&gt;&lt;/a&gt;    &lt;a href=&quot;https://github.com/PaddlePaddle/PaddleMIX/blob/develop/ppdiffusers/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/license-Apache%202-dfd.svg&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;h4 align=&quot;center&quot;&gt;  &lt;a href=#ç‰¹æ€§&gt; ç‰¹æ€§ &lt;/a&gt; |  &lt;a href=#å®‰è£…&gt; å®‰è£… &lt;/a&gt; |  &lt;a href=#å¿«é€Ÿå¼€å§‹&gt; å¿«é€Ÿå¼€å§‹ &lt;/a&gt; |  &lt;a href=#æ¨¡å‹éƒ¨ç½²&gt; æ¨¡å‹éƒ¨ç½²&lt;/a&gt;&lt;/h4&gt;# PPDiffusers: Diffusers toolbox implemented based on PaddlePaddle**PPDiffusers**æ˜¯ä¸€æ¬¾æ”¯æŒå¤šç§æ¨¡æ€ï¼ˆå¦‚æ–‡æœ¬å›¾åƒè·¨æ¨¡æ€ã€å›¾åƒã€è¯­éŸ³ï¼‰æ‰©æ•£æ¨¡å‹ï¼ˆDiffusion Modelï¼‰è®­ç»ƒå’Œæ¨ç†çš„å›½äº§åŒ–å·¥å…·ç®±ï¼Œä¾æ‰˜äº[**PaddlePaddle**](https://www.paddlepaddle.org.cn/)æ¡†æ¶å’Œ[**PaddleNLP**](https://github.com/PaddlePaddle/PaddleNLP)è‡ªç„¶è¯­è¨€å¤„ç†å¼€å‘åº“ã€‚## News ğŸ“¢* ğŸ”¥ **2023.09.27 å‘å¸ƒ 0.19.3 ç‰ˆæœ¬ï¼Œæ–°å¢[SDXL](#æ–‡æœ¬å›¾åƒå¤šæ¨¡)ï¼Œæ”¯æŒText2Imageã€Img2Imgã€Inpaintingã€InstructPix2Pixç­‰ä»»åŠ¡ï¼Œæ”¯æŒDreamBooth Loraè®­ç»ƒï¼›æ–°å¢[UniDiffuser](#æ–‡æœ¬å›¾åƒå¤šæ¨¡)ï¼Œé€šè¿‡ç»Ÿä¸€çš„å¤šæ¨¡æ€æ‰©æ•£è¿‡ç¨‹æ”¯æŒæ–‡ç”Ÿå›¾ã€å›¾ç”Ÿæ–‡ç­‰ä»»åŠ¡ï¼›æ–°å¢æ–‡æœ¬æ¡ä»¶è§†é¢‘ç”Ÿæˆæ¨¡å‹[LVDM](https://github.com/PaddlePaddle/PaddleMIX/tree/develop/ppdiffusers/examples/text_to_video_lvdm)ï¼Œæ”¯æŒè®­ç»ƒä¸æ¨ç†ï¼›æ–°å¢æ–‡å›¾ç”Ÿæˆæ¨¡å‹[Kandinsky 2.2](#æ–‡æœ¬å›¾åƒå¤šæ¨¡)ï¼Œ[Consistency models](#æ–‡æœ¬å›¾åƒå¤šæ¨¡)ï¼›Stable Diffusionæ”¯æŒ[BF16 O2è®­ç»ƒ](https://github.com/PaddlePaddle/PaddleMIX/tree/develop/ppdiffusers/examples/stable_diffusion)ï¼Œæ•ˆæœå¯¹é½FP32ï¼›[LoRAåŠ è½½å‡çº§](#åŠ è½½HF-LoRAæƒé‡)ï¼Œæ”¯æŒåŠ è½½SDXLçš„LoRAæƒé‡ï¼›[Controlnet](https://github.com/PaddlePaddle/PaddleMIX/tree/develop/ppdiffusers/ppdiffusers/pipelines/controlnet)å‡çº§ï¼Œæ”¯æŒControlNetImg2Imgã€ControlNetInpaintã€StableDiffusionXLControlNetç­‰ã€‚*** ğŸ”¥ **2023.06.20 å‘å¸ƒ 0.16.1 ç‰ˆæœ¬ï¼Œæ–°å¢[T2I-Adapter](https://github.com/PaddlePaddle/PaddleMIX/tree/develop/ppdiffusers/examples/t2i-adapter)ï¼Œæ”¯æŒè®­ç»ƒä¸æ¨ç†ï¼›ControlNetå‡çº§ï¼Œæ”¯æŒ[reference onlyæ¨ç†](https://github.com/PaddlePaddle/PaddleMIX/tree/develop/ppdiffusers/examples/community#controlnet-reference-only)ï¼›æ–°å¢[WebUIStableDiffusionPipeline](https://github.com/PaddlePaddle/PaddleMIX/tree/develop/ppdiffusers/examples/community#automatic1111-webui-stable-diffusion)ï¼Œæ”¯æŒé€šè¿‡promptçš„æ–¹å¼åŠ¨æ€åŠ è½½loraã€textual_inversionæƒé‡ï¼›æ–°å¢[StableDiffusionHiresFixPipeline](https://github.com/PaddlePaddle/PaddleMIX/tree/develop/ppdiffusers/examples/community#stable-diffusion-with-high-resolution-fixing)ï¼Œæ”¯æŒé«˜åˆ†è¾¨ç‡ä¿®å¤ï¼›æ–°å¢å…³é”®ç‚¹æ§åˆ¶ç”Ÿæˆä»»åŠ¡è¯„ä»·æŒ‡æ ‡[COCOeval](https://github.com/PaddlePaddle/PaddleMIX/tree/develop/ppdiffusers/scripts/cocoeval_keypoints_score)ï¼›æ–°å¢å¤šç§æ¨¡æ€æ‰©æ•£æ¨¡å‹Pipelineï¼ŒåŒ…æ‹¬è§†é¢‘ç”Ÿæˆï¼ˆ[Text-to-Video-Synth](#æ–‡æœ¬è§†é¢‘å¤šæ¨¡)ã€[Text-to-Video-Zero](#æ–‡æœ¬è§†é¢‘å¤šæ¨¡)ï¼‰ã€éŸ³é¢‘ç”Ÿæˆï¼ˆ[AudioLDM](#æ–‡æœ¬éŸ³é¢‘å¤šæ¨¡)ã€[Spectrogram Diffusion](#éŸ³é¢‘)ï¼‰ï¼›æ–°å¢æ–‡å›¾ç”Ÿæˆæ¨¡å‹[IF](#æ–‡æœ¬å›¾åƒå¤šæ¨¡)ã€‚*** ğŸ”¥ **2023.03.29 å‘å¸ƒ 0.14.0 ç‰ˆæœ¬ï¼Œæ–°å¢[LoRA](https://github.com/PaddlePaddle/PaddleMIX/tree/develop/ppdiffusers/examples/dreambooth)ã€[ControlNet](https://github.com/PaddlePaddle/PaddleMIX/tree/develop/ppdiffusers/examples/controlnet)ï¼Œæ”¯æŒè®­ç»ƒä¸æ¨ç†ï¼›æ¨¡å‹åŠ è½½å‡çº§ï¼Œ[å¯ç›´æ¥åŠ è½½HF Diffusersçš„æƒé‡](#åŠ è½½HF-Diffusersæƒé‡)ï¼ˆsafetensorså’Œptï¼‰æˆ– [SDç­‰åŸåº“çš„Lightningæƒé‡è¿›è¡Œæ¨ç†](#åŠ è½½åŸåº“çš„Lightningæƒé‡)ï¼Œ[æ”¯æŒåŠ è½½Civitaiç¤¾åŒºçš„LoRAæƒé‡](#åŠ è½½Civitaiç¤¾åŒºçš„LoRAæƒé‡)ï¼›[æ”¯æŒxformers](#XFormersåŠ é€Ÿ) è®­ç»ƒä¸æ¨ç†ï¼›æ–°å¢ç”¨äºè¶…é«˜åˆ†è¾¨ç‡ç”Ÿæˆçš„VAE tilingï¼›æ–°å¢Instruct Pix2Pixã€Semantic guidanceã€Depth2imageç­‰æ¨¡å‹ã€‚**## ç‰¹æ€§#### ğŸ“¦ SOTAæ‰©æ•£æ¨¡å‹Pipelinesé›†åˆæˆ‘ä»¬æä¾›**SOTAï¼ˆState-of-the-Artï¼‰** çš„æ‰©æ•£æ¨¡å‹Pipelinesé›†åˆã€‚ç›®å‰**PPDiffusers**å·²ç»é›†æˆäº†**100+Pipelines**ï¼Œæ”¯æŒæ–‡å›¾ç”Ÿæˆï¼ˆText-to-Image Generationï¼‰ã€æ–‡æœ¬å¼•å¯¼çš„å›¾åƒç¼–è¾‘ï¼ˆText-Guided Image Inpaintingï¼‰ã€æ–‡æœ¬å¼•å¯¼çš„å›¾åƒå˜æ¢ï¼ˆImage-to-Image Text-Guided Generationï¼‰ã€æ–‡æœ¬æ¡ä»¶çš„è§†é¢‘ç”Ÿæˆï¼ˆText-to-Video Generationï¼‰ã€è¶…åˆ†ï¼ˆSuper Superresolutionï¼‰ã€æ–‡æœ¬æ¡ä»¶çš„éŸ³é¢‘ç”Ÿæˆï¼ˆText-to-Audio Generationï¼‰åœ¨å†…çš„**10ä½™é¡¹**ä»»åŠ¡ï¼Œè¦†ç›–**æ–‡æœ¬ã€å›¾åƒã€è§†é¢‘ã€éŸ³é¢‘**ç­‰å¤šç§æ¨¡æ€ã€‚å¦‚æœæƒ³è¦äº†è§£å½“å‰æ”¯æŒçš„æ‰€æœ‰**Pipelines**ä»¥åŠå¯¹åº”çš„æ¥æºä¿¡æ¯ï¼Œå¯ä»¥é˜…è¯»[ğŸ”¥ PPDiffusers Pipelines](https://github.com/PaddlePaddle/PaddleMIX/blob/develop/ppdiffusers/ppdiffusers/pipelines/README.md)æ–‡æ¡£ã€‚#### ğŸ”Š æä¾›ä¸°å¯Œçš„Noise Scheduleræˆ‘ä»¬æä¾›äº†ä¸°å¯Œçš„**å™ªå£°è°ƒåº¦å™¨ï¼ˆNoise Schedulerï¼‰**ï¼Œå¯ä»¥å¯¹**é€Ÿåº¦**ä¸**è´¨é‡**è¿›è¡Œæƒè¡¡ï¼Œç”¨æˆ·å¯åœ¨æ¨ç†æ—¶æ ¹æ®éœ€æ±‚å¿«é€Ÿåˆ‡æ¢ä½¿ç”¨ã€‚å½“å‰**PPDiffusers**å·²ç»é›†æˆäº†**14+Scheduler**ï¼Œä¸ä»…æ”¯æŒ [DDPM](https://github.com/PaddlePaddle/PaddleMIX/blob/develop/ppdiffusers/ppdiffusers/schedulers/scheduling_ddpm.py)ã€[DDIM](https://github.com/PaddlePaddle/PaddleMIX/blob/develop/ppdiffusers/ppdiffusers/schedulers/scheduling_ddim.py) å’Œ [PNDM](https://github.com/PaddlePaddle/PaddleMIX/blob/develop/ppdiffusers/ppdiffusers/schedulers/scheduling_pndm.py)ï¼Œè¿˜æ”¯æŒæœ€æ–°çš„ [ğŸ”¥ DPMSolver](https://github.com/PaddlePaddle/PaddleMIX/blob/develop/ppdiffusers/ppdiffusers/schedulers/scheduling_dpmsolver_multistep.py)ï¼#### ğŸ›ï¸ æä¾›å¤šç§æ‰©æ•£æ¨¡å‹ç»„ä»¶æˆ‘ä»¬æä¾›äº†**å¤šç§æ‰©æ•£æ¨¡å‹**ç»„ä»¶ï¼Œå¦‚[UNet1DModel](https://github.com/PaddlePaddle/PaddleMIX/blob/develop/ppdiffusers/ppdiffusers/models/unet_1d.py)ã€[UNet2DModel](https://github.com/PaddlePaddle/PaddleMIX/blob/develop/ppdiffusers/ppdiffusers/models/unet_2d.py)ã€[UNet2DConditionModel](https://github.com/PaddlePaddle/PaddleMIX/blob/develop/ppdiffusers/ppdiffusers/models/unet_2d_condition.py)ã€[UNet3DConditionModel](https://github.com/PaddlePaddle/PaddleMIX/blob/develop/ppdiffusers/ppdiffusers/models/unet_3d_condition.py)ã€[VQModel](https://github.com/PaddlePaddle/PaddleMIX/blob/develop/ppdiffusers/ppdiffusers/models/vae.py)ã€[AutoencoderKL](https://github.com/PaddlePaddle/PaddleMIX/blob/develop/ppdiffusers/ppdiffusers/models/vae.py)ç­‰ã€‚#### ğŸ“– æä¾›ä¸°å¯Œçš„è®­ç»ƒå’Œæ¨ç†æ•™ç¨‹æˆ‘ä»¬æä¾›äº†ä¸°å¯Œçš„è®­ç»ƒæ•™ç¨‹ï¼Œä¸ä»…æ”¯æŒæ‰©æ•£æ¨¡å‹çš„äºŒæ¬¡å¼€å‘å¾®è°ƒï¼Œå¦‚åŸºäº[Textual Inversion](https://github.com/PaddlePaddle/PaddleMIX/tree/develop/ppdiffusers/examples/textual_inversion)å’Œ[DreamBooth](https://github.com/PaddlePaddle/PaddleMIX/tree/develop/ppdiffusers/examples/dreambooth)ä½¿ç”¨3-5å¼ å›¾å®šåˆ¶åŒ–è®­ç»ƒç”Ÿæˆå›¾åƒçš„é£æ ¼æˆ–ç‰©ä½“ï¼Œè¿˜æ”¯æŒ[ğŸ”¥ Latent Diffusion Model](https://github.com/PaddlePaddle/PaddleMIX/tree/develop/ppdiffusers/examples/text_to_image_laion400m)ã€[ğŸ”¥ ControlNet](https://github.com/PaddlePaddle/PaddleMIX/tree/develop/ppdiffusers/examples/controlnet)ã€[ğŸ”¥ T2I-Adapter](https://github.com/PaddlePaddle/PaddleMIX/tree/develop/ppdiffusers/examples/t2i-adapter)  ç­‰æ‰©æ•£æ¨¡å‹çš„è®­ç»ƒï¼æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æä¾›äº†ä¸°å¯Œçš„[ğŸ”¥ Pipelinesæ¨ç†æ ·ä¾‹](https://github.com/PaddlePaddle/PaddleMIX/tree/develop/ppdiffusers/examples/inference)ã€‚#### ğŸš€ æ”¯æŒFastDeployé«˜æ€§èƒ½éƒ¨ç½²æˆ‘ä»¬æä¾›åŸºäº[FastDeploy](https://github.com/PaddlePaddle/FastDeploy)çš„[ğŸ”¥ é«˜æ€§èƒ½Stable Diffusion Pipeline](https://github.com/PaddlePaddle/PaddleMIX/blob/develop/ppdiffusers/ppdiffusers/pipelines/stable_diffusion/pipeline_fastdeploy_stable_diffusion.py)ï¼Œæ›´å¤šæœ‰å…³FastDeployè¿›è¡Œå¤šæ¨ç†å¼•æ“åç«¯é«˜æ€§èƒ½éƒ¨ç½²çš„ä¿¡æ¯è¯·å‚è€ƒ[ğŸ”¥ é«˜æ€§èƒ½FastDeployæ¨ç†æ•™ç¨‹](https://github.com/PaddlePaddle/PaddleMIX/tree/develop/ppdiffusers/deploy)ã€‚```pythonfrom ppdiffusers import StableDiffusionPipeline, FastDeployStableDiffusionPipelineorig_pipe = StableDiffusionPipeline.from_pretrained(&quot;runwayml/stable-diffusion-v1-5&quot;)fd_pipe = FastDeployStableDiffusionPipeline.from_pretrained(&quot;runwayml/stable-diffusion-v1-5@fastdeploy&quot;)```## ä»»åŠ¡å±•ç¤º### æ–‡æœ¬å›¾åƒå¤šæ¨¡&lt;details open&gt;&lt;summary&gt;&amp;emsp;æ–‡å›¾ç”Ÿæˆï¼ˆText-to-Image Generationï¼‰&lt;/summary&gt;#### text_to_image_generation-stable_diffusion```pythonfrom ppdiffusers import StableDiffusionPipeline# åŠ è½½æ¨¡å‹å’Œschedulerpipe = StableDiffusionPipeline.from_pretrained(&quot;runwayml/stable-diffusion-v1-5&quot;)# æ‰§è¡Œpipelineè¿›è¡Œæ¨ç†prompt = &quot;a photo of an astronaut riding a horse on mars&quot;image = pipe(prompt).images[0]# ä¿å­˜å›¾ç‰‡image.save(&quot;astronaut_rides_horse_sd.png&quot;)```&lt;div align=&quot;center&quot;&gt;&lt;img width=&quot;300&quot; alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/20476674/209322401-6ecfeaaa-6878-4302-b592-07a31de4e590.png&quot;&gt;&lt;/div&gt;#### text_to_image_generation-stable_diffusion_xl```pythonimport paddlefrom ppdiffusers import StableDiffusionXLPipelinepipe = StableDiffusionXLPipeline.from_pretrained(     &quot;stabilityai/stable-diffusion-xl-base-1.0&quot;,     paddle_dtype=paddle.float16,     variant=&quot;fp16&quot;)prompt = &quot;a photo of an astronaut riding a horse on mars&quot;generator = paddle.Generator().manual_seed(42)image = pipe(prompt=prompt, generator=generator, num_inference_steps=50).images[0]image.save('sdxl_text2image.png')```&lt;div align=&quot;center&quot;&gt;&lt;img width=&quot;300&quot; alt=&quot;image&quot; src=&quot;https://github.com/PaddlePaddle/PaddleMIX/assets/35400185/d72729f9-8685-48f9-a238-e4ddf6d264f3&quot;&gt;&lt;/div&gt;#### text_to_image_generation-sdxl_base_with_refiner```pythonfrom ppdiffusers import DiffusionPipelineimport paddle# load both base &amp; refinerbase = DiffusionPipeline.from_pretrained(    &quot;stabilityai/stable-diffusion-xl-base-1.0&quot;,)refiner = DiffusionPipeline.from_pretrained(    &quot;stabilityai/stable-diffusion-xl-refiner-1.0&quot;,    text_encoder_2=base.text_encoder_2,    vae=base.vae,    paddle_dtype=paddle.float16,    variant=&quot;fp16&quot;,)# Define how many steps and what % of steps to be run on each experts (80/20) heren_steps = 40high_noise_frac = 0.8prompt = &quot;A majestic lion jumping from a big stone at night&quot;prompt = &quot;a photo of an astronaut riding a horse on mars&quot;generator = paddle.Generator().manual_seed(42)# run both expertsimage = base(    prompt=prompt,    output_type=&quot;latent&quot;,    generator=generator,).imagesimage = refiner(    prompt=prompt,    image=image,    generator=generator,).images[0]image.save('text_to_image_generation-sdxl-base-with-refiner-result.png')```&lt;div align=&quot;center&quot;&gt;&lt;img width=&quot;300&quot; alt=&quot;image&quot; src=&quot;https://github.com/PaddlePaddle/PaddleMIX/assets/35400185/8ef36826-ed94-4856-a356-af1677f60d1b&quot;&gt;&lt;/div&gt;#### text_to_image_generation-kandinsky2_2```pythonfrom ppdiffusers import KandinskyV22Pipeline, KandinskyV22PriorPipelinepipe_prior = KandinskyV22PriorPipeline.from_pretrained(&quot;kandinsky-community/kandinsky-2-2-prior&quot;)prompt = &quot;red cat, 4k photo&quot;out = pipe_prior(prompt)image_emb = out.image_embedszero_image_emb = out.negative_image_embedspipe = KandinskyV22Pipeline.from_pretrained(&quot;kandinsky-community/kandinsky-2-2-decoder&quot;)image = pipe(    image_embeds=image_emb,    negative_image_embeds=zero_image_emb,    height=768,    width=768,    num_inference_steps=50,).imagesimage[0].save(&quot;text_to_image_generation-kandinsky2_2-result-cat.png&quot;)```&lt;div align=&quot;center&quot;&gt;&lt;img width=&quot;300&quot; alt=&quot;image&quot; src=&quot;https://github.com/PaddlePaddle/PaddleMIX/assets/35400185/188f76dd-4bd7-4a33-8f30-b893c7a9e249&quot;&gt;&lt;/div&gt;#### text_to_image_generation-unidiffuser```pythonimport paddlefrom paddlenlp.trainer import set_seedfrom ppdiffusers import UniDiffuserPipelinemodel_id_or_path = &quot;thu-ml/unidiffuser-v1&quot;pipe = UniDiffuserPipeline.from_pretrained(model_id_or_path, paddle_dtype=paddle.float16)set_seed(42)# Text variation can be performed with a text-to-image generation followed by a image-to-text generation:# 1. Text-to-image generationprompt = &quot;an elephant under the sea&quot;sample = pipe(prompt=prompt, num_inference_steps=20, guidance_scale=8.0)t2i_image = sample.images[0]t2i_image.save(&quot;t2i_image.png&quot;)````&lt;div align=&quot;center&quot;&gt;&lt;img width=&quot;300&quot; alt=&quot;image&quot; src=&quot;https://github.com/PaddlePaddle/PaddleMIX/assets/35400185/a6eb11d2-ad27-4263-8cb4-b0d8dd42b36c&quot;&gt;&lt;/div&gt;#### text_to_image_generation-deepfloyd_if```pythonimport paddlefrom ppdiffusers import DiffusionPipeline, IFPipeline, IFSuperResolutionPipelinefrom ppdiffusers.utils import pd_to_pil# Stage 1: generate imagespipe = IFPipeline.from_pretrained(&quot;DeepFloyd/IF-I-XL-v1.0&quot;, variant=&quot;fp16&quot;, paddle_dtype=paddle.float16)pipe.enable_xformers_memory_efficient_attention()prompt = 'a photo of a kangaroo wearing an orange hoodie and blue sunglasses standing in front of the eiffel tower holding a sign that says &quot;very deep learning&quot;'prompt_embeds, negative_embeds = pipe.encode_prompt(prompt)image = pipe(    prompt_embeds=prompt_embeds,    negative_prompt_embeds=negative_embeds,    output_type=&quot;pd&quot;,).images# save intermediate imagepil_image = pd_to_pil(image)pil_image[0].save(&quot;text_to_image_generation-deepfloyd_if-result-if_stage_I.png&quot;)# save gpu memorypipe.to(paddle_device=&quot;cpu&quot;)# Stage 2: super resolution stage1super_res_1_pipe = IFSuperResolutionPipeline.from_pretrained(    &quot;DeepFloyd/IF-II-L-v1.0&quot;, text_encoder=None, variant=&quot;fp16&quot;, paddle_dtype=paddle.float16)super_res_1_pipe.enable_xformers_memory_efficient_attention()image = super_res_1_pipe(    image=image,    prompt_embeds=prompt_embeds,    negative_prompt_embeds=negative_embeds,    output_type=&quot;pd&quot;,).images# save intermediate imagepil_image = pd_to_pil(image)pil_image[0].save(&quot;text_to_image_generation-deepfloyd_if-result-if_stage_II.png&quot;)# save gpu memorysuper_res_1_pipe.to(paddle_device=&quot;cpu&quot;)```&lt;div align=&quot;center&quot;&gt;&lt;img alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/20476674/246785766-700dfad9-159d-4bfb-bfc7-c18df938a052.png&quot;&gt;&lt;/div&gt;&lt;div align=&quot;center&quot;&gt;&lt;center&gt;if_stage_I&lt;/center&gt;&lt;/div&gt;&lt;div align=&quot;center&quot;&gt;&lt;img alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/20476674/246785773-3359ca5f-dadf-4cc8-b318-ff1f9d4a2d35.png&quot;&gt;&lt;/div&gt;&lt;div align=&quot;center&quot;&gt;&lt;center&gt;if_stage_II&lt;/center&gt;&lt;!-- &lt;img alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/20476674/246785774-8870829a-354b-4a87-9d67-93af315f51e6.png&quot;&gt;&lt;center&gt;if_stage_III&lt;/center&gt; --&gt;&lt;/div&gt;&lt;/details&gt;&lt;details&gt;&lt;summary&gt;&amp;emsp;æ–‡æœ¬å¼•å¯¼çš„å›¾åƒæ”¾å¤§ï¼ˆText-Guided Image Upscalingï¼‰&lt;/summary&gt;#### text_guided_image_upscaling-stable_diffusion_2```pythonfrom ppdiffusers import StableDiffusionUpscalePipelinefrom ppdiffusers.utils import load_imagepipe = StableDiffusionUpscalePipeline.from_pretrained(&quot;stabilityai/stable-diffusion-x4-upscaler&quot;)url = &quot;https://paddlenlp.bj.bcebos.com/models/community/CompVis/data/low_res_cat.png&quot;low_res_img = load_image(url).resize((128, 128))prompt = &quot;a white cat&quot;upscaled_image = pipe(prompt=prompt, image=low_res_img).images[0]upscaled_image.save(&quot;upsampled_cat_sd2.png&quot;)```&lt;div align=&quot;center&quot;&gt;&lt;img alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/20476674/209324085-0d058b70-89b0-43c2-affe-534eedf116cf.png&quot;&gt;&lt;center&gt;åŸå›¾åƒ&lt;/center&gt;&lt;img alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/20476674/209323862-ce2d8658-a52b-4f35-90cb-aa7d310022e7.png&quot;&gt;&lt;center&gt;ç”Ÿæˆå›¾åƒ&lt;/center&gt;&lt;/div&gt;&lt;/details&gt;&lt;details&gt;&lt;summary&gt;&amp;emsp;æ–‡æœ¬å¼•å¯¼çš„å›¾åƒç¼–è¾‘ï¼ˆText-Guided Image Inpaintingï¼‰&lt;/summary&gt;#### text_guided_image_inpainting-stable_diffusion_2```pythonimport paddlefrom ppdiffusers import PaintByExamplePipelinefrom ppdiffusers.utils import load_imageimg_url = &quot;https://paddlenlp.bj.bcebos.com/models/community/Fantasy-Studio/data/image_example_1.png&quot;mask_url = &quot;https://paddlenlp.bj.bcebos.com/models/community/Fantasy-Studio/data/mask_example_1.png&quot;example_url = &quot;https://paddlenlp.bj.bcebos.com/models/community/Fantasy-Studio/data/reference_example_1.jpeg&quot;init_image = load_image(img_url).resize((512, 512))mask_image = load_image(mask_url).resize((512, 512))example_image = load_image(example_url).resize((512, 512))pipe = PaintByExamplePipeline.from_pretrained(&quot;Fantasy-Studio/Paint-by-Example&quot;)# ä½¿ç”¨fp16åŠ å¿«ç”Ÿæˆé€Ÿåº¦with paddle.amp.auto_cast(True):    image = pipe(image=init_image, mask_image=mask_image, example_image=example_image).images[0]image.save(&quot;image_guided_image_inpainting-paint_by_example-result.png&quot;)```&lt;div align=&quot;center&quot;&gt;&lt;img alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/20476674/247118364-5d91f433-f9ac-4514-b5f0-cb4599905847.png&quot; width=300&gt;&lt;center&gt;åŸå›¾åƒ&lt;/center&gt;&lt;div align=&quot;center&quot;&gt;&lt;img alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/20476674/247118361-0f78d6db-6896-4f8d-b1bd-8350192f7a4e.png&quot; width=300&gt;&lt;center&gt;æ©ç å›¾åƒ&lt;/center&gt;&lt;div align=&quot;center&quot;&gt;&lt;img alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/20476674/247118368-305a048d-ddc3-4a5f-8915-58591ef680f0.jpeg&quot; width=300&gt;&lt;center&gt;å‚è€ƒå›¾åƒ&lt;/center&gt;&lt;img alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/20476674/247117963-e5b9b754-39a3-480b-a557-46a2f9310e79.png&quot; width=300&gt;&lt;center&gt;ç”Ÿæˆå›¾åƒ&lt;/center&gt;&lt;/div&gt;&lt;/details&gt;&lt;details&gt;&lt;summary&gt;&amp;emsp;æ–‡æœ¬å¼•å¯¼çš„å›¾åƒå˜æ¢ï¼ˆImage-to-Image Text-Guided Generationï¼‰&lt;/summary&gt;#### text_guided_image_inpainting-kandinsky2_2```pythonimport numpy as npimport paddlefrom ppdiffusers import KandinskyV22InpaintPipeline, KandinskyV22PriorPipelinefrom ppdiffusers.utils import load_imagepipe_prior = KandinskyV22PriorPipeline.from_pretrained(    &quot;kandinsky-community/kandinsky-2-2-prior&quot;, paddle_dtype=paddle.float16)prompt = &quot;a hat&quot;image_emb, zero_image_emb = pipe_prior(prompt, return_dict=False)pipe = KandinskyV22InpaintPipeline.from_pretrained(    &quot;kandinsky-community/kandinsky-2-2-decoder-inpaint&quot;, paddle_dtype=paddle.float16)init_image = load_image(    &quot;https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/kandinsky/cat.png&quot;)mask = np.zeros((768, 768), dtype=np.float32)mask[:250, 250:-250] = 1out = pipe(    image=init_image,    mask_image=mask,    image_embeds=image_emb,    negative_image_embeds=zero_image_emb,    height=768,    width=768,    num_inference_steps=50,)image = out.images[0]image.save(&quot;text_guided_image_inpainting-kandinsky2_2-result-cat_with_hat.png&quot;)```&lt;div align=&quot;center&quot;&gt;&lt;img width=&quot;300&quot; alt=&quot;image&quot; src=&quot;https://github.com/PaddlePaddle/PaddleMIX/assets/35400185/64a943d5-167b-4433-91c3-3cf9279714db&quot;&gt;&lt;center&gt;åŸå›¾åƒ&lt;/center&gt;&lt;img width=&quot;300&quot; alt=&quot;image&quot; src=&quot;https://github.com/PaddlePaddle/PaddleMIX/assets/35400185/f469c127-52f4-4173-a693-c06b92a052aa&quot;&gt;&lt;center&gt;ç”Ÿæˆå›¾åƒ&lt;/center&gt;&lt;/div&gt;#### image_to_image_text_guided_generation-stable_diffusion```pythonimport paddlefrom ppdiffusers import StableDiffusionImg2ImgPipelinefrom ppdiffusers.utils import load_image# åŠ è½½pipelinepipe = StableDiffusionImg2ImgPipeline.from_pretrained(&quot;runwayml/stable-diffusion-v1-5&quot;)# ä¸‹è½½åˆå§‹å›¾ç‰‡url = &quot;https://paddlenlp.bj.bcebos.com/models/community/CompVis/stable-diffusion-v1-4/sketch-mountains-input.png&quot;init_image = load_image(url).resize((768, 512))prompt = &quot;A fantasy landscape, trending on artstation&quot;# ä½¿ç”¨fp16åŠ å¿«ç”Ÿæˆé€Ÿåº¦with paddle.amp.auto_cast(True):    image = pipe(prompt=prompt, image=init_image, strength=0.75, guidance_scale=7.5).images[0]image.save(&quot;fantasy_landscape.png&quot;)```&lt;div align=&quot;center&quot;&gt;&lt;img width=&quot;300&quot; alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/20476674/209327142-d8e1d0c7-3bf8-4a08-a0e8-b11451fc84d8.png&quot;&gt;&lt;center&gt;åŸå›¾åƒ&lt;/center&gt;&lt;img width=&quot;300&quot; alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/20476674/209325799-d9ff279b-0d57-435f-bda7-763e3323be23.png&quot;&gt;&lt;center&gt;ç”Ÿæˆå›¾åƒ&lt;/center&gt;&lt;/div&gt;#### image_to_image_text_guided_generation-stable_diffusion_xl```pythonimport paddlefrom ppdiffusers import StableDiffusionXLImg2ImgPipelinefrom ppdiffusers.utils import load_imagepipe = StableDiffusionXLImg2ImgPipeline.from_pretrained(    &quot;stabilityai/stable-diffusion-xl-refiner-1.0&quot;,    paddle_dtype=paddle.float16,    # from_hf_hub=True,    # from_diffusers=True,    variant=&quot;fp16&quot;)url = &quot;https://paddlenlp.bj.bcebos.com/models/community/westfish/develop-0-19-3/000000009.png&quot;init_image = load_image(url).convert(&quot;RGB&quot;)prompt = &quot;a photo of an astronaut riding a horse on mars&quot;image = pipe(prompt, image=init_image).images[0]image.save('sdxl_image2image.png')```&lt;div align=&quot;center&quot;&gt;&lt;img width=&quot;300&quot; alt=&quot;image&quot; src=&quot;https://github.com/PaddlePaddle/PaddleMIX/assets/35400185/41bd9381-2799-4bed-a5e2-ba312a2f8da9&quot;&gt;&lt;center&gt;åŸå›¾åƒ&lt;/center&gt;&lt;img width=&quot;300&quot; alt=&quot;image&quot; src=&quot;https://github.com/PaddlePaddle/PaddleMIX/assets/35400185/db672d03-2e3a-46ac-97fd-d80cca18dbbe&quot;&gt;&lt;center&gt;ç”Ÿæˆå›¾åƒ&lt;/center&gt;&lt;/div&gt;#### image_to_image_text_guided_generation-kandinsky2_2```pythonimport paddlefrom ppdiffusers import KandinskyV22Img2ImgPipeline, KandinskyV22PriorPipelinefrom ppdiffusers.utils import load_imagepipe_prior = KandinskyV22PriorPipeline.from_pretrained(    &quot;kandinsky-community/kandinsky-2-2-prior&quot;, paddle_dtype=paddle.float16)prompt = &quot;A red cartoon frog, 4k&quot;image_emb, zero_image_emb = pipe_prior(prompt, return_dict=False)pipe = KandinskyV22Img2ImgPipeline.from_pretrained(    &quot;kandinsky-community/kandinsky-2-2-decoder&quot;, paddle_dtype=paddle.float16)init_image = load_image(    &quot;https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main&quot; &quot;/kandinsky/frog.png&quot;)image = pipe(    image=init_image,    image_embeds=image_emb,    negative_image_embeds=zero_image_emb,    height=768,    width=768,    num_inference_steps=100,    strength=0.2,).imagesimage[0].save(&quot;image_to_image_text_guided_generation-kandinsky2_2-result-red_frog.png&quot;)```&lt;div align=&quot;center&quot;&gt;&lt;img width=&quot;300&quot; alt=&quot;image&quot; src=&quot;https://github.com/PaddlePaddle/PaddleMIX/assets/35400185/aae57109-94ad-408e-ae75-8cce650cebe5&quot;&gt;&lt;center&gt;åŸå›¾åƒ&lt;/center&gt;&lt;img width=&quot;300&quot; alt=&quot;image&quot; src=&quot;https://github.com/PaddlePaddle/PaddleMIX/assets/35400185/23cf2c4e-416f-4f21-82a6-e57de11b5e83&quot;&gt;&lt;center&gt;ç”Ÿæˆå›¾åƒ&lt;/center&gt;&lt;/div&gt;&lt;/details&gt;&lt;/details&gt;&lt;details&gt;&lt;summary&gt;&amp;emsp;æ–‡æœ¬å›¾åƒåŒå¼•å¯¼å›¾åƒç”Ÿæˆï¼ˆDual Text and Image Guided Generationï¼‰&lt;/summary&gt;#### dual_text_and_image_guided_generation-versatile_diffusion```pythonfrom ppdiffusers import VersatileDiffusionDualGuidedPipelinefrom ppdiffusers.utils import load_imageurl = &quot;https://paddlenlp.bj.bcebos.com/models/community/CompVis/data/benz.jpg&quot;image = load_image(url)text = &quot;a red car in the sun&quot;pipe = VersatileDiffusionDualGuidedPipeline.from_pretrained(&quot;shi-labs/versatile-diffusion&quot;)pipe.remove_unused_weights()text_to_image_strength = 0.75image = pipe(prompt=text, image=image, text_to_image_strength=text_to_image_strength).images[0]image.save(&quot;versatile-diffusion-red_car.png&quot;)```&lt;div align=&quot;center&quot;&gt;&lt;img width=&quot;300&quot; alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/20476674/209325965-2475e9c4-a524-4970-8498-dfe10ff9cf24.jpg&quot; &gt;&lt;center&gt;åŸå›¾åƒ&lt;/center&gt;&lt;img width=&quot;300&quot; alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/20476674/209325293-049098d0-d591-4abc-b151-9291ac2636da.png&quot;&gt;&lt;center&gt;ç”Ÿæˆå›¾åƒ&lt;/center&gt;&lt;/div&gt;&lt;/details&gt;### æ–‡æœ¬è§†é¢‘å¤šæ¨¡&lt;details open&gt;&lt;summary&gt;&amp;emsp;æ–‡æœ¬æ¡ä»¶çš„è§†é¢‘ç”Ÿæˆï¼ˆText-to-Video Generationï¼‰&lt;/summary&gt;#### text_to_video_generation-lvdm```pythonimport paddlefrom ppdiffusers import LVDMTextToVideoPipeline# åŠ è½½æ¨¡å‹å’Œschedulerpipe = LVDMTextToVideoPipeline.from_pretrained(&quot;westfish/lvdm_text2video_orig_webvid_2m&quot;)# æ‰§è¡Œpipelineè¿›è¡Œæ¨ç†seed = 2013generator = paddle.Generator().manual_seed(seed)samples = pipe(    prompt=&quot;cutting in kitchen&quot;,    num_frames=16,    height=256,    width=256,    num_inference_steps=50,    generator=generator,    guidance_scale=15,    eta=1,    save_dir=&quot;.&quot;,    save_name=&quot;text_to_video_generation-lvdm-result-ddim_lvdm_text_to_video_ucf&quot;,    encoder_type=&quot;2d&quot;,    scale_factor=0.18215,    shift_factor=0,)```&lt;div align=&quot;center&quot;&gt;&lt;img width=&quot;300&quot; alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/20476674/270906907-2b9d53c1-0272-4c7a-81b2-cd962d23bbee.gif&quot;&gt;&lt;/div&gt;#### text_to_video_generation-synth```pythonimport imageiofrom ppdiffusers import DPMSolverMultistepScheduler, TextToVideoSDPipelinepipe = TextToVideoSDPipeline.from_pretrained(&quot;damo-vilab/text-to-video-ms-1.7b&quot;)pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)prompt = &quot;An astronaut riding a horse.&quot;video_frames = pipe(prompt, num_inference_steps=25).framesimageio.mimsave(&quot;text_to_video_generation-synth-result-astronaut_riding_a_horse.mp4&quot;, video_frames, fps=8)```&lt;div align=&quot;center&quot;&gt;&lt;img width=&quot;300&quot; alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/20476674/246780441-8242a955-490b-4326-8415-84264a54a938.gif&quot;&gt;&lt;/div&gt;#### text_to_video_generation-synth with zeroscope_v2_XL```pythonimport imageiofrom ppdiffusers import DPMSolverMultistepScheduler, TextToVideoSDPipeline# from ppdiffusers.utils import export_to_videopipe = TextToVideoSDPipeline.from_pretrained(&quot;cerspense/zeroscope_v2_XL&quot;)pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)prompt = &quot;An astronaut riding a horse.&quot;video_frames = pipe(prompt, num_inference_steps=50, height=320, width=576, num_frames=24).framesimageio.mimsave(&quot;text_to_video_generation-synth-result-astronaut_riding_a_horse.mp4&quot;, video_frames, fps=8)```&lt;div align=&quot;center&quot;&gt;&lt;img width=&quot;300&quot; alt=&quot;image&quot; src=&quot;https://github.com/PaddlePaddle/PaddleMIX/assets/35400185/43ebbca0-9f07-458b-809a-acf296a2539b&quot;&gt;&lt;/div&gt;#### text_to_video_generation-zero```pythonimport imageio# pip install imageio[ffmpeg]import paddlefrom ppdiffusers import TextToVideoZeroPipelinemodel_id = &quot;runwayml/stable-diffusion-v1-5&quot;pipe = TextToVideoZeroPipeline.from_pretrained(model_id, paddle_dtype=paddle.float16)prompt = &quot;A panda is playing guitar on times square&quot;result = pipe(prompt=prompt).imagesresult = [(r * 255).astype(&quot;uint8&quot;) for r in result]imageio.mimsave(&quot;text_to_video_generation-zero-result-panda.mp4&quot;, result, fps=4)```&lt;div align=&quot;center&quot;&gt;&lt;img width=&quot;300&quot; alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/20476674/246779321-c2b0c2b4-e383-40c7-a4d8-f417e8062b35.gif&quot;&gt;&lt;/div&gt;&lt;/details&gt;### æ–‡æœ¬éŸ³é¢‘å¤šæ¨¡&lt;details&gt;&lt;summary&gt;&amp;emsp;æ–‡æœ¬æ¡ä»¶çš„éŸ³é¢‘ç”Ÿæˆï¼ˆText-to-Audio Generationï¼‰&lt;/summary&gt;#### text_to_audio_generation-audio_ldm```pythonimport paddleimport scipyfrom ppdiffusers import AudioLDMPipelinepipe = AudioLDMPipeline.from_pretrained(&quot;cvssp/audioldm&quot;, paddle_dtype=paddle.float16)prompt = &quot;Techno music with a strong, upbeat tempo and high melodic riffs&quot;audio = pipe(prompt, num_inference_steps=10, audio_length_in_s=5.0).audios[0]output_path = &quot;text_to_audio_generation-audio_ldm-techno.wav&quot;# save the audio sample as a .wav filescipy.io.wavfile.write(output_path, rate=16000, data=audio)```&lt;div align = &quot;center&quot;&gt;  &lt;thead&gt;  &lt;/thead&gt;  &lt;tbody&gt;   &lt;tr&gt;      &lt;td align = &quot;center&quot;&gt;      &lt;a href=&quot;https://paddlenlp.bj.bcebos.com/models/community/westfish/develop_ppdiffusers_data/techno.wav&quot; rel=&quot;nofollow&quot;&gt;            &lt;img align=&quot;center&quot; src=&quot;https://user-images.githubusercontent.com/20476674/209344877-edbf1c24-f08d-4e3b-88a4-a27e1fd0a858.png&quot; width=&quot;200 style=&quot;max-width: 100%;&quot;&gt;&lt;/a&gt;&lt;br&gt;      &lt;/td&gt;    &lt;/tr&gt;  &lt;/tbody&gt;&lt;/div&gt;&lt;/details&gt;### å›¾åƒ&lt;details&gt;&lt;summary&gt;&amp;emsp;æ— æ¡ä»¶å›¾åƒç”Ÿæˆï¼ˆUnconditional Image Generationï¼‰&lt;/summary&gt;#### unconditional_image_generation-latent_diffusion_uncond```pythonfrom ppdiffusers import LDMPipeline# åŠ è½½æ¨¡å‹å’Œschedulerpipe = LDMPipeline.from_pretrained(&quot;CompVis/ldm-celebahq-256&quot;)# æ‰§è¡Œpipelineè¿›è¡Œæ¨ç†image = pipe(num_inference_steps=200).images[0]# ä¿å­˜å›¾ç‰‡image.save(&quot;ldm_generated_image.png&quot;)```&lt;div align=&quot;center&quot;&gt;&lt;img width=&quot;300&quot; alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/20476674/209327936-7fe914e0-0ea0-4e21-a433-24eaed6ee94c.png&quot;&gt;&lt;/div&gt;&lt;/details&gt;&lt;details&gt;&lt;summary&gt;&amp;emsp;è¶…åˆ†ï¼ˆSuper Superresolutionï¼‰&lt;/summary&gt;#### super_resolution-latent_diffusion```pythonimport paddlefrom ppdiffusers import LDMSuperResolutionPipelinefrom ppdiffusers.utils import load_image# åŠ è½½pipelinepipe = LDMSuperResolutionPipeline.from_pretrained(&quot;CompVis/ldm-super-resolution-4x-openimages&quot;)# ä¸‹è½½åˆå§‹å›¾ç‰‡url = &quot;https://paddlenlp.bj.bcebos.com/models/community/CompVis/stable-diffusion-v1-4/overture-creations.png&quot;init_image = load_image(url).resize((128, 128))init_image.save(&quot;original-image.png&quot;)# ä½¿ç”¨fp16åŠ å¿«ç”Ÿæˆé€Ÿåº¦with paddle.amp.auto_cast(True):    image = pipe(init_image, num_inference_steps=100, eta=1).images[0]image.save(&quot;super-resolution-image.png&quot;)```&lt;div align=&quot;center&quot;&gt;&lt;img  alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/20476674/209328660-9700fdc3-72b3-43bd-9a00-23b370ba030b.png&quot;&gt;&lt;center&gt;åŸå›¾åƒ&lt;/center&gt;&lt;img  alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/20476674/209328479-4eaea5d8-aa4a-4f31-aa2a-b47e3c730f15.png&quot;&gt;&lt;center&gt;ç”Ÿæˆå›¾åƒ&lt;/center&gt;&lt;/div&gt;&lt;/details&gt;&lt;details&gt;&lt;summary&gt;&amp;emsp;å›¾åƒç¼–è¾‘ï¼ˆImage Inpaintingï¼‰&lt;/summary&gt;#### image_inpainting-repaint```pythonfrom ppdiffusers import RePaintPipeline, RePaintSchedulerfrom ppdiffusers.utils import load_imageimg_url = &quot;https://paddlenlp.bj.bcebos.com/models/community/CompVis/data/celeba_hq_256.png&quot;mask_url = &quot;https://paddlenlp.bj.bcebos.com/models/community/CompVis/data/mask_256.png&quot;# Load the original image and the mask as PIL imagesoriginal_image = load_image(img_url).resize((256, 256))mask_image = load_image(mask_url).resize((256, 256))scheduler = RePaintScheduler.from_pretrained(&quot;google/ddpm-ema-celebahq-256&quot;, subfolder=&quot;scheduler&quot;)pipe = RePaintPipeline.from_pretrained(&quot;google/ddpm-ema-celebahq-256&quot;, scheduler=scheduler)output = pipe(    original_image=original_image,    mask_image=mask_image,    num_inference_steps=250,    eta=0.0,    jump_length=10,    jump_n_sample=10,)inpainted_image = output.images[0]inpainted_image.save(&quot;repaint-image.png&quot;)```&lt;div align=&quot;center&quot;&gt;&lt;img  alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/20476674/209329052-b6fc2aaf-1a59-49a3-92ef-60180fdffd81.png&quot;&gt;&lt;center&gt;åŸå›¾åƒ&lt;/center&gt;&lt;img  alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/20476674/209329048-4fe12176-32a0-4800-98f2-49bd8d593799.png&quot;&gt;&lt;center&gt;maskå›¾åƒ&lt;/center&gt;&lt;img  alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/20476674/209329241-b7e4d99e-468a-4b95-8829-d77ee14bfe98.png&quot;&gt;&lt;center&gt;ç”Ÿæˆå›¾åƒ&lt;/center&gt;&lt;/div&gt;&lt;/details&gt;&lt;details&gt;&lt;summary&gt;&amp;emsp;å›¾åƒå˜åŒ–ï¼ˆImage Variationï¼‰&lt;/summary&gt;#### image_variation-versatile_diffusion```pythonfrom ppdiffusers import VersatileDiffusionImageVariationPipelinefrom ppdiffusers.utils import load_imageurl = &quot;https://paddlenlp.bj.bcebos.com/models/community/CompVis/data/benz.jpg&quot;image = load_image(url)pipe = VersatileDiffusionImageVariationPipeline.from_pretrained(&quot;shi-labs/versatile-diffusion&quot;)image = pipe(image).images[0]image.save(&quot;versatile-diffusion-car_variation.png&quot;)```&lt;div align=&quot;center&quot;&gt;&lt;img  width=&quot;300&quot; alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/20476674/209331434-51f6cdbd-b8e4-4faa-8e49-1cc852e35603.jpg&quot;&gt;&lt;center&gt;åŸå›¾åƒ&lt;/center&gt;&lt;img  width=&quot;300&quot; alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/20476674/209331591-f6cc4cd8-8430-4627-8d22-bf404fb2bfdd.png&quot;&gt;&lt;center&gt;ç”Ÿæˆå›¾åƒ&lt;/center&gt;&lt;/div&gt;&lt;/details&gt;### éŸ³é¢‘&lt;details&gt;&lt;summary&gt;&amp;emsp;æ— æ¡ä»¶éŸ³é¢‘ç”Ÿæˆï¼ˆUnconditional Audio Generationï¼‰&lt;/summary&gt;#### unconditional_audio_generation-audio_diffusion```pythonfrom scipy.io.wavfile import writefrom ppdiffusers import AudioDiffusionPipelineimport paddle# åŠ è½½æ¨¡å‹å’Œschedulerpipe = AudioDiffusionPipeline.from_pretrained(&quot;teticio/audio-diffusion-ddim-256&quot;)pipe.set_progress_bar_config(disable=None)generator = paddle.Generator().manual_seed(42)output = pipe(generator=generator)audio = output.audios[0]image = output.images[0]# ä¿å­˜éŸ³é¢‘åˆ°æœ¬åœ°for i, audio in enumerate(audio):    write(f&quot;audio_diffusion_test{i}.wav&quot;, pipe.mel.sample_rate, audio.transpose())# ä¿å­˜å›¾ç‰‡image.save(&quot;audio_diffusion_test.png&quot;)```&lt;div align = &quot;center&quot;&gt;  &lt;thead&gt;  &lt;/thead&gt;  &lt;tbody&gt;   &lt;tr&gt;      &lt;td align = &quot;center&quot;&gt;      &lt;a href=&quot;https://paddlenlp.bj.bcebos.com/models/community/teticio/data/audio_diffusion_test0.wav&quot; rel=&quot;nofollow&quot;&gt;            &lt;img align=&quot;center&quot; src=&quot;https://user-images.githubusercontent.com/20476674/209344877-edbf1c24-f08d-4e3b-88a4-a27e1fd0a858.png&quot; width=&quot;200 style=&quot;max-width: 100%;&quot;&gt;&lt;/a&gt;&lt;br&gt;      &lt;/td&gt;    &lt;/tr&gt;  &lt;/tbody&gt;&lt;/div&gt;&lt;div align=&quot;center&quot;&gt;&lt;img  width=&quot;300&quot; alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/20476674/209342125-93e8715e-895b-4115-9e1e-e65c6c2cd95a.png&quot;&gt;&lt;/div&gt;#### unconditional_audio_generation-spectrogram_diffusion```pythonimport paddleimport scipyfrom ppdiffusers import MidiProcessor, SpectrogramDiffusionPipelinefrom ppdiffusers.utils.download_utils import ppdiffusers_url_download# Download MIDI from: wget https://paddlenlp.bj.bcebos.com/models/community/junnyu/develop/beethoven_hammerklavier_2.midmid_file_path = ppdiffusers_url_download(    &quot;https://paddlenlp.bj.bcebos.com/models/community/junnyu/develop/beethoven_hammerklavier_2.mid&quot;, cache_dir=&quot;.&quot;)pipe = SpectrogramDiffusionPipeline.from_pretrained(&quot;google/music-spectrogram-diffusion&quot;, paddle_dtype=paddle.float16)processor = MidiProcessor()output = pipe(processor(mid_file_path))audio = output.audios[0]output_path = &quot;unconditional_audio_generation-spectrogram_diffusion-result-beethoven_hammerklavier_2.wav&quot;# save the audio sample as a .wav filescipy.io.wavfile.write(output_path, rate=16000, data=audio)```&lt;div align = &quot;center&quot;&gt;  &lt;thead&gt;  &lt;/thead&gt;  &lt;tbody&gt;   &lt;tr&gt;      &lt;td align = &quot;center&quot;&gt;      &lt;a href=&quot;https://paddlenlp.bj.bcebos.com/models/community/westfish/develop_ppdiffusers_data/beethoven_hammerklavier_2.wav&quot; rel=&quot;nofollow&quot;&gt;            &lt;img align=&quot;center&quot; src=&quot;https://user-images.githubusercontent.com/20476674/209344877-edbf1c24-f08d-4e3b-88a4-a27e1fd0a858.png&quot; width=&quot;200 style=&quot;max-width: 100%;&quot;&gt;&lt;/a&gt;&lt;br&gt;      &lt;/td&gt;    &lt;/tr&gt;  &lt;/tbody&gt;&lt;/div&gt;&lt;/details&gt;## å®‰è£…### ç¯å¢ƒä¾èµ–```pip install -r requirements.txt```å…³äºPaddlePaddleå®‰è£…çš„è¯¦ç»†æ•™ç¨‹è¯·æŸ¥çœ‹[Installation](https://www.paddlepaddle.org.cn/install/quick?docurl=/documentation/docs/zh/develop/install/pip/linux-pip.html)ã€‚### pipå®‰è£…```shellpip install --upgrade ppdiffusers```### æ‰‹åŠ¨å®‰è£…```shellgit clone https://github.com/PaddlePaddle/PaddleMIX# æ³¨æ„ï¼šå¦‚æœcloneä»“åº“éå¸¸æ…¢çš„è¯ï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨é•œåƒç‰ˆæœ¬# git clone https://gitee.com/paddlepaddle/PaddleMIXcd PaddleMIX/ppdiffuserspython setup.py install```## å¿«é€Ÿå¼€å§‹æˆ‘ä»¬å°†ä»¥æ‰©æ•£æ¨¡å‹çš„å…¸å‹ä»£è¡¨**Stable Diffusion**ä¸ºä¾‹ï¼Œå¸¦ä½ å¿«é€Ÿäº†è§£PPDiffusersã€‚**Stable Diffusion**åŸºäº**æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLatent Diffusion Modelsï¼‰**ï¼Œä¸“é—¨ç”¨äº**æ–‡å›¾ç”Ÿæˆï¼ˆText-to-Image Generationï¼‰ä»»åŠ¡**ã€‚è¯¥æ¨¡å‹æ˜¯ç”±æ¥è‡ª [CompVis](https://github.com/CompVis), [Stability AI](https://stability.ai/), [LAION](https://laion.ai/)ä»¥åŠ[RunwayML](https://runwayml.com/)çš„å·¥ç¨‹å¸ˆå…±åŒå¼€å‘å®Œæˆï¼Œç›®å‰å‘å¸ƒäº†v1å’Œv2ä¸¤ä¸ªç‰ˆæœ¬ã€‚v1ç‰ˆæœ¬é‡‡ç”¨äº†LAION-5Bæ•°æ®é›†å­é›†ï¼ˆåˆ†è¾¨ç‡ä¸º 512x512ï¼‰è¿›è¡Œè®­ç»ƒï¼Œå¹¶å…·æœ‰ä»¥ä¸‹æ¶æ„è®¾ç½®ï¼šè‡ªåŠ¨ç¼–ç å™¨ä¸‹é‡‡æ ·å› å­ä¸º8ï¼ŒUNetå¤§å°ä¸º860Mï¼Œæ–‡æœ¬ç¼–ç å™¨ä¸ºCLIP ViT-L/14ã€‚v2ç‰ˆæœ¬ç›¸è¾ƒäºv1ç‰ˆæœ¬åœ¨ç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œåˆ†è¾¨ç‡ç­‰è¿›è¡Œäº†æ”¹å–„ã€‚### Stable Diffusioné‡ç‚¹æ¨¡å‹æƒé‡&lt;details&gt;&lt;summary&gt;&amp;emsp; Stable Diffusion æ¨¡å‹æ”¯æŒçš„æƒé‡ï¼ˆè‹±æ–‡ï¼‰ &lt;/summary&gt;**æˆ‘ä»¬åªéœ€è¦å°†ä¸‹é¢çš„&quot;xxxx&quot;ï¼Œæ›¿æ¢æˆæ‰€éœ€çš„æƒé‡åï¼Œå³å¯å¿«é€Ÿä½¿ç”¨ï¼**```pythonfrom ppdiffusers import *pipe_text2img = StableDiffusionPipeline.from_pretrained(&quot;xxxx&quot;)pipe_img2img = StableDiffusionImg2ImgPipeline.from_pretrained(&quot;xxxx&quot;)pipe_inpaint_legacy = StableDiffusionInpaintPipelineLegacy.from_pretrained(&quot;xxxx&quot;)pipe_mega = StableDiffusionMegaPipeline.from_pretrained(&quot;xxxx&quot;)# pipe_mega.text2img() ç­‰äº pipe_text2img()# pipe_mega.img2img() ç­‰äº pipe_img2img()# pipe_mega.inpaint_legacy() ç­‰äº pipe_inpaint_legacy()```| PPDiffusersæ”¯æŒçš„æ¨¡å‹åç§°                     | æ”¯æŒåŠ è½½çš„Pipeline                                    | å¤‡æ³¨ | huggingface.coåœ°å€ || :-------------------------------------------: | :--------------------------------------------------------------------: | --- | :-----------------------------------------: || CompVis/stable-diffusion-v1-4           | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | Stable-Diffusion-v1-4 ä½¿ç”¨ Stable-Diffusion-v1-2 çš„æƒé‡è¿›è¡Œåˆå§‹åŒ–ã€‚éšååœ¨&quot;laion-aesthetics v2 5+&quot;æ•°æ®é›†ä¸Šä»¥ **512x512** åˆ†è¾¨ç‡å¾®è°ƒäº† **225k** æ­¥æ•°ï¼Œå¯¹æ–‡æœ¬ä½¿ç”¨äº† **10%** çš„dropoutï¼ˆå³ï¼šè®­ç»ƒè¿‡ç¨‹ä¸­æ–‡å›¾å¯¹ä¸­çš„æ–‡æœ¬æœ‰ 10% çš„æ¦‚ç‡ä¼šå˜æˆç©ºæ–‡æœ¬ï¼‰ã€‚æ¨¡å‹ä½¿ç”¨äº†[CLIP ViT-L/14](https://huggingface.co/openai/clip-vit-large-patch14)ä½œä¸ºæ–‡æœ¬ç¼–ç å™¨ã€‚| [åœ°å€](https://huggingface.co/CompVis/stable-diffusion-v1-4) || CompVis/ldm-text2im-large-256               | LDMTextToImagePipeline | [LDMè®ºæ–‡](https://arxiv.org/pdf/2112.10752.pdf) LDM-KL-8-G* æƒé‡ã€‚| [åœ°å€](https://huggingface.co/CompVis/ldm-text2im-large-256) || CompVis/ldm-super-resolution-4x-openimages  | LDMSuperResolutionPipeline | [LDMè®ºæ–‡](https://arxiv.org/pdf/2112.10752.pdf) LDM-VQ-4 æƒé‡ï¼Œ[åŸå§‹æƒé‡é“¾æ¥](https://ommer-lab.com/files/latent-diffusion/sr_bsr.zip)ã€‚| [åœ°å€](https://huggingface.co/CompVis/ldm-super-resolution-4x-openimages) || runwayml/stable-diffusion-v1-5              | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | Stable-Diffusion-v1-5 ä½¿ç”¨ Stable-Diffusion-v1-2 çš„æƒé‡è¿›è¡Œåˆå§‹åŒ–ã€‚éšååœ¨&quot;laion-aesthetics v2 5+&quot;æ•°æ®é›†ä¸Šä»¥ **512x512** åˆ†è¾¨ç‡å¾®è°ƒäº† **595k** æ­¥æ•°ï¼Œå¯¹æ–‡æœ¬ä½¿ç”¨äº† **10%** çš„dropoutï¼ˆå³ï¼šè®­ç»ƒè¿‡ç¨‹ä¸­æ–‡å›¾å¯¹ä¸­çš„æ–‡æœ¬æœ‰ 10% çš„æ¦‚ç‡ä¼šå˜æˆç©ºæ–‡æœ¬ï¼‰ã€‚æ¨¡å‹åŒæ ·ä¹Ÿä½¿ç”¨äº†[CLIP ViT-L/14](https://huggingface.co/openai/clip-vit-large-patch14)ä½œä¸ºæ–‡æœ¬ç¼–ç å™¨ã€‚| [åœ°å€](https://huggingface.co/runwayml/stable-diffusion-v1-5) || runwayml/stable-diffusion-inpainting        | StableDiffusionInpaintPipeline | Stable-Diffusion-Inpainting ä½¿ç”¨ Stable-Diffusion-v1-2 çš„æƒé‡è¿›è¡Œåˆå§‹åŒ–ã€‚é¦–å…ˆè¿›è¡Œäº† **595k** æ­¥çš„å¸¸è§„è®­ç»ƒï¼ˆå®é™…ä¹Ÿå°±æ˜¯ Stable-Diffusion-v1-5 çš„æƒé‡ï¼‰ï¼Œç„¶åè¿›è¡Œäº† **440k** æ­¥çš„ inpainting ä¿®å¤è®­ç»ƒã€‚å¯¹äº inpainting ä¿®å¤è®­ç»ƒï¼Œç»™ UNet é¢å¤–å¢åŠ äº† **5** è¾“å…¥é€šé“ï¼ˆå…¶ä¸­ **4** ä¸ªç”¨äºè¢« Mask é®ç›–ä½çš„å›¾ç‰‡ï¼Œ**1** ä¸ªç”¨äº Mask æœ¬èº«ï¼‰ã€‚åœ¨è®­ç»ƒæœŸé—´ï¼Œä¼šéšæœºç”Ÿæˆ Maskï¼Œå¹¶æœ‰ **25%** æ¦‚ç‡ä¼šå°†åŸå§‹å›¾ç‰‡å…¨éƒ¨ Mask æ‰ã€‚| [åœ°å€](https://huggingface.co/runwayml/stable-diffusion-inpainting) || stabilityai/stable-diffusion-2-base         | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | è¯¥æ¨¡å‹é¦–å…ˆåœ¨ [LAION-5B 256x256 å­é›†ä¸Š](https://laion.ai/blog/laion-5b/) ï¼ˆè¿‡æ»¤æ¡ä»¶ï¼š[punsafe = 0.1 çš„ LAION-NSFW åˆ†ç±»å™¨](https://github.com/LAION-AI/CLIP-based-NSFW-Detector) å’Œ å®¡ç¾åˆ†æ•°å¤§äºç­‰äº 4.5 ï¼‰ä»å¤´å¼€å§‹è®­ç»ƒ **550k** æ­¥ï¼Œç„¶ååˆåœ¨åˆ†è¾¨ç‡ **&gt;= 512x512** çš„åŒä¸€æ•°æ®é›†ä¸Šè¿›ä¸€æ­¥è®­ç»ƒ **850k** æ­¥ã€‚| [åœ°å€](https://huggingface.co/stabilityai/stable-diffusion-2-base) || stabilityai/stable-diffusion-2              | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | stable-diffusion-2 ä½¿ç”¨ stable-diffusion-2-base æƒé‡è¿›è¡Œåˆå§‹åŒ–ï¼Œé¦–å…ˆåœ¨åŒä¸€æ•°æ®é›†ä¸Šï¼ˆ**512x512** åˆ†è¾¨ç‡ï¼‰ä½¿ç”¨ [v-objective](https://arxiv.org/abs/2202.00512) è®­ç»ƒäº† **150k** æ­¥ã€‚ç„¶ååˆåœ¨ **768x768** åˆ†è¾¨ç‡ä¸Šä½¿ç”¨ [v-objective](https://arxiv.org/abs/2202.00512) ç»§ç»­è®­ç»ƒäº† **140k** æ­¥ã€‚| [åœ°å€](https://huggingface.co/stabilityai/stable-diffusion-2) || stabilityai/stable-diffusion-2-inpainting   | StableDiffusionInpaintPipeline |stable-diffusion-2-inpainting ä½¿ç”¨ stable-diffusion-2-base æƒé‡åˆå§‹åŒ–ï¼Œå¹¶ä¸”é¢å¤–è®­ç»ƒäº† **200k** æ­¥ã€‚è®­ç»ƒè¿‡ç¨‹ä½¿ç”¨äº† [LAMA](https://github.com/saic-mdal/lama) ä¸­æå‡ºçš„ Mask ç”Ÿæˆç­–ç•¥ï¼Œå¹¶ä¸”ä½¿ç”¨ Mask å›¾ç‰‡çš„ Latent è¡¨ç¤ºï¼ˆç»è¿‡ VAE ç¼–ç ï¼‰ä½œä¸ºé™„åŠ æ¡ä»¶ã€‚| [åœ°å€](https://huggingface.co/stabilityai/stable-diffusion-2-inpainting) || stabilityai/stable-diffusion-x4-upscaler    | StableDiffusionUpscalePipeline | è¯¥æ¨¡å‹åœ¨**LAION 10M** å­é›†ä¸Šï¼ˆ&gt;2048x2048ï¼‰è®­ç»ƒäº† 1.25M æ­¥ã€‚è¯¥æ¨¡å‹è¿˜åœ¨åˆ†è¾¨ç‡ä¸º **512x512** çš„å›¾åƒä¸Šä½¿ç”¨ [Text-guided Latent Upscaling Diffusion Model](https://arxiv.org/abs/2112.10752) è¿›è¡Œäº†è®­ç»ƒã€‚é™¤äº†**æ–‡æœ¬è¾“å…¥**ä¹‹å¤–ï¼Œå®ƒè¿˜æ¥æ”¶ **noise_level** ä½œä¸ºè¾“å…¥å‚æ•°ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ [é¢„å®šä¹‰çš„ Scheduler](https://huggingface.co/stabilityai/stable-diffusion-x4-upscaler/blob/main/low_res_scheduler/scheduler_config.json) å‘ä½åˆ†è¾¨ç‡çš„è¾“å…¥å›¾ç‰‡æ·»åŠ å™ªå£°ã€‚| [åœ°å€](https://huggingface.co/stabilityai/stable-diffusion-x4-upscaler) || hakurei/waifu-diffusion    | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | waifu-diffusion-v1-2 ä½¿ç”¨ stable-diffusion-v1-4 æƒé‡åˆå§‹åŒ–ï¼Œå¹¶ä¸”åœ¨**é«˜è´¨é‡åŠ¨æ¼«**å›¾åƒæ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒåå¾—åˆ°çš„æ¨¡å‹ã€‚ç”¨äºå¾®è°ƒçš„æ•°æ®æ˜¯ **680k** æ–‡æœ¬å›¾åƒæ ·æœ¬ï¼Œè¿™äº›æ ·æœ¬æ˜¯é€šè¿‡ **booru ç½‘ç«™** ä¸‹è½½çš„ã€‚| [åœ°å€](https://huggingface.co/hakurei/waifu-diffusion) || hakurei/waifu-diffusion-v1-3    | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | waifu-diffusion-v1-3 æ˜¯ waifu-diffusion-v1-2 åŸºç¡€ä¸Šè¿›ä¸€æ­¥è®­ç»ƒå¾—åˆ°çš„ã€‚ä»–ä»¬å¯¹æ•°æ®é›†è¿›è¡Œäº†é¢å¤–æ“ä½œï¼šï¼ˆ1ï¼‰åˆ é™¤ä¸‹åˆ’çº¿ï¼›ï¼ˆ2ï¼‰åˆ é™¤æ‹¬å·ï¼›ï¼ˆ3ï¼‰ç”¨é€—å·åˆ†éš”æ¯ä¸ªbooru æ ‡ç­¾ï¼›ï¼ˆ4ï¼‰éšæœºåŒ–æ ‡ç­¾é¡ºåºã€‚| [åœ°å€](https://huggingface.co/hakurei/waifu-diffusion) || naclbit/trinart_stable_diffusion_v2_60k    | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | trinart_stable_diffusion ä½¿ç”¨ stable-diffusion-v1-4 æƒé‡åˆå§‹åŒ–ï¼Œåœ¨ 40k **é«˜åˆ†è¾¨ç‡æ¼«ç”»/åŠ¨æ¼«é£æ ¼**çš„å›¾ç‰‡æ•°æ®é›†ä¸Šå¾®è°ƒäº† 8 ä¸ª epochã€‚V2 ç‰ˆæ¨¡å‹ä½¿ç”¨ **dropouts**ã€**10k+ å›¾åƒ**å’Œ**æ–°çš„æ ‡è®°ç­–ç•¥**è®­ç»ƒäº†**æ›´é•¿æ—¶é—´**ã€‚| [åœ°å€](https://huggingface.co/naclbit/trinart_stable_diffusion_v2) || naclbit/trinart_stable_diffusion_v2_95k    | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | **95k** æ­¥æ•°çš„ç»“æœï¼Œå…¶ä»–åŒä¸Šã€‚| [åœ°å€](https://huggingface.co/naclbit/trinart_stable_diffusion_v2) || naclbit/trinart_stable_diffusion_v2_115k    | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | **115k** æ­¥æ•°çš„ç»“æœï¼Œå…¶ä»–åŒä¸Šã€‚| [åœ°å€](https://huggingface.co/naclbit/trinart_stable_diffusion_v2) || Deltaadams/Hentai-Diffusion    | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | None| [åœ°å€](https://huggingface.co/Deltaadams/Hentai-Diffusion) || ringhyacinth/nail-set-diffuser    | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | ç¾ç”²é¢†åŸŸçš„æ‰©æ•£æ¨¡å‹ï¼Œè®­ç»ƒæ•°æ®ä½¿ç”¨äº† [Weekend](https://weibo.com/u/5982308498)| [åœ°å€](https://huggingface.co/ringhyacinth/nail-set-diffuser) || Linaqruf/anything-v3.0    | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | è¯¥æ¨¡å‹å¯é€šè¿‡è¾“å…¥å‡ ä¸ªæ–‡æœ¬æç¤ºè¯å°±èƒ½ç”Ÿæˆ**é«˜è´¨é‡ã€é«˜åº¦è¯¦ç»†çš„åŠ¨æ¼«é£æ ¼å›¾ç‰‡**ï¼Œè¯¥æ¨¡å‹æ”¯æŒä½¿ç”¨ **danbooru æ ‡ç­¾æ–‡æœ¬** ç”Ÿæˆå›¾åƒã€‚| [åœ°å€](https://huggingface.co/Linaqruf/anything-v3.0) |&lt;/details&gt;&lt;details&gt;&lt;summary&gt;&amp;emsp; Stable Diffusion æ¨¡å‹æ”¯æŒçš„æƒé‡ï¼ˆä¸­æ–‡å’Œå¤šè¯­è¨€ï¼‰ &lt;/summary&gt;| PPDiffusersæ”¯æŒçš„æ¨¡å‹åç§°                     | æ”¯æŒåŠ è½½çš„Pipeline                                    | å¤‡æ³¨ | huggingface.coåœ°å€ || :-------------------------------------------: | :--------------------------------------------------------------------: | --- | :-----------------------------------------: || BAAI/AltDiffusion                           | AltDiffusionPipelineã€AltDiffusionImg2ImgPipeline | è¯¥æ¨¡å‹ä½¿ç”¨ [AltCLIP](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/AltCLIP/README.md) ä½œä¸ºæ–‡æœ¬ç¼–ç å™¨ï¼Œåœ¨ Stable Diffusion åŸºç¡€ä¸Šè®­ç»ƒäº†**åŒè¯­Diffusionæ¨¡å‹**ï¼Œå…¶ä¸­è®­ç»ƒæ•°æ®æ¥è‡ª [WuDaoæ•°æ®é›†](https://data.baai.ac.cn/details/WuDaoCorporaText) å’Œ [LAION](https://huggingface.co/datasets/ChristophSchuhmann/improved_aesthetics_6plus) ã€‚| [åœ°å€](https://huggingface.co/BAAI/AltDiffusion) || BAAI/AltDiffusion-m9                        | AltDiffusionPipelineã€AltDiffusionImg2ImgPipeline |è¯¥æ¨¡å‹ä½¿ç”¨9ç§è¯­è¨€çš„ [AltCLIP-m9](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/AltCLIP/README.md) ä½œä¸ºæ–‡æœ¬ç¼–ç å™¨ï¼Œå…¶ä»–åŒä¸Šã€‚| [åœ°å€](https://huggingface.co/BAAI/AltDiffusion-m9) || IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-v0.1 | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | ä»–ä»¬å°† [Noah-Wukong](https://wukong-dataset.github.io/wukong-dataset/) æ•°æ®é›† (100M) å’Œ [Zero](https://zero.so.com/) æ•°æ®é›† (23M) ç”¨ä½œé¢„è®­ç»ƒçš„æ•°æ®é›†ï¼Œå…ˆç”¨ [IDEA-CCNL/Taiyi-CLIP-RoBERTa-102M-ViT-L-Chinese](https://huggingface.co/IDEA-CCNL/Taiyi-CLIP-RoBERTa-102M-ViT-L-Chinese) å¯¹è¿™ä¸¤ä¸ªæ•°æ®é›†çš„å›¾æ–‡å¯¹ç›¸ä¼¼æ€§è¿›è¡Œæ‰“åˆ†ï¼Œå– CLIP Score å¤§äº 0.2 çš„å›¾æ–‡å¯¹ä½œä¸ºè®­ç»ƒé›†ã€‚ ä»–ä»¬ä½¿ç”¨ [IDEA-CCNL/Taiyi-CLIP-RoBERTa-102M-ViT-L-Chinese](https://huggingface.co/IDEA-CCNL/Taiyi-CLIP-RoBERTa-102M-ViT-L-Chinese) ä½œä¸ºåˆå§‹åŒ–çš„text encoderï¼Œå†»ä½ [stable-diffusion-v1-4](https://huggingface.co/CompVis/stable-diffusion-v1-4) ([è®ºæ–‡](https://arxiv.org/abs/2112.10752)) æ¨¡å‹çš„å…¶ä»–éƒ¨åˆ†ï¼Œåªè®­ç»ƒ text encoderï¼Œä»¥ä¾¿ä¿ç•™åŸå§‹æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ä¸”å®ç°ä¸­æ–‡æ¦‚å¿µçš„å¯¹é½ã€‚è¯¥æ¨¡å‹ç›®å‰åœ¨0.2äº¿å›¾æ–‡å¯¹ä¸Šè®­ç»ƒäº†ä¸€ä¸ª epochã€‚ åœ¨ 32 x A100 ä¸Šè®­ç»ƒäº†å¤§çº¦100å°æ—¶ï¼Œè¯¥ç‰ˆæœ¬åªæ˜¯ä¸€ä¸ªåˆæ­¥çš„ç‰ˆæœ¬ã€‚| [åœ°å€](https://huggingface.co/IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-v0.1) || IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-EN-v0.1 | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | ä»–ä»¬å°† [Noah-Wukong](https://wukong-dataset.github.io/wukong-dataset/) æ•°æ®é›† (100M) å’Œ [Zero](https://zero.so.com/) æ•°æ®é›† (23M) ç”¨ä½œé¢„è®­ç»ƒçš„æ•°æ®é›†ï¼Œå…ˆç”¨ [IDEA-CCNL/Taiyi-CLIP-RoBERTa-102M-ViT-L-Chinese](https://huggingface.co/IDEA-CCNL/Taiyi-CLIP-RoBERTa-102M-ViT-L-Chinese) å¯¹è¿™ä¸¤ä¸ªæ•°æ®é›†çš„å›¾æ–‡å¯¹ç›¸ä¼¼æ€§è¿›è¡Œæ‰“åˆ†ï¼Œå– CLIP Score å¤§äº 0.2 çš„å›¾æ–‡å¯¹ä½œä¸ºè®­ç»ƒé›†ã€‚ ä»–ä»¬ä½¿ç”¨ [stable-diffusion-v1-4](https://huggingface.co/CompVis/stable-diffusion-v1-4) ([è®ºæ–‡](https://arxiv.org/abs/2112.10752)) æ¨¡å‹è¿›è¡Œç»§ç»­è®­ç»ƒï¼Œå…¶ä¸­è®­ç»ƒåˆ†ä¸º**ä¸¤ä¸ªstage**ã€‚**ç¬¬ä¸€ä¸ªstage** ä¸­å†»ä½æ¨¡å‹çš„å…¶ä»–éƒ¨åˆ†ï¼Œåªè®­ç»ƒ text encoder ï¼Œä»¥ä¾¿ä¿ç•™åŸå§‹æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ä¸”å®ç°ä¸­æ–‡æ¦‚å¿µçš„å¯¹é½ã€‚**ç¬¬äºŒä¸ªstage** ä¸­å°†å…¨éƒ¨æ¨¡å‹è§£å†»ï¼Œä¸€èµ·è®­ç»ƒ text encoder å’Œ diffusion model ï¼Œä»¥ä¾¿ diffusion model æ›´å¥½çš„é€‚é…ä¸­æ–‡å¼•å¯¼ã€‚ç¬¬ä¸€ä¸ª stage ä»–ä»¬è®­ç»ƒäº† 80 å°æ—¶ï¼Œç¬¬äºŒä¸ª stage è®­ç»ƒäº† 100 å°æ—¶ï¼Œä¸¤ä¸ªstageéƒ½æ˜¯ç”¨äº†8 x A100ï¼Œè¯¥ç‰ˆæœ¬æ˜¯ä¸€ä¸ªåˆæ­¥çš„ç‰ˆæœ¬ã€‚| [åœ°å€](https://huggingface.co/IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-EN-v0.1) |&lt;/details&gt;### åŠ è½½HF Diffusersæƒé‡```pythonfrom ppdiffusers import StableDiffusionPipeline# è®¾ç½®from_hf_hubä¸ºTrueï¼Œè¡¨ç¤ºä»huggingface hubä¸‹è½½ï¼Œfrom_diffusersä¸ºTrueè¡¨ç¤ºåŠ è½½çš„æ˜¯diffusersç‰ˆPytorchæƒé‡pipe = StableDiffusionPipeline.from_pretrained(&quot;stabilityai/stable-diffusion-2&quot;, from_hf_hub=True, from_diffusers=True)```### åŠ è½½åŸåº“çš„Lightningæƒé‡```pythonfrom ppdiffusers import StableDiffusionPipeline# å¯è¾“å…¥ç½‘å€ æˆ– æœ¬åœ°ckptã€safetensorsæ–‡ä»¶pipe = StableDiffusionPipeline.from_pretrained_original_ckpt(&quot;https://paddlenlp.bj.bcebos.com/models/community/junnyu/develop/ppdiffusers/chilloutmix_NiPrunedFp32Fix.safetensors&quot;)```### åŠ è½½HF LoRAæƒé‡```pythonfrom ppdiffusers import DiffusionPipelinepipe = DiffusionPipeline.from_pretrained(&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;, paddle_dtype=paddle.float16)pipe.load_lora_weights(&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;,    weight_name=&quot;sd_xl_offset_example-lora_1.0.safetensors&quot;,    from_diffusers=True)```### åŠ è½½Civitaiç¤¾åŒºçš„LoRAæƒé‡```pythonfrom ppdiffusers import StableDiffusionPipelinepipe = StableDiffusionPipeline.from_pretrained(&quot;TASUKU2023/Chilloutmix&quot;)# åŠ è½½loraæƒé‡pipe.apply_lora(&quot;https://paddlenlp.bj.bcebos.com/models/community/junnyu/develop/ppdiffusers/Moxin_10.safetensors&quot;)```### XFormersåŠ é€Ÿä¸ºäº†ä½¿ç”¨**XFormersåŠ é€Ÿ**ï¼Œæˆ‘ä»¬éœ€è¦å®‰è£…`develop`ç‰ˆæœ¬çš„`paddle`ï¼ŒLinuxç³»ç»Ÿçš„å®‰è£…å‘½ä»¤å¦‚ä¸‹ï¼š```shpython -m pip install paddlepaddle-gpu==0.0.0.post117 -f https://www.paddlepaddle.org.cn/whl/linux/gpu/develop.html``````pythonimport paddlefrom ppdiffusers import StableDiffusionPipelinepipe = StableDiffusionPipeline.from_pretrained(&quot;TASUKU2023/Chilloutmix&quot;, paddle_dtype=paddle.float16)# å¼€å¯xformersåŠ é€Ÿ é»˜è®¤é€‰æ‹©&quot;cutlass&quot;åŠ é€Ÿpipe.enable_xformers_memory_efficient_attention()# flash éœ€è¦ä½¿ç”¨ A100ã€A10ã€3060ã€3070ã€3080ã€3090 ç­‰ä»¥ä¸Šæ˜¾å¡ã€‚# pipe.enable_xformers_memory_efficient_attention(&quot;flash&quot;)```### ToME + ControlNet```python# å®‰è£…developçš„ppdiffusers# pip install &quot;ppdiffusers&gt;=0.16.1&quot;import paddlefrom ppdiffusers import ControlNetModel, StableDiffusionControlNetPipelinefrom ppdiffusers.utils import load_imagecontrolnet = ControlNetModel.from_pretrained(&quot;lllyasviel/sd-controlnet-canny&quot;)pipe = StableDiffusionControlNetPipeline.from_pretrained(    &quot;runwayml/stable-diffusion-v1-5&quot;, safety_checker=None, controlnet=controlnet, paddle_dtype=paddle.float16)# Apply ToMe with a 50% merging ratiopipe.apply_tome(ratio=0.5) # Can also use pipe.unet in place of pipe here# æˆ‘ä»¬å¯ä»¥å¼€å¯ xformers# pipe.enable_xformers_memory_efficient_attention()generator = paddle.Generator().manual_seed(0)prompt = &quot;bird&quot;image = load_image(    &quot;https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/sd_controlnet/bird_canny.png&quot;)image = pipe(prompt, image, generator=generator).images[0]image.save(&quot;bird.png&quot;)```### æ–‡å›¾ç”Ÿæˆ ï¼ˆText-to-Image Generationï¼‰```pythonimport paddlefrom ppdiffusers import StableDiffusionPipelinepipe = StableDiffusionPipeline.from_pretrained(&quot;stabilityai/stable-diffusion-2&quot;)# è®¾ç½®éšæœºç§å­ï¼Œæˆ‘ä»¬å¯ä»¥å¤ç°ä¸‹é¢çš„ç»“æœï¼paddle.seed(5232132133)prompt = &quot;a portrait of shiba inu with a red cap growing on its head. intricate. lifelike. soft light. sony a 7 r iv 5 5 mm. cinematic post - processing &quot;image = pipe(prompt, guidance_scale=7.5, height=768, width=768).images[0]image.save(&quot;shiba_dog_with_a_red_cap.png&quot;)```&lt;div align=&quot;center&quot;&gt;&lt;img width=&quot;500&quot; alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/50394665/204796701-d7911f76-8670-47d5-8d1b-8368b046c5e4.png&quot;&gt;&lt;/div&gt;### æ–‡æœ¬å¼•å¯¼çš„å›¾åƒå˜æ¢ï¼ˆImage-to-Image Text-Guided Generationï¼‰&lt;details&gt;&lt;summary&gt;&amp;emsp;Image-to-Image Text-Guided Generation Demo &lt;/summary&gt;```pythonimport paddlefrom ppdiffusers import StableDiffusionImg2ImgPipelinefrom ppdiffusers.utils import load_imagepipe = StableDiffusionImg2ImgPipeline.from_pretrained(&quot;Linaqruf/anything-v3.0&quot;, safety_checker=None)url = &quot;https://paddlenlp.bj.bcebos.com/models/community/CompVis/data/image_Kurisu.png&quot;image = load_image(url).resize((512, 768))# è®¾ç½®éšæœºç§å­ï¼Œæˆ‘ä»¬å¯ä»¥å¤ç°ä¸‹é¢çš„ç»“æœï¼paddle.seed(42)prompt = &quot;Kurisu Makise, looking at viewer, long hair, standing, 1girl, hair ornament, hair flower, cute, jacket, white flower, white dress&quot;negative_prompt = &quot;lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry&quot;image = pipe(prompt=prompt, negative_prompt=negative_prompt, image=image, strength=0.75, guidance_scale=7.5).images[0]image.save(&quot;image_Kurisu_img2img.png&quot;)```&lt;div align=&quot;center&quot;&gt;&lt;img width=&quot;500&quot; alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/50394665/204799529-cd89dcdb-eb1d-4247-91ac-b0f7bad777f8.png&quot;&gt;&lt;/div&gt;&lt;/details&gt;### æ–‡æœ¬å¼•å¯¼çš„å›¾åƒç¼–è¾‘ï¼ˆText-Guided Image Inpaintingï¼‰æ³¨æ„ï¼å½“å‰æœ‰ä¸¤ç§ç‰ˆæœ¬çš„å›¾åƒç¼–è¾‘ä»£ç ï¼Œä¸€ä¸ªæ˜¯Legacyç‰ˆæœ¬ï¼Œä¸€ä¸ªæ˜¯æ­£å¼ç‰ˆæœ¬ï¼Œä¸‹é¢å°†åˆ†åˆ«ä»‹ç»ä¸¤ç§ä»£ç å¦‚ä½•ä½¿ç”¨ï¼&lt;details&gt;&lt;summary&gt;&amp;emsp;Legacyç‰ˆæœ¬ä»£ç &lt;/summary&gt;```pythonimport paddlefrom ppdiffusers import StableDiffusionInpaintPipelineLegacyfrom ppdiffusers.utils import load_image# å¯é€‰æ¨¡å‹æƒé‡# CompVis/stable-diffusion-v1-4# runwayml/stable-diffusion-v1-5# stabilityai/stable-diffusion-2-base ï¼ˆåŸå§‹ç­–ç•¥ 512x512ï¼‰# stabilityai/stable-diffusion-2 ï¼ˆv-objective 768x768ï¼‰# Linaqruf/anything-v3.0# ......img_url = &quot;https://paddlenlp.bj.bcebos.com/models/community/CompVis/stable-diffusion-v1-4/overture-creations.png&quot;mask_url = &quot;https://paddlenlp.bj.bcebos.com/models/community/CompVis/stable-diffusion-v1-4/overture-creations-mask.png&quot;image = load_image(img_url).resize((512, 512))mask_image = load_image(mask_url).resize((512, 512))pipe = StableDiffusionInpaintPipelineLegacy.from_pretrained(&quot;stabilityai/stable-diffusion-2-base&quot;, safety_checker=None)# è®¾ç½®éšæœºç§å­ï¼Œæˆ‘ä»¬å¯ä»¥å¤ç°ä¸‹é¢çš„ç»“æœï¼paddle.seed(10245)prompt = &quot;a red cat sitting on a bench&quot;image = pipe(prompt=prompt, image=image, mask_image=mask_image, strength=0.75).images[0]image.save(&quot;a_red_cat_legacy.png&quot;)```&lt;div align=&quot;center&quot;&gt;&lt;img width=&quot;900&quot; alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/50394665/204802186-5a6d302b-83aa-4247-a5bb-ebabfcc3abc4.png&quot;&gt;&lt;/div&gt;&lt;/details&gt;&lt;details&gt;&lt;summary&gt;&amp;emsp;æ­£å¼ç‰ˆæœ¬ä»£ç &lt;/summary&gt;Tips: ä¸‹é¢çš„ä½¿ç”¨æ–¹æ³•æ˜¯æ–°ç‰ˆæœ¬çš„ä»£ç ï¼Œä¹Ÿæ˜¯å®˜æ–¹æ¨èçš„ä»£ç ï¼Œæ³¨æ„å¿…é¡»é…åˆ **runwayml/stable-diffusion-inpainting** å’Œ **stabilityai/stable-diffusion-2-inpainting** æ‰å¯æ­£å¸¸ä½¿ç”¨ã€‚```pythonimport paddlefrom ppdiffusers import StableDiffusionInpaintPipelinefrom ppdiffusers.utils import load_image# å¯é€‰æ¨¡å‹æƒé‡# runwayml/stable-diffusion-inpainting# stabilityai/stable-diffusion-2-inpaintingimg_url = &quot;https://paddlenlp.bj.bcebos.com/models/community/CompVis/stable-diffusion-v1-4/overture-creations.png&quot;mask_url = &quot;https://paddlenlp.bj.bcebos.com/models/community/CompVis/stable-diffusion-v1-4/overture-creations-mask.png&quot;image = load_image(img_url).resize((512, 512))mask_image = load_image(mask_url).resize((512, 512))pipe = StableDiffusionInpaintPipeline.from_pretrained(&quot;stabilityai/stable-diffusion-2-inpainting&quot;)# è®¾ç½®éšæœºç§å­ï¼Œæˆ‘ä»¬å¯ä»¥å¤ç°ä¸‹é¢çš„ç»“æœï¼paddle.seed(1024)prompt = &quot;Face of a yellow cat, high resolution, sitting on a park bench&quot;image = pipe(prompt=prompt, image=image, mask_image=mask_image).images[0]image.save(&quot;a_yellow_cat.png&quot;)```&lt;div align=&quot;center&quot;&gt;&lt;img width=&quot;900&quot; alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/50394665/204801946-6cd043bc-f3db-42cf-82cd-6a6171484523.png&quot;&gt;&lt;/div&gt;&lt;/details&gt;### æ–‡æœ¬å¼•å¯¼çš„å›¾åƒæ”¾å¤§ &amp; è¶…åˆ†ï¼ˆText-Guided Image Upscaling &amp; Super-Resolutionï¼‰&lt;details&gt;&lt;summary&gt;&amp;emsp;Text-Guided Image Upscaling Demo&lt;/summary&gt;```pythonimport paddlefrom ppdiffusers import StableDiffusionUpscalePipelinefrom ppdiffusers.utils import load_imagepipe = StableDiffusionUpscalePipeline.from_pretrained(&quot;stabilityai/stable-diffusion-x4-upscaler&quot;)url = &quot;https://paddlenlp.bj.bcebos.com/models/community/CompVis/data/low_res_cat.png&quot;# æˆ‘ä»¬äººå·¥å°†åŸå§‹å›¾ç‰‡ç¼©å°æˆ 128x128 åˆ†è¾¨ç‡ï¼Œæœ€ç»ˆä¿å­˜çš„å›¾ç‰‡ä¼šæ”¾å¤§4å€ï¼low_res_img = load_image(url).resize((128, 128))prompt = &quot;a white cat&quot;image = pipe(prompt=prompt, image=low_res_img).images[0]image.save(&quot;upscaled_white_cat.png&quot;)```&lt;div align=&quot;center&quot;&gt;&lt;img width=&quot;200&quot; alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/50394665/204806180-b7f1b9cf-8a62-4577-b5c4-91adda08a13b.png&quot;&gt;&lt;img width=&quot;400&quot; alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/50394665/204806202-8c110be3-5f48-4946-95ea-21ad5a9a2340.png&quot;&gt;&lt;/div&gt;&lt;/details&gt;&lt;details&gt;&lt;summary&gt;&amp;emsp;Super-Resolution Demo&lt;/summary&gt;```pythonimport paddlefrom ppdiffusers import LDMSuperResolutionPipelinefrom ppdiffusers.utils import load_imagepipe = LDMSuperResolutionPipeline.from_pretrained(&quot;CompVis/ldm-super-resolution-4x-openimages&quot;)url = &quot;https://paddlenlp.bj.bcebos.com/models/community/CompVis/stable-diffusion-v1-4/overture-creations.png&quot;# æˆ‘ä»¬äººå·¥å°†åŸå§‹å›¾ç‰‡ç¼©å°æˆ 128x128 åˆ†è¾¨ç‡ï¼Œæœ€ç»ˆä¿å­˜çš„å›¾ç‰‡ä¼šæ”¾å¤§4å€ï¼low_res_img = load_image(url).resize((128, 128))image = pipe(image=low_res_img, num_inference_steps=100).images[0]image.save(&quot;ldm-super-resolution-image.png&quot;)```&lt;div align=&quot;center&quot;&gt;&lt;img width=&quot;200&quot; alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/50394665/204804426-5e28b571-aa41-4f56-ba26-68cca75fdaae.png&quot;&gt;&lt;img width=&quot;400&quot; alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/50394665/204804148-fe7c293b-6cd7-4942-ae9c-446369fe8410.png&quot;&gt;&lt;/div&gt;&lt;/details&gt;## æ¨¡å‹æ¨ç†éƒ¨ç½²é™¤äº†**PaddleåŠ¨æ€å›¾**è¿è¡Œä¹‹å¤–ï¼Œå¾ˆå¤šæ¨¡å‹è¿˜æ”¯æŒå°†æ¨¡å‹å¯¼å‡ºå¹¶ä½¿ç”¨æ¨ç†å¼•æ“è¿è¡Œã€‚æˆ‘ä»¬æä¾›åŸºäº[FastDeploy](https://github.com/PaddlePaddle/FastDeploy)ä¸Šçš„**StableDiffusion**æ¨¡å‹éƒ¨ç½²ç¤ºä¾‹ï¼Œæ¶µç›–æ–‡ç”Ÿå›¾ã€å›¾ç”Ÿå›¾ã€å›¾åƒç¼–è¾‘ç­‰ä»»åŠ¡ï¼Œç”¨æˆ·å¯ä»¥æŒ‰ç…§æˆ‘ä»¬æä¾›[StableDiffusionæ¨¡å‹å¯¼å‡ºæ•™ç¨‹](https://github.com/PaddlePaddle/PaddleMIX/blob/develop/ppdiffusers/deploy/export.md)å°†æ¨¡å‹å¯¼å‡ºï¼Œç„¶åä½¿ç”¨`FastDeployStableDiffusionMegaPipeline`è¿›è¡Œé«˜æ€§èƒ½æ¨ç†éƒ¨ç½²ï¼&lt;details&gt;&lt;summary&gt;&amp;emsp; å·²é¢„å…ˆå¯¼å‡ºçš„FastDeployç‰ˆStable Diffusionæƒé‡ &lt;/summary&gt;**æ³¨æ„ï¼šå½“å‰å¯¼å‡ºçš„vae encoderå¸¦æœ‰éšæœºå› ç´ ï¼**- CompVis/stable-diffusion-v1-4@fastdeploy- runwayml/stable-diffusion-v1-5@fastdeploy- runwayml/stable-diffusion-inpainting@fastdeploy- stabilityai/stable-diffusion-2-base@fastdeploy- stabilityai/stable-diffusion-2@fastdeploy- stabilityai/stable-diffusion-2-inpainting@fastdeploy- Linaqruf/anything-v3.0@fastdeploy- hakurei/waifu-diffusion-v1-3@fastdeploy&lt;/details&gt;&lt;details&gt;&lt;summary&gt;&amp;emsp; FastDeploy Demo &lt;/summary&gt;```pythonimport paddleimport fastdeploy as fdfrom ppdiffusers import FastDeployStableDiffusionMegaPipelinefrom ppdiffusers.utils import load_imagedef create_runtime_option(device_id=0, backend=&quot;paddle&quot;, use_cuda_stream=True):    option = fd.RuntimeOption()    if backend == &quot;paddle&quot;:        option.use_paddle_backend()    else:        option.use_ort_backend()    if device_id == -1:        option.use_cpu()    else:        option.use_gpu(device_id)        if use_cuda_stream:            paddle_stream = paddle.device.cuda.current_stream(device_id).cuda_stream            option.set_external_raw_stream(paddle_stream)    return optionruntime_options = {    &quot;text_encoder&quot;: create_runtime_option(0, &quot;paddle&quot;),  # use gpu:0    &quot;vae_encoder&quot;: create_runtime_option(0, &quot;paddle&quot;),  # use gpu:0    &quot;vae_decoder&quot;: create_runtime_option(0, &quot;paddle&quot;),  # use gpu:0    &quot;unet&quot;: create_runtime_option(0, &quot;paddle&quot;),  # use gpu:0}fd_pipe = FastDeployStableDiffusionMegaPipeline.from_pretrained(    &quot;Linaqruf/anything-v3.0@fastdeploy&quot;, runtime_options=runtime_options)# text2imgprompt = &quot;a portrait of shiba inu with a red cap growing on its head. intricate. lifelike. soft light. sony a 7 r iv 5 5 mm. cinematic post - processing &quot;image_text2img = fd_pipe.text2img(prompt=prompt, num_inference_steps=50).images[0]image_text2img.save(&quot;image_text2img.png&quot;)# img2imgurl = &quot;https://paddlenlp.bj.bcebos.com/models/community/CompVis/data/image_Kurisu.png&quot;image = load_image(url).resize((512, 512))prompt = &quot;Kurisu Makise, looking at viewer, long hair, standing, 1girl, hair ornament, hair flower, cute, jacket, white flower, white dress&quot;negative_prompt = &quot;lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry&quot;image_img2img = fd_pipe.img2img(    prompt=prompt, negative_prompt=negative_prompt, image=image, strength=0.75, guidance_scale=7.5).images[0]image_img2img.save(&quot;image_img2img.png&quot;)# inpaint_legacyimg_url = &quot;https://paddlenlp.bj.bcebos.com/models/community/CompVis/stable-diffusion-v1-4/overture-creations.png&quot;mask_url = &quot;https://paddlenlp.bj.bcebos.com/models/community/CompVis/stable-diffusion-v1-4/overture-creations-mask.png&quot;image = load_image(img_url).resize((512, 512))mask_image = load_image(mask_url).resize((512, 512))prompt = &quot;a red cat sitting on a bench&quot;image_inpaint_legacy = fd_pipe.inpaint_legacy(    prompt=prompt, image=image, mask_image=mask_image, strength=0.75, num_inference_steps=50).images[0]image_inpaint_legacy.save(&quot;image_inpaint_legacy.png&quot;)```&lt;/details&gt;&lt;div align=&quot;center&quot;&gt;&lt;img width=&quot;900&quot; alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/50394665/205297240-46b80992-34af-40cd-91a6-ae76589d0e21.png&quot;&gt;&lt;/div&gt;## LicensePPDiffusers éµå¾ª [Apache-2.0å¼€æºåè®®](https://github.com/PaddlePaddle/PaddleMIX/blob/develop/ppdiffusers/LICENSE)ã€‚Stable Diffusion éµå¾ª [The CreativeML OpenRAIL M å¼€æºåè®®](https://huggingface.co/spaces/CompVis/stable-diffusion-license)ã€‚&gt; The CreativeML OpenRAIL M is an [Open RAIL M license](https://www.licenses.ai/blog/2022/8/18/naming-convention-of-responsible-ai-licenses), adapted from the work that [BigScience](https://bigscience.huggingface.co/) and [the RAIL Initiative](https://www.licenses.ai/) are jointly carrying in the area of responsible AI licensing. See also [the article about the BLOOM Open RAIL license](https://bigscience.huggingface.co/blog/the-bigscience-rail-license) on which this license is based.## Acknowledgeæˆ‘ä»¬å€Ÿé‰´äº†ğŸ¤— Hugging Faceçš„[Diffusers](https://github.com/huggingface/diffusers)å…³äºé¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ä½¿ç”¨çš„ä¼˜ç§€è®¾è®¡ï¼Œåœ¨æ­¤å¯¹Hugging Faceä½œè€…åŠå…¶å¼€æºç¤¾åŒºè¡¨ç¤ºæ„Ÿè°¢ã€‚## CreditsThis library concretizes previous work by many different authors and would not have been possible without their great research and implementations. We'd like to thank, in particular, the following implementations which have helped us in our development and without which the API could not have been as polished today:- @huggingface' diffusers library, available [here](https://github.com/huggingface/diffusers)- @CompVis' latent diffusion models library, available [here](https://github.com/CompVis/latent-diffusion)- @hojonathanho original DDPM implementation, available [here](https://github.com/hojonathanho/diffusion) as well as the extremely useful translation into PyTorch by @pesser, available [here](https://github.com/pesser/pytorch_diffusion)- @ermongroup's DDIM implementation, available [here](https://github.com/ermongroup/ddim).- @yang-song's Score-VE and Score-VP implementations, available [here](https://github.com/yang-song/score_sde_pytorch)We also want to thank @heejkoo for the very helpful overview of papers, code and resources on diffusion models, available [here](https://github.com/heejkoo/Awesome-Diffusion-Models) as well as @crowsonkb and @rromb for useful discussions and insights.## Citation```bibtex@misc{von-platen-etal-2022-diffusers,  author = {Patrick von Platen and Suraj Patil and Anton Lozhkov and Pedro Cuenca and Nathan Lambert and Kashif Rasul and Mishig Davaadorj and Thomas Wolf},  title = {Diffusers: State-of-the-art diffusion models},  year = {2022},  publisher = {GitHub},  journal = {GitHub repository},  howpublished = {\url{https://github.com/huggingface/diffusers}}}```</longdescription>
</pkgmetadata>