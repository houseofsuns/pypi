<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># LMT: The CLI Tool for ChatGPT`lmt` is a versatile CLI tool that allows you to interact directly with OpenAI's ChatGPT models from the comfort of your terminal.&lt;!-- TOC --&gt;## Table of Contents1. [Features](#features)1. [Installation](#installation)    1. [`pip`](#pip)    1. [`pipx`, the Easy Way](#pipx-the-easy-way)1. [Getting Started](#getting-started)    1. [Configuring your OpenAI API key](#configuring-your-openai-api-key)1. [Usage](#usage)    1. [Basic Example](#basic-example)    1. [Add a Persona](#add-a-persona)    1. [Switching Models](#switching-models)    1. [Template Utilization](#template-utilization)    1. [Emoji Integration](#emoji-integration)    1. [Prompt Cost Estimation](#prompt-cost-estimation)    1. [Reading from `stdin`](#reading-from-stdin)    1. [Append an Additional Prompt to Piped `stdin`](#append-an-additional-prompt-to-piped-stdin)    1. [Output Redirection](#output-redirection)1. [Theming Colors for Code Blocks](#theming-colors-for-code-blocks)    1. [Example](#example)1. [License](#license)&lt;!-- /TOC --&gt;## Features* **Access All ChatGPT Models**: `lmt` supports all available ChatGPT models (gpt-3.5-turbo, gpt-3.5-turbo-16k, gpt-4, gpt-4-32k), giving you the power to choose the most suitable one for your task.* **Custom Templates**: Design your own toolbox of templates to streamline your workflow.* **Read File**: Incorporate file content into your prompts seamlessly.* **Output to a File**: Redirect standard output (`stdout`) to a file or another program as needed.* **Easy Vim Integration**: Integrate ChatGPT into Vim effortlessly by using `lmt` as a filter command.## Installation### `pip````bashpython3 -m pip install lmt-cli```### `pipx`, the Easy Way```bashpipx install lmt-cli```## Getting Started### Configuring your OpenAI API keyFor LMT to work properly, it is necessary to acquire and configure an OpenAI API key. Follow these steps to accomplish this:1. **Acquire the OpenAI API key**: You can do this by creating an account on the [OpenAI website](https://platform.openai.com/account/api-keys). Once registered, you will have access to your unique API key.2. **Set usage limit**: Before you start using the API, you need to define a usage limit. You can configure this in your OpenAI account settings by navigating to *Billing -&gt; Usage limits*.3. **Configure the OpenAI API key**: Once you have your API key, you can set it up by running the `lmt key set` command.    ```bash    lmt key set    ```With these steps, you should now have successfully set up your OpenAI API key, ready for use with the LMT.## Usage### Basic ExampleThe simplest way to use `lmt` is by entering a prompt for the model to respond to.**Here's a basic usage example where we ask the model to generate a greeting**:```bashlmt &quot;Say hello&quot;```In this case, the model will generate and return a greeting based on the given prompt.### Add a PersonaYou can also instruct the model to adopt a specific persona using the `--system` flag. This is useful when you want the model's responses to emulate a certain character or writing style.**Here's an example where we instruct the model to write like the philosopher Cioran**:```bashlmt &quot;Tell me what you think of large language models.&quot; \        --system &quot;You are Cioran. You write like Cioran.&quot;```In this case, the model will generate a response based on its understanding of Cioran's writing style and perspective.### Switching ModelsSwitching between different models is a breeze with `lmt`. Use the `-m` flag followed by the alias of the model you wish to employ.```bashlmt &quot;Explain what is a large language model&quot; -m 4```Below is a table outlining available model aliases for your convenience:| Alias | Corresponding Model || --- | --- || chatgpt | gpt-3.5-turbo || chatgpt-16k | gpt-3.5-turbo-16k || 3.5 | gpt-3.5-turbo || 3.5-16k | gpt-3.5-turbo-16k || 4 | gpt-4 || gpt4 | gpt-4 || 4-32k | gpt-4-32k || gpt4-32k | gpt-4-32k |For instance, if you want to use the `gpt-4` model, simply include `-m 4` in your command.### Template UtilizationTemplates, stored in `~/.config/lmt/templates` and written in YAML, can be generated using the following command:```bashlmt templates add```**For help regarding the `templates` subcommand, use**:```bashlmt templates --help```**Here's an example of invoking a template named &quot;cioran&quot;**:```bashlmt &quot;Tell me how AI will change the world.&quot; --template cioran```You can also use the shorter version: `-t cioran`.### Emoji IntegrationTo infuse a touch of emotion into your requests, append the `--emoji` flag option.### Prompt Cost EstimationFor an estimation of your prompt's cost before sending, utilize the `--tokens` flag option.### Reading from `stdin``lmt` facilitates reading inputs directly from `stdin`, allowing you to pipe in the content of a file as a prompt. This feature can be particularly useful when dealing with longer or more complex prompts, or when you want to streamline your workflow by incorporating `lmt` into a larger pipeline of commands.To use this feature, you simply need to pipe your content into the `lmt` command like this:```bashcat your_file.txt | lmt```In this example, `lmt` would use the content of `your_file.txt` as the input for the `prompt` command.Also, remember that you can still use all other command line options with `stdin`. For instance, you might run:```bashcat your_file.py | lmt \        --system &quot;You explain code in the style of \        a fast-talkin' wise guy from a 1940's gangster movie&quot; \        -m 4 --emoji```In this example, `lmt` takes the content of `your_file.py` as the input for the `prompt` command. With the `gpt-4` model selected via `-m 4`, the system is instructed to respond in the style of a fast-talking wiseguy from a 1940s gangster movie, as specified in the `-s/--system` option. The `--emoji` flag indicates that the response may include emojis for added expressiveness.### Append an Additional Prompt to Piped `stdin`Beyond the `-s/--system` option, `lmt` offers the capability to append an additional user prompt when reading from `stdin`. This is especially useful when you want to add context or specific instructions to the piped input without altering the system prompt.For example, with a `grocery_list.txt` file, you can append a prompt for healthy alternatives and set the system prompt to guide the AI's chef-like response.```bashcat grocery_list.txt | lmt &quot;What are some healthy alternatives to these items?&quot; \                        --system &quot;You are a chef with a focus on healthy and sustainable cooking.&quot;```### Output RedirectionYou can use output redirections. For instance:```bashlmt &quot;List 5 Wikipedia articles&quot; &gt; wiki_articles.md```## Theming Colors for Code BlocksOnce you used `lmt`, you should have a configuration file (`~/.config/lmt/config.json`) in which you can configure the colors for inline code and code blocks.Here are the styles for the code blocks: &lt;https://pygments.org/styles/&gt;As for the inline code blocks, they can be styled with the 256 colors (names or hexadecimal code).### Example```json{    &quot;code_block_theme&quot;: &quot;autumn&quot;,    &quot;inline_code_theme&quot;: &quot;blue on #f0f0f0&quot;}```## License`lmt` is licensed under Apache License version 2.0.___&lt;https://github.com/sderev/lmt&gt;</longdescription>
</pkgmetadata>