<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>[ç®€ä½“ä¸­æ–‡ğŸ€„](./README.md) | **EnglishğŸŒ**&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://user-images.githubusercontent.com/1371212/175816733-8ec25eb0-9af3-4380-9218-27c154518258.png&quot; align=&quot;middle&quot;  width=&quot;500&quot; /&gt; &lt;/p&gt;------------------------------------------------------------------------------------------&lt;p align=&quot;center&quot;&gt;    &lt;a href=&quot;./LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/license-Apache%202-dfd.svg&quot;&gt;&lt;/a&gt;    &lt;a href=&quot;https://github.com/PaddlePaddle/PaddleNLP/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/release/PaddlePaddle/PaddleNLP?color=ffa&quot;&gt;&lt;/a&gt;    &lt;a href=&quot;&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/python-3.7+-aff.svg&quot;&gt;&lt;/a&gt;    &lt;a href=&quot;&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-pink.svg&quot;&gt;&lt;/a&gt;    &lt;a href=&quot;https://github.com/PaddlePaddle/PaddleNLP/graphs/contributors&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/contributors/PaddlePaddle/PaddleNLP?color=9ea&quot;&gt;&lt;/a&gt;    &lt;a href=&quot;https://github.com/PaddlePaddle/PaddleNLP/commits&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/commit-activity/m/PaddlePaddle/PaddleNLP?color=3af&quot;&gt;&lt;/a&gt;    &lt;a href=&quot;https://pypi.org/project/paddlenlp/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/dm/paddlenlp?color=9cf&quot;&gt;&lt;/a&gt;    &lt;a href=&quot;https://github.com/PaddlePaddle/PaddleNLP/issues&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues/PaddlePaddle/PaddleNLP?color=9cc&quot;&gt;&lt;/a&gt;    &lt;a href=&quot;https://github.com/PaddlePaddle/PaddleNLP/stargazers&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/PaddlePaddle/PaddleNLP?color=ccf&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;h4 align=&quot;center&quot;&gt; &lt;a href=#features&gt; Features &lt;/a&gt; | &lt;a href=#installation&gt; Installation &lt;/a&gt; | &lt;a href=#quick-start&gt; Quick Start &lt;/a&gt; | &lt;a href=#api-reference&gt; API Reference &lt;/a&gt; | &lt;a href=#community&gt; Community &lt;/a&gt;**PaddleNLP** is a NLP library that is both **easy to use** and **powerful**. It aggregates high-quality pretrained models in the industry and provides a **plug-and-play** development experience, covering a model library for various NLP scenarios. With practical examples from industry practices, PaddleNLP can meet the needs of developers who require **flexible customization**.## News ğŸ“¢* **2023.6.12: [Release of PaddleNLP v2.6rc](https://github.com/PaddlePaddle/PaddleNLP/releases/tag/v2.6.0rc)**  * ğŸ”¨ LLM Toolsï¼šIntroduces comprehensive examples of open-source LLM training and inference, including [Bloom](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples/language_model/bloom), [ChatGLM](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples/language_model/chatglm), [GLM](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples/language_model/glm), [Llama](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples/language_model/llama) and [OPT](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples/language_model/opt). Added Tensor Parallel capability to [Trainer API](./docs/trainer.md) for distributed LLM trainin. Also released [Parameter-Efficient Finetuning](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/paddlenlp/peft),which enables training LLMs on consumer hardware.* **2023.1.12: [Release of PaddleNLP v2.5](&lt;https://github.com/PaddlePaddle/PaddleNLP/releases/tag/v2.5.0&gt;)**    * ğŸ”¨ NLP Tools: [PPDiffusers](./ppdiffusers), our cross-modal diffusion model toolbox based on PaddlePaddle, has been released! It provides a complete training process for diffusion models, and supports FastDeploy inference acceleration and multi-hardware deployment (supports Ascend chips and Kunlun core deployment).    * ğŸ’ Industrial Applications: Information extraction, text classification, sentiment analysis, and intelligent question answering have all been newly upgraded. New releases include document information extraction [UIE-X](./applications/information_extraction/document), unified text classificationÂ [UTC](./applications/zero_shot_text_classification), unified sentiment analysisÂ [UIE-Senta](./applications/sentiment_analysis/unified_sentiment_extraction) , andÂ [unsupervised QA application](./applications/question_answering/unsupervised_qa). At the same time, theÂ [ERNIE 3.0 Tiny v2](./model_zoo/ernie-tiny)Â series of pretrained small models have been released, which are more effective with low-resource and foreign data. They provide open-source end-to-end deployment solutions such as model pruning, model quantization, FastDeploy inference acceleration, and edge-side deployment to reduce the difficulty of pretrained model deployment.    * ğŸ’ª Framework Upgrade: Pretrained modelÂ [parameter configuration unification](./paddlenlp/transformers/configuration_utils.py), saving and loading custom parameter configurations no longer requires additional development;Â [Trainer API](./docs/trainer.md)Â has added BF16 training, recompute recalculations, sharding, and other distributed capabilities. Large-scale pre-training model training can easily be accomplished through simple configuration.Â [Model Compression API](./docs/compression.md)Â supports quantization training, vocabulary compression, and other functions. The compressed model has smaller accuracy loss, and the memory consumption of model deployment is greatly reduced.Â [Data Augmentation API](./docs/dataaug.md)Â has been comprehensively upgraded to support three granularities of data augmentation strategy: character, word, and sentence, making it easy to customize data augmentation strategies.    * ğŸ¤ Community: ğŸ¤—Huggingface hub officially supports PaddleNLP pretrained models, supporting PaddleNLP Model and Tokenizer downloads and uploads directly from the ğŸ¤—Huggingface hub. Everyone is welcome to try out PaddleNLP pretrained models on the ğŸ¤—Huggingface hubÂ [here](https://huggingface.co/PaddlePaddle).* **September 6, 2022: [Release of PaddleNLP v2.4](&lt;https://github.com/PaddlePaddle/PaddleNLP/releases/tag/v2.4.0&gt;)**    * ğŸ”¨ NLP Tools:Â [NLP Pipeline System Pipelines](./pipelines)Â has been released, supporting the rapid construction of search engines and question-answering systems, and can be extended to support various NLP systems, making it easy, flexible, and efficient to solve NLP tasks like building blocks!    * ğŸ’ Industrial Applications: A newÂ [text classification full-process application solution](./applications/text_classification)Â has been added, covering various scenarios such as multi-classification, multi-label, and hierarchical classification, supporting small-sample learning and TrustAI trustworthy computing model training and tuning.    * ğŸ­ AIGC: The SOTA modelÂ [CodeGen](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/examples/code_generation/codegen)Â for code generation in various programming languages has been added.    * ğŸ’ª Framework Upgrade:Â [Automatic Model Compression API](./docs/compression.md)Â has been released, which automatically cuts and quantizes models, greatly reducing the threshold for using model compression technology.Â [Few-shot Prompt](./applications/text_classification/multi_class/few-shot)Â capability has been released, integrating classic algorithms such as PET, P-Tuning, and RGL.## Features#### &lt;a href=#out-of-box-nlp-toolset&gt; ğŸ“¦ Out-of-Box NLP Toolset &lt;/a&gt;#### &lt;a href=#awesome-chinese-model-zoo&gt; ğŸ¤— Awesome Chinese Model Zoo &lt;/a&gt;#### &lt;a href=#industrial-end-to-end-system&gt; ğŸ›ï¸ Industrial End-to-end System &lt;/a&gt;#### &lt;a href=#high-performance-distributed-training-and-inference&gt; ğŸš€ High Performance Distributed Training and Inference &lt;/a&gt;### Out-of-Box NLP ToolsetTaskflow aims to provide off-the-shelf NLP pre-built task covering NLU and NLG technique, in the meanwhile with extremely fast inference satisfying industrial scenario.![taskflow1](https://user-images.githubusercontent.com/11793384/159693816-fda35221-9751-43bb-b05c-7fc77571dd76.gif)For more usage please refer to [Taskflow Docs](./docs/model_zoo/taskflow.md).### Awesome Chinese Model Zoo#### ğŸ€„ Comprehensive Chinese Transformer ModelsWe provide **45+** network architectures and over **500+** pretrained models. Not only includes all the SOTA model like ERNIE, PLATO and SKEP released by Baidu, but also integrates most of the high-quality Chinese pretrained model developed by other organizations. Use `AutoModel` API to **âš¡SUPER FASTâš¡** download pretrained models of different architecture. We welcome all developers to contribute your Transformer models to PaddleNLP!```pythonfrom paddlenlp.transformers import *ernie = AutoModel.from_pretrained('ernie-3.0-medium-zh')bert = AutoModel.from_pretrained('bert-wwm-chinese')albert = AutoModel.from_pretrained('albert-chinese-tiny')roberta = AutoModel.from_pretrained('roberta-wwm-ext')electra = AutoModel.from_pretrained('chinese-electra-small')gpt = AutoModelForPretraining.from_pretrained('gpt-cpm-large-cn')```Due to the computation limitation, you can use the ERNIE-Tiny light models to accelerate the deployment of pretrained models.```python# 6L768Hernie = AutoModel.from_pretrained('ernie-3.0-medium-zh')# 6L384Hernie = AutoModel.from_pretrained('ernie-3.0-mini-zh')# 4L384Hernie = AutoModel.from_pretrained('ernie-3.0-micro-zh')# 4L312Hernie = AutoModel.from_pretrained('ernie-3.0-nano-zh')```Unified API experience for NLP task like semantic representation, text classification, sentence matching, sequence labeling, question answering, etc.```pythonimport paddlefrom paddlenlp.transformers import *tokenizer = AutoTokenizer.from_pretrained('ernie-3.0-medium-zh')text = tokenizer('natural language processing')# Semantic Representationmodel = AutoModel.from_pretrained('ernie-3.0-medium-zh')sequence_output, pooled_output = model(input_ids=paddle.to_tensor([text['input_ids']]))# Text Classificaiton and Matchingmodel = AutoModelForSequenceClassification.from_pretrained('ernie-3.0-medium-zh')# Sequence Labelingmodel = AutoModelForTokenClassification.from_pretrained('ernie-3.0-medium-zh')# Question Answeringmodel = AutoModelForQuestionAnswering.from_pretrained('ernie-3.0-medium-zh')```#### Wide-range NLP Task SupportPaddleNLP provides rich examples covering mainstream NLP task to help developers accelerate problem solving. You can find our powerful transformer [Model Zoo](./model_zoo), and wide-range NLP application [examples](./examples) with detailed instructions.Also you can run our interactive [Notebook tutorial](https://aistudio.baidu.com/aistudio/personalcenter/thirdview/574995) on AI Studio, a powerful platform with **FREE** computing resource.&lt;details&gt;&lt;summary&gt; PaddleNLP Transformer model summary (&lt;b&gt;click to show details&lt;/b&gt;) &lt;/summary&gt;&lt;div&gt;| Model              | Sequence Classification | Token Classification | Question Answering | Text Generation | Multiple Choice || :----------------- | ----------------------- | -------------------- | ------------------ | --------------- | --------------- || ALBERT             | âœ…                       | âœ…                    | âœ…                  | âŒ               | âœ…               || BART               | âœ…                       | âœ…                    | âœ…                  | âœ…               | âŒ               || BERT               | âœ…                       | âœ…                    | âœ…                  | âŒ               | âœ…               || BigBird            | âœ…                       | âœ…                    | âœ…                  | âŒ               | âœ…               || BlenderBot         | âŒ                       | âŒ                    | âŒ                  | âœ…               | âŒ               || ChineseBERT        | âœ…                       | âœ…                    | âœ…                  | âŒ               | âŒ               || ConvBERT           | âœ…                       | âœ…                    | âœ…                  | âŒ               | âœ…               || CTRL               | âœ…                       | âŒ                    | âŒ                  | âŒ               | âŒ               || DistilBERT         | âœ…                       | âœ…                    | âœ…                  | âŒ               | âŒ               || ELECTRA            | âœ…                       | âœ…                    | âœ…                  | âŒ               | âœ…               || ERNIE              | âœ…                       | âœ…                    | âœ…                  | âŒ               | âœ…               || ERNIE-CTM          | âŒ                       | âœ…                    | âŒ                  | âŒ               | âŒ               || ERNIE-Doc          | âœ…                       | âœ…                    | âœ…                  | âŒ               | âŒ               || ERNIE-GEN          | âŒ                       | âŒ                    | âŒ                  | âœ…               | âŒ               || ERNIE-Gram         | âœ…                       | âœ…                    | âœ…                  | âŒ               | âŒ               || ERNIE-M            | âœ…                       | âœ…                    | âœ…                  | âŒ               | âŒ               || FNet               | âœ…                       | âœ…                    | âœ…                  | âŒ               | âœ…               || Funnel-Transformer | âœ…                       | âœ…                    | âœ…                  | âŒ               | âŒ               || GPT                | âœ…                       | âœ…                    | âŒ                  | âœ…               | âŒ               || LayoutLM           | âœ…                       | âœ…                    | âŒ                  | âŒ               | âŒ               || LayoutLMv2         | âŒ                       | âœ…                    | âŒ                  | âŒ               | âŒ               || LayoutXLM          | âŒ                       | âœ…                    | âŒ                  | âŒ               | âŒ               || LUKE               | âŒ                       | âœ…                    | âœ…                  | âŒ               | âŒ               || mBART              | âœ…                       | âŒ                    | âœ…                  | âŒ               | âœ…               || MegatronBERT       | âœ…                       | âœ…                    | âœ…                  | âŒ               | âœ…               || MobileBERT         | âœ…                       | âŒ                    | âœ…                  | âŒ               | âŒ               || MPNet              | âœ…                       | âœ…                    | âœ…                  | âŒ               | âœ…               || NEZHA              | âœ…                       | âœ…                    | âœ…                  | âŒ               | âœ…               || PP-MiniLM          | âœ…                       | âŒ                    | âŒ                  | âŒ               | âŒ               || ProphetNet         | âŒ                       | âŒ                    | âŒ                  | âœ…               | âŒ               || Reformer           | âœ…                       | âŒ                    | âœ…                  | âŒ               | âŒ               || RemBERT            | âœ…                       | âœ…                    | âœ…                  | âŒ               | âœ…               || RoBERTa            | âœ…                       | âœ…                    | âœ…                  | âŒ               | âœ…               || RoFormer           | âœ…                       | âœ…                    | âœ…                  | âŒ               | âŒ               || SKEP               | âœ…                       | âœ…                    | âŒ                  | âŒ               | âŒ               || SqueezeBERT        | âœ…                       | âœ…                    | âœ…                  | âŒ               | âŒ               || T5                 | âŒ                       | âŒ                    | âŒ                  | âœ…               | âŒ               || TinyBERT           | âœ…                       | âŒ                    | âŒ                  | âŒ               | âŒ               || UnifiedTransformer | âŒ                       | âŒ                    | âŒ                  | âœ…               | âŒ               || XLNet              | âœ…                       | âœ…                    | âœ…                  | âŒ               | âœ…               |&lt;/div&gt;&lt;/details&gt;For more pretrained model usage, please refer to [Transformer API Docs](./docs/model_zoo/index.rst).### Industrial End-to-end SystemWe provide high value scenarios including information extraction, semantic retrieval, question answering high-value.For more details industrial cases please refer to [Applications](./applications).#### ğŸ” Neural Search System&lt;div align=&quot;center&quot;&gt;    &lt;img src=&quot;https://user-images.githubusercontent.com/11793384/168514909-8817d79a-72c4-4be1-8080-93d1f682bb46.gif&quot; width=&quot;400&quot;&gt;&lt;/div&gt;For more details please refer to [Neural Search](./applications/neural_search).#### â“ Question Answering SystemWe provide question answering pipeline which can support FAQ system, Document-level Visual Question answering system based on [ğŸš€RocketQA](https://github.com/PaddlePaddle/RocketQA).&lt;div align=&quot;center&quot;&gt;    &lt;img src=&quot;https://user-images.githubusercontent.com/11793384/168514868-1babe981-c675-4f89-9168-dd0a3eede315.gif&quot; width=&quot;400&quot;&gt;&lt;/div&gt;For more details please refer to [Question Answering](./applications/question_answering) and [Document VQA](./applications/document_intelligence/doc_vqa).#### ğŸ’Œ Opinion Extraction and Sentiment AnalysisWe build an opinion extraction system for product review and fine-grained sentiment analysis based on [SKEP](https://arxiv.org/abs/2005.05635) Model.&lt;div align=&quot;center&quot;&gt;    &lt;img src=&quot;https://user-images.githubusercontent.com/11793384/168407260-b7f92800-861c-4207-98f3-2291e0102bbe.png&quot; width=&quot;300&quot;&gt;&lt;/div&gt;For more details please refer to [Sentiment Analysis](./applications/sentiment_analysis).#### ğŸ™ï¸ Speech Command AnalysisIntegrated ASR Model, Information Extraction, we provide a speech command analysis pipeline that show how to use PaddleNLP and [PaddleSpeech](https://github.com/PaddlePaddle/PaddleSpeech) to solve Speech + NLP real scenarios.&lt;div align=&quot;center&quot;&gt;    &lt;img src=&quot;https://user-images.githubusercontent.com/11793384/168412618-04897a47-79c9-4fe7-a054-5dc1f6a1f75c.png&quot; width=&quot;500&quot;&gt;&lt;/div&gt;For more details please refer to [Speech Command Analysis](./applications/speech_cmd_analysis).### High Performance Distributed Training and Inference#### âš¡ FastTokenizer: High Performance Text Preprocessing Library&lt;div align=&quot;center&quot;&gt;    &lt;img src=&quot;https://user-images.githubusercontent.com/11793384/168407921-b4395b1d-44bd-41a0-8c58-923ba2b703ef.png&quot; width=&quot;400&quot;&gt;&lt;/div&gt;```pythonAutoTokenizer.from_pretrained(&quot;ernie-3.0-medium-zh&quot;, use_fast=True)```Set `use_fast=True` to use C++ Tokenizer kernel to achieve 100x faster on text pre-processing. For more usage please refer to [FastTokenizer](./fast_tokenizer).#### âš¡ FastGeneration: High Performance Generation Library&lt;div align=&quot;center&quot;&gt;    &lt;img src=&quot;https://user-images.githubusercontent.com/11793384/168407831-914dced0-3a5a-40b8-8a65-ec82bf13e53c.gif&quot; width=&quot;400&quot;&gt;&lt;/div&gt;```pythonmodel = GPTLMHeadModel.from_pretrained('gpt-cpm-large-cn')...outputs, _ = model.generate(    input_ids=inputs_ids, max_length=10, decode_strategy='greedy_search',    use_fast=True)```Set `use_fast=True` to achieve 5x speedup for Transformer, GPT, BART, PLATO, UniLM text generation. For more usage please refer to [FastGeneration](./fast_generation).#### ğŸš€ Fleet: 4D Hybrid Distributed Training&lt;div align=&quot;center&quot;&gt;    &lt;img src=&quot;https://user-images.githubusercontent.com/11793384/168515134-513f13e0-9902-40ef-98fa-528271dcccda.png&quot; width=&quot;300&quot;&gt;&lt;/div&gt;For more super large-scale model pre-training details please refer to [GPT-3](./examples/language_model/gpt-3).## Installation### Prerequisites* python &gt;= 3.7* paddlepaddle &gt;= 2.3More information about PaddlePaddle installation please refer to [PaddlePaddle's Website](https://www.paddlepaddle.org.cn/install/quick?docurl=/documentation/docs/zh/install/conda/linux-conda.html).### Python pip Installation```pip install --upgrade paddlenlp```or you can install the latest develop branch code with the following command:```shellpip install --pre --upgrade paddlenlp -f https://www.paddlepaddle.org.cn/whl/paddlenlp.html```## Quick Start**Taskflow** aims to provide off-the-shelf NLP pre-built task covering NLU and NLG scenario, in the meanwhile with extremely fast inference satisfying industrial applications.```pythonfrom paddlenlp import Taskflow# Chinese Word Segmentationseg = Taskflow(&quot;word_segmentation&quot;)seg(&quot;ç¬¬åå››å±Šå…¨è¿ä¼šåœ¨è¥¿å®‰ä¸¾åŠ&quot;)&gt;&gt;&gt; ['ç¬¬åå››å±Š', 'å…¨è¿ä¼š', 'åœ¨', 'è¥¿å®‰', 'ä¸¾åŠ']# POS Taggingtag = Taskflow(&quot;pos_tagging&quot;)tag(&quot;ç¬¬åå››å±Šå…¨è¿ä¼šåœ¨è¥¿å®‰ä¸¾åŠ&quot;)&gt;&gt;&gt; [('ç¬¬åå››å±Š', 'm'), ('å…¨è¿ä¼š', 'nz'), ('åœ¨', 'p'), ('è¥¿å®‰', 'LOC'), ('ä¸¾åŠ', 'v')]# Named Entity Recognitionner = Taskflow(&quot;ner&quot;)ner(&quot;ã€Šå­¤å¥³ã€‹æ˜¯2010å¹´ä¹å·å‡ºç‰ˆç¤¾å‡ºç‰ˆçš„å°è¯´ï¼Œä½œè€…æ˜¯ä½™å…¼ç¾½&quot;)&gt;&gt;&gt; [('ã€Š', 'w'), ('å­¤å¥³', 'ä½œå“ç±»_å®ä½“'), ('ã€‹', 'w'), ('æ˜¯', 'è‚¯å®šè¯'), ('2010å¹´', 'æ—¶é—´ç±»'), ('ä¹å·å‡ºç‰ˆç¤¾', 'ç»„ç»‡æœºæ„ç±»'), ('å‡ºç‰ˆ', 'åœºæ™¯äº‹ä»¶'), ('çš„', 'åŠ©è¯'), ('å°è¯´', 'ä½œå“ç±»_æ¦‚å¿µ'), ('ï¼Œ', 'w'), ('ä½œè€…', 'äººç‰©ç±»_æ¦‚å¿µ'), ('æ˜¯', 'è‚¯å®šè¯'), ('ä½™å…¼ç¾½', 'äººç‰©ç±»_å®ä½“')]# Dependency Parsingddp = Taskflow(&quot;dependency_parsing&quot;)ddp(&quot;9æœˆ9æ—¥ä¸Šåˆçº³è¾¾å°”åœ¨äºšç‘ŸÂ·é˜¿ä»€çƒåœºå‡»è´¥ä¿„ç½—æ–¯çƒå‘˜æ¢…å¾·éŸ¦æ°å¤«&quot;)&gt;&gt;&gt; [{'word': ['9æœˆ9æ—¥', 'ä¸Šåˆ', 'çº³è¾¾å°”', 'åœ¨', 'äºšç‘ŸÂ·é˜¿ä»€çƒåœº', 'å‡»è´¥', 'ä¿„ç½—æ–¯', 'çƒå‘˜', 'æ¢…å¾·éŸ¦æ°å¤«'], 'head': [2, 6, 6, 5, 6, 0, 8, 9, 6], 'deprel': ['ATT', 'ADV', 'SBV', 'MT', 'ADV', 'HED', 'ATT', 'ATT', 'VOB']}]# Sentiment Analysissenta = Taskflow(&quot;sentiment_analysis&quot;)senta(&quot;è¿™ä¸ªäº§å“ç”¨èµ·æ¥çœŸçš„å¾ˆæµç•…ï¼Œæˆ‘éå¸¸å–œæ¬¢&quot;)&gt;&gt;&gt; [{'text': 'è¿™ä¸ªäº§å“ç”¨èµ·æ¥çœŸçš„å¾ˆæµç•…ï¼Œæˆ‘éå¸¸å–œæ¬¢', 'label': 'positive', 'score': 0.9938690066337585}]```## API Reference- Support [LUGE](https://www.luge.ai/) dataset loading and compatible with Hugging Face [Datasets](https://huggingface.co/datasets). For more details please refer to [Dataset API](https://paddlenlp.readthedocs.io/zh/latest/data_prepare/dataset_list.html).- Using Hugging Face style API to load 500+ selected transformer models and download with fast speed. For more information please refer to [Transformers API](https://paddlenlp.readthedocs.io/zh/latest/model_zoo/index.html).- One-line of code to load pre-trained word embedding. For more usage please refer to [Embedding API](https://paddlenlp.readthedocs.io/zh/latest/model_zoo/embeddings.html).Please find all PaddleNLP API Reference from our [readthedocs](https://paddlenlp.readthedocs.io/).## Community### SlackTo connect with other users and contributors, welcome to join our [Slack channel](https://paddlenlp.slack.com/).### WeChatScan the QR code below with your Wechatâ¬‡ï¸. You can access to official technical exchange group. Look forward to your participation.&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/11987277/245085922-0aa68d24-00ff-442e-9c53-2f1e898151ce.png&quot; width=&quot;150&quot; height=&quot;150&quot; /&gt;&lt;/div&gt;## CitationIf you find PaddleNLP useful in your research, please consider cite```@misc{=paddlenlp,    title={PaddleNLP: An Easy-to-use and High Performance NLP Library},    author={PaddleNLP Contributors},    howpublished = {\url{https://github.com/PaddlePaddle/PaddleNLP}},    year={2021}}```## AcknowledgeWe have borrowed from Hugging Face's [Transformers](https://github.com/huggingface/transformers)ğŸ¤— excellent design on pretrained models usage, and we would like to express our gratitude to the authors of Hugging Face and its open source community.## LicensePaddleNLP is provided under the [Apache-2.0 License](./LICENSE).</longdescription>
</pkgmetadata>