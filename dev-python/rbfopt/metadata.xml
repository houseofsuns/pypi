<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>..File:      README.rstAuthor(s): Giacomo Nannicini        University of Southern Californiag.nannicini@usc.edu(C) Copyright Singapore University of Technology and Design 2015.(C) Copyright International Business Machines Corporation 2016.You should have received a copy of the license with this code.Research partially supported by SUTD-MIT International Design Center.=================Table of contents=================This software is released under the Revised BSD License. By usingthis software, you are implicitly accepting the terms of the license.RBFOpt is a Python library for black-box optimization (also known asderivative-free optimization). It is developed for Python 3 butcurrently runs on Python 2.7 as well. This README containsinstallation instructions and a brief overview. More details can befound in the user manual.Contents of this directory:* AUTHORS: Authors of the library.* CHANGELOG: Changelog.* LICENSE: Licensing information.* MANIFEST.in: List of additional files to be included in archives.* README.rst: This file.* VERSION: Version of the library.* manual.pdf: User manual.* requirements.txt: List of dependencies for this project.* setup.cfg: Configuration file for setup.py.* setup.py: Setup file.* tox.ini: Configuration file for tox.* bin/  * rbfopt_cl_interface.py: Script for the command-line interface,    to run the library on a user-defined black-box function    implemented in a user-specified file.  * rbfopt_test_interface.py: Script to test the library on a    global optimization test set.* src/  * rbfopt/      * rbfopt_black_box.py: Description of an abstract black-box      function.    * rbfopt_algorithm.py: Main optimization algorithm, both      serial and parallel.    * rbfopt_aux_problems.py: Interface for the auxiliary problems      solved during the optimization process.    * rbfopt_degreeX_models.py: PyOmo models for the auxiliary      problems necessary for RBF functions with minimum required      polynomial degree X.    * rbfopt_refinement: Routines for refinement phase.    * rbfopt_settings.py: Global and algorithmic settings.    * rbfopt_test_functions.py: Mathematical test functions.    * rbfopt_user_black_box.py: A black-box class constructed from      user data.    * rbfopt_utils.py: Utility routines.    * doc/      * conf.py: Configuration file for Sphinx.      * Makefile: Makefile (for Linux/Mac) to build thedocumentation.      * make.bat: Batch file (for Windows) to build thedocumentation.      * \*.rst: ReStructured Text files for the documentation.    * examples/      * rbfopt_black_box_example.py: Example of an implementationof a simple black-box function.  * tests/  * context.py: Configuration file for nose.  * test_functions.py: Global optimization test functions.  * test_rbfopt_algorithm.py: Testing module for    rbfopt_algorithm.py (regular unit tests).  * slow_test_rbfopt_algorithm.py: Testing module for    rbfopt_algorithm.py (additional, slow tests).  * test_rbfopt_aux_problems.py: Testing module for    rbfopt_aux_problems.py.  * test_rbfopt_degreeX_models.py: Testing module for    rbfopt_degreeX_models.py.  * test_rbfopt_env.py: Environment variables for testing    environment.  * test_rbfopt_mwe.py: Test the minimal working example given in the    documentation.  * test_rbfopt_refinement: Testing module for rbfopt_refinement.py  * test_rbfopt_settings.py: Testing module for rbfopt_settings.py.  * test_rbfopt_utils.py: Testing module for rbfopt_utils.py.=========================Installation requirements=========================This package requires the following software:* Python version &gt;= 3.7* NumPy version &gt;= 1.11.0* SciPy version &gt;= 0.17.0* Pyomo version &gt;= 5.1.1The software has been tested with the versions indicated above. It maywork with earlier version and should work with subsequent version, ifthey are backward compatible. In particular, the software is known towork with Pyomo version 4 and earlier versions of Scipy.The code is developed for Python 3.7, but it currently also runs onPython 2.7. Since Python 2.7 has reached end-of-life in January 2020,we recommend using Python 3.7 or higher.The easiest, and recommended, way to install the package is via thePython module manager pip. The code is on PyPI, therefore it can beinstalled from PyPI using::  pip install rbfoptYou can install from source, downloading an archive or cloning fromgit (for example if you want to use a development version that is notreleased on PyPI yet), using the command::  pip install .You may need the -e switch to install in a virtual environment. Tobuild the documentation, you also need numpydoc::  pip install numpydocOn Windows systems, we recommend `WinPython&lt;http://winpython.sourceforge.net/&gt;`_, which comes with NumPy, SciPyand pip already installed. After installing WinPython, it is typicallynecessary to update the PATH environment variable. The above commandusing pip to install missing libraries has been successfully tested ona fresh WinPython installation.RBFOpt requires the solution of convex and nonconvex nonlinearprograms (NLPs), as well as nonconvex mixed-integer nonlinear programs(MINLPs) if some of the decision variables (design parameters) areconstrained to be integer. Solution of these subproblems is performedthrough Pyomo, which in principle supports any solver with an AMPLinterface (.nl file format). The code is setup to employ Bonmin andIpopt, that are open-source, with a permissive license, and availablethrough the COIN-OR repository. The end-users are responsible forchecking that they have the right to use these solvers. To usedifferent solvers, a few lines of the source code have to be modified:ask for help on GitHub or on the mailing list, see below.To obtain pre-compiled binaries for Bonmin and Ipopt for severalplatforms, we suggest having a look at the AMPL `opensource solvers&lt;http://ampl.com/products/solvers/open-source/&gt;`_ (also `here&lt;http://ampl.com/dl/open/&gt;`_) for static binaries. **Note:** Thesebinaries might be outdated: better performance can sometimes beobtained compiling Bonmin from scratch (Bonmin contains Ipopt aswell), especially if compiling with a different solver for linearsystems rather than the default Mumps, e.g., ma27.  Bonmin and Ipoptmust be compiled with ASL support.In case any of the packages indicated above is missing, some featuresmay be disabled, not function properly, or the software may not run atall.=============================================Installation instructions and getting started=============================================1) Install the package with pip as indicated above. This will install   the two executable Python scripts rbfopt_cl_interface.py and   rbfopt_test_interface.py in your bin/ directory (whatever is used   by pip for this purpose), as well as the module files in your   site-packages directory.2) Make sure Bonmin and Ipopt are in your path; otherwise, use the   options minlp_solver_path and nlp_solver_path in RbfoptSettings to   indicate the full path to the solvers. If you use RBFOpt as a   library and create your own RbfoptSettings object, these options   can be given as::     import rbfopt     settings = rbfopt.RbfoptSettings(minlp_solver_path='full/path/to/bonmin', nlp_solver_path='full/path/to/ipopt')   If you use the command-line tools, you can simply provide the option preceded by double hyphen, as in::     rbfopt_test_interface.py --minlp_solver_path='full/path/to/bonmin' branin3) Enjoy!4) You can test the installation by running::     rbfopt_test_interface.py branin   See::     rbfopt_test_interface.py --help   for more details on command-line options for the testing tool.   Many more test functions, with different characteristics, are   implemented in the file rbfopt_test_functions.py. They can all be   used for testing.5) Unit tests for the library can be executed by running::     nose2   or::     python setup.py test   from the current (main) directory. If some of the tests fail, the   library may or may not work correctly. Some of the test failures   are relatively harmless. You are advised to contact the mailing   list (see below) if you are unsure about some test failure.   Additional slow tests, that check if various parametrizations of   the optimization algorithm can solve some global optimization   problems, are found in the file slow_test_rbfopt_algorithm.py,   which is ignored by nose by default. To execute these tests, run::     nose2 tests.slow_test_rbfopt_algorithm   =======================Minimal working example=======================After installation, the easiest way to optimize a function is to usethe RbfoptUserBlackBox class to define a black-box, and executeRbfoptAlgorithm on it. This is a minimal example to optimize the3-dimensional function defined below::  import rbfopt  import numpy as np  def obj_funct(x):    return x[0]*x[1] - x[2]    bb = rbfopt.RbfoptUserBlackBox(3, np.array([0] * 3), np.array([10] * 3),                                 np.array(['R', 'I', 'R']), obj_funct)  settings = rbfopt.RbfoptSettings(max_evaluations=50)  alg = rbfopt.RbfoptAlgorithm(settings, bb)  val, x, itercount, evalcount, fast_evalcount = alg.optimize()Another possibility is to define your own class derived fromRbfoptBlackBox in a separate file, and execute the command-lineinterface on the file. An example is provided undersrc/rbfopt/examples, in the file rbfopt_black_box_example.py. This canbe executed with::  rbfopt_cl_interface.py src/rbfopt/examples/rbfopt_black_box_example.py=====================Parallel optimization=====================RBFOpt supports asynchronous parallel optimization using Python'smultiprocessing library. This mode is enabled whenever the parameternum_cpus is set to a value greater than 1. Black-box functionevaluations as well as some of the heaviest computatations carried outby the algorithm will then be executed in parallel. Since the parallelcomputations are asynchronous, determinism cannot be guaranteed: inother words, if you execute the parallel optimizer twice in a row, youmay (and often will) get different results, even if you provide thesame random seed. This is because the order in which the computationswill be completed may change, and this may impact the course of thealgorithm.The default parameters of the algorithm are optimized for the serialoptimization mode. For recommendations on what parameters to use withthe parallel optimizer, feel free to ask on the mailing list.Note that the parallel optimizer is oblivious of the system-widesettings for executing linear algebra routines (BLAS) in parallel. Werecommend setting the number of threads for BLAS to 1 when using theparallel optimizer, see the next section.==========================Known issues with OpenBLAS==========================We are aware of an issue when launching multiple distinct processesthat use RBFOpt and the NumPy implementation is configured to useOpenBLAS in parallel: in this case, on rare occasions we have observedthat some processes may get stuck forever when computing matrix-vectormultiplications. The problem can be fixed by setting the number ofthreads for OpenBLAS to 1. We do not know if the same issue occurswith other parallel implementations of BLAS.For this reason, and because parallel BLAS uses resources suboptimallywhen used in conjunction with the parallel optimizer of RBFOpt (ifBLAS runs in parallel, each thread of the parallel optimizer wouldspawn multiple threads to run BLAS, therefore disregarding the optionnum_cpus), RBFOpt attempts to set the number of BLAS threads to 1 atrun time.All scripts (rbfopt_cl_interface.py and rbfopt_test_interface.py) setthe environment variables OMP_NUM_THREADS to 1. Furthermore, therbfopt module does the same when imported for the first time.Note that these settings are only effective if the environmentvariable is set *before* NumPy is imported; otherwise, they areignored. If you are facing the same issue, we recommend settingenvironment variable OMP_NUM_THREADS to 1. In Python, this can be donewith::  import os  os.environ['OMP_NUM_THREADS'] = '1'=============Documentation=============The documentation for the code can be built using Sphinx with thenumpydoc extension. numpydoc can be installed with pip::  pip install numpydocAfter that, the directory src/rbfopt/doc/ contains a Makefile (onWindows, use make.bat) and the Sphinx configuration file conf.py.You can build the HTML documentation (recommended) with::  make htmlThe output will be located in _build/html/ and the index can be foundin _build/html/index.html.A PDF version of the documentation (much less readable than the HTMLversion) can be built using the command::  make latexpdfAn online version of the documentation for the latest master branch ofthe code, and for the latest stable release, are available onReadTheDocs for the `latest&lt;http://rbfopt.readthedocs.org/en/latest/&gt;`_ and `stable&lt;http://rbfopt.readthedocs.org/en/stable/&gt;`_ version.=============Citing RBFOpt=============If you use RBFOpt in one of your projects or papers, please cite thefollowing papers (this is the only way in which the authors getcredit):* A. Costa and G. Nannicini. RBFOpt: an open-source library for  black-box optimization with costly function  evaluations. Mathematical Programming Computation,  10(4):597â€“629, 2018. (The paper can be downloaded as: `Optimization  Online paper 4538  &lt;http://www.optimization-online.org/DB_HTML/2014/09/4538.html&gt;`_)* G. Nannicini. On the implementation of a global optimization method  for mixed-variable problems. Open Journal of Mathematical  Optimization, 2(1), 2021. (Download link: `OJMO  &lt;https://ojmo.centre-mersenne.org/articles/OJMO_2021__2__A1_0/&gt;`_)======================================RBFOpt for hyperparameter optimization======================================RBFOpt is used in `IBM Watson Studio AutoAI&lt;https://www.ibm.com/cloud/watson-studio/autoai&gt;`_. For a discussionon the application of RBFOpt to hyperparameter optimization in machinelearning, besides the aforementioned paper published in `OJMO&lt;https://ojmo.centre-mersenne.org/articles/OJMO_2021__2__A1_0/&gt;`_, seethe paper:* G. I. Diaz, A. Fokoue-Nkoutche, G. Nannicini and H. Samulowitz. An  effective algorithm for hyperparameter optimization of neural  networks. IBM Journal of Research and Development 61, no. 4/5  (2017): 9-1. (Download link: `IBM Journal of R&amp;D  &lt;https://ieeexplore.ieee.org/document/8030298&gt;`_)=======Support=======If you believe there is a bug or an issue, please open an issue onGitHub.  If you have a general question, please use GitHub's&quot;Discussions&quot; feature (the tab can be opened at the top of the page).</longdescription>
</pkgmetadata>