# automatically generated by g-sorcery
# please do not edit this file

EAPI=8

REALNAME="${PN}"
LITERALNAME="GPTQModel"
REALVERSION="${PV}"
DIGEST_SOURCES="yes"
PYTHON_COMPAT=( python{3_11,3_12,3_13,3_14} )
DISTUTILS_USE_PEP517=standalone

inherit python-r1 gs-pypi

DESCRIPTION="Production ready LLM model compression/quantization toolkit with hw accelerated inference support for both cpu/gpu via HF, vLLM, and SGLang."

HOMEPAGE="https://github.com/ModelCloud/GPTQModel"
LICENSE=""
SRC_URI="https://files.pythonhosted.org/packages/source/${REALNAME::1}/${REALNAME}/${REALNAME}-${REALVERSION}.tar.gz"
SOURCEFILE="${REALNAME}-${REALVERSION}.tar.gz"
RESTRICT="test"

SLOT="0"
KEYWORDS="~amd64 ~x86"

IUSE="bitblas eval hf mlx openai quality sglang test triton vllm"
DEPENDENCIES="dev-python/accelerate[${PYTHON_USEDEP}]
	~dev-python/numpy-2.2.6[${PYTHON_USEDEP}]
	dev-python/torch[${PYTHON_USEDEP}]
	dev-python/safetensors[${PYTHON_USEDEP}]
	dev-python/transformers[${PYTHON_USEDEP}]
	>=dev-python/threadpoolctl-3.6.0[${PYTHON_USEDEP}]
	>=dev-python/packaging-24.2[${PYTHON_USEDEP}]
	dev-python/device-smi[${PYTHON_USEDEP}]
	>=dev-python/protobuf-6.32.0[${PYTHON_USEDEP}]
	>=dev-python/pillow-11.3.0[${PYTHON_USEDEP}]
	dev-python/hf-transfer[${PYTHON_USEDEP}]
	dev-python/huggingface-hub[${PYTHON_USEDEP}]
	dev-python/tokenicer[${PYTHON_USEDEP}]
	dev-python/logbar[${PYTHON_USEDEP}]
	dev-python/maturin[${PYTHON_USEDEP}]
	dev-python/datasets[${PYTHON_USEDEP}]
	>=dev-python/pyarrow-21.0[${PYTHON_USEDEP}]
	>=dev-python/dill-0.3.8[${PYTHON_USEDEP}]
	dev-python/pypcre[${PYTHON_USEDEP}]
	dev-python/torchao[${PYTHON_USEDEP}]
	dev-python/kernels[${PYTHON_USEDEP}]
	test? ( >=dev-python/pytest-8.3.5[${PYTHON_USEDEP}] )
	test? ( >=dev-python/pytest-timeout-2.3.1[${PYTHON_USEDEP}] )
	test? ( dev-python/parameterized[${PYTHON_USEDEP}] )
	quality? ( dev-python/ruff[${PYTHON_USEDEP}] )
	vllm? ( dev-python/vllm[${PYTHON_USEDEP}] )
	vllm? ( dev-python/flashinfer-python[${PYTHON_USEDEP}] )
	sglang? ( dev-python/sglang[${PYTHON_USEDEP}] )
	sglang? ( dev-python/flashinfer-python[${PYTHON_USEDEP}] )
	bitblas? ( dev-python/bitblas[${PYTHON_USEDEP}] )
	hf? ( dev-python/optimum[${PYTHON_USEDEP}] )
	eval? ( dev-python/lm-eval[${PYTHON_USEDEP}] )
	eval? ( dev-python/evalplus[${PYTHON_USEDEP}] )
	triton? ( dev-python/triton[${PYTHON_USEDEP}] )
	openai? ( dev-python/uvicorn[${PYTHON_USEDEP}] )
	openai? ( dev-python/fastapi[${PYTHON_USEDEP}] )
	openai? ( dev-python/pydantic[${PYTHON_USEDEP}] )
	mlx? ( dev-python/mlx-lm[${PYTHON_USEDEP}] )"
BDEPEND="${DEPENDENCIES}"
RDEPEND="${DEPENDENCIES}"
