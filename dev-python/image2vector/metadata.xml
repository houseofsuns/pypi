<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription># image2vector## ç®€ä»‹å°†å›¾ç‰‡è½¬æˆå‘é‡ï¼Œå¯ç”¨äºä»¥å›¾æœå›¾å’Œå›¾ç‰‡ç›¸ä¼¼åº¦æ¯”è¾ƒ&gt; å‘é‡çº¬åº¦ä¸º 512â­ï¸ ğŸŒŸ âœ¨ âš¡ï¸ â˜„ï¸ ğŸ’¥## ä¾èµ–Python è§£é‡Šå™¨:- CPython : 3.8 åŠä»¥ä¸Šç‰ˆæœ¬ç¬¬ä¸‰æ–¹åŒ…:- ä½¿ç”¨ pytorch æ¨ç†éœ€è¦å®‰è£…ï¼š  - pytorch- ä½¿ç”¨ onnxruntime æ¨ç†éœ€è¦å®‰è£…:  - onnx  - onnxruntime- ä½¿ç”¨ tensorRT æ¨ç†éœ€è¦å®‰è£…:  - tensorrt  - torch_tensorrt&gt; pip install pytorch&gt;&gt; pip install onnx&gt;&gt; pip install onnxruntime&gt;&gt; pip install tensorrt&gt;&gt; pip install torch_tensorrt# æ–‡æ¡£## ç¤ºä¾‹é€šè¿‡ä¸‹é¢çš„ demo ç¤ºä¾‹ï¼Œä½ å¯ä»¥å­¦ä¼š:- åˆå§‹åŒ–ä¸€ä¸ª resnet ç½‘ç»œ- ä¸ºä¸€å¼ å›¾ç‰‡ç”Ÿæˆå¯¹åº”çš„å‘é‡- ä½¿ç”¨æ¬§å¼è·ç¦»ï¼Œæ¯”è¾ƒä¸¤ä¸ªå‘é‡çš„ç›¸ä¼¼ç¨‹åº¦### ä½¿ç”¨ä¸åŒçš„ runtime æ¨ç†#### ä½¿ç”¨ pytorch ç›´æ¥è¿›è¡Œæ¨ç†```pythonfrom pathlib import Pathfrom typing import Listfrom iv import ResNet, l2from iv.schemas import Runtime# Initialize a residual neural networkresnet: ResNet = ResNet(    runtime=Runtime.PYTORCH,    runtime_model='weight/gl18-tl-resnet50-gem-w-83fdc30.pth')# Generate a vector of specified images# The generated vector is a List[float] data structure,# the length of the list is 512, which means the vector is of 512 dimensionsvector_1: List[float] = resnet.gen_vector('example-1.jpg')vector_2: List[float] = resnet.gen_vector('example-2.jpg')# Compare the Euclidean distance of two vectorsdistance: float = l2(vector_1, vector_2)print('Euclidean Distance is ', distance)```&gt; Where to get the `weight/gl18-tl-resnet50-gem-w-83fdc30.pth` file from, you can visit: http://cmp.felk.cvut.cz/cnnimageretrieval/data/networks/gl18/#### ä½¿ç”¨ onnxruntime ç›´æ¥è¿›è¡Œæ¨ç†```pythonfrom pathlib import Pathfrom typing import Listfrom iv import ResNet, l2from iv.schemas import Runtime# Initialize a residual neural networkresnet: ResNet = ResNet(    runtime=Runtime.ONNXRUNTIME,    runtime_model='models/iv_resnet50_export_into_onnx_model.pb',    device='cpu')# Generate a vector of specified images# The generated vector is a List[float] data structure,# the length of the list is 512, which means the vector is of 512 dimensionsvector_1: List[float] = resnet.gen_vector('example-1.jpg')vector_2: List[float] = resnet.gen_vector('example-2.jpg')# Compare the Euclidean distance of two vectorsdistance: float = l2(vector_1, vector_2)print('Euclidean Distance is ', distance)```#### ä½¿ç”¨ tensorRT ç›´æ¥è¿›è¡Œæ¨ç†```pythonfrom pathlib import Pathfrom typing import Listfrom iv import ResNet, l2from iv.schemas import Runtime# Initialize a residual neural networkresnet: ResNet = ResNet(    runtime=Runtime.PYTORCH_TENSORRT,    runtime_model='models/iv_resnet50_export_into_pytorch_tensorrt_model.ts',    device='cuda')# Generate a vector of specified images# The generated vector is a List[float] data structure,# the length of the list is 512, which means the vector is of 512 dimensionsvector_1: List[float] = resnet.gen_vector('example-1.jpg')vector_2: List[float] = resnet.gen_vector('example-2.jpg')# Compare the Euclidean distance of two vectorsdistance: float = l2(vector_1, vector_2)print('Euclidean Distance is ', distance)```### ä½¿ç”¨ä¸åŒçš„è®¾å¤‡æ¨ç†é»˜è®¤ä½¿ç”¨ cpu è¿›è¡Œæ¨ç†ï¼Œå¦‚æœéœ€è¦æŒ‡å®šè®¾å¤‡ï¼Œå¯ä»¥åœ¨åˆå§‹åŒ–ç½‘ç»œçš„æ—¶å€™ï¼ŒæŒ‡å®š deviceä½¿ç”¨ cpu:```pythonresnet: ResNet = ResNet(    runtime=Runtime.PYTORCH,    runtime_model='weight/gl18-tl-resnet50-gem-w-83fdc30.pth',    device='cpu')```ä½¿ç”¨ cuda:```pythonresnet: ResNet = ResNet(    runtime=Runtime.PYTORCH,    runtime_model='weight/gl18-tl-resnet50-gem-w-83fdc30.pth',    device='cuda')```ä½¿ç”¨ mps:```pythonresnet: ResNet = ResNet(    runtime=Runtime.PYTORCH,    runtime_model='weight/gl18-tl-resnet50-gem-w-83fdc30.pth',    device='mps')```æ€»å…±æ”¯æŒå¦‚ä¸‹è®¾å¤‡:```pythonclass Device(Enum):    MPS = 'mps'    CPU = 'cpu'    CUDA = 'cuda'    CUDNN = 'cudnn'    MKL = 'mkl'    MKLDNN = 'mkldnn'    OPENMP = 'openmp'    QUANTIZED = 'quantized'```### æ‰¹é‡æ¨ç†ç½‘ç»œæä¾›å¦‚ä¸‹ä¸¤ä¸ª API:- gen_vector, è¾“å…¥ä¸€ä¸ªå›¾ç‰‡ï¼Œè¾“å‡ºä¸€ä¸ªå‘é‡- gen_vectors, è¾“å…¥ n ä¸ªå›¾ç‰‡ï¼Œè¾“å‡º n ä¸ªå‘é‡æ‰€ä»¥ï¼Œå¦‚æœéœ€è¦æ‰¹é‡æ¨ç†ï¼Œå¯ä»¥ä½¿ç”¨ gen_vectorsç¤ºä¾‹å¦‚ä¸‹:```pythonfrom pathlib import Pathfrom typing import Listfrom PIL import Imagefrom iv import ResNetfrom iv.schemas import Runtimedevice = 'cuda'batch_size = 500################################################################################### å‡†å¤‡å›¾ç‰‡image_file_path = Path('resources/images/std.jpg')image = Image.open(image_file_path).convert('RGB')images = [image]*batch_sizeassert isinstance(images[0], Image.Image), f'images[0] type: {type(images[0])}'################################################################################### åˆå§‹åŒ–ç½‘ç»œï¼Œå¹¶ä¸”æ‰¹é‡ç”Ÿæˆå‘é‡resnet_tensorrt: ResNet = ResNet(    runtime_model='models/iv_resnet50_export_into_pytorch_tensorrt_model.ts',    device=device,    runtime=Runtime.PYTORCH_TENSORRT)vs: List[List[float]] = resnet_tensorrt.gen_vectors(images)```## æ›´å¤šæµ‹è¯•æŠ¥å‘Š- [æ¨ç†é€Ÿåº¦æµ‹è¯•æŠ¥å‘Š.md](./doc/æ¨ç†é€Ÿåº¦æµ‹è¯•æŠ¥å‘Š.md)- [svddb åœ¨å›¾ç‰‡ size ä» 512 é™ä½åˆ° 224 çš„å¯è¡Œæ€§åˆ†ææŠ¥å‘Š.md](./doc/svddb åœ¨å›¾ç‰‡ size ä» 512 é™ä½åˆ° 224 çš„å¯è¡Œæ€§åˆ†ææŠ¥å‘Š.md)## å‚è€ƒé¡¹ç›®- [cnnimageretrieval-pytorch](https://github.com/filipradenovic/cnnimageretrieval-pytorch)- [ImageRetrieval-LSH](https://github.com/yinhaoxs/ImageRetrieval-LSH)</longdescription>
</pkgmetadata>