<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>   üöÄ We are granting pilot access to **Ivy's Compiler and Transpiler**   to some users, `join the waitlist &lt;https://console.unify.ai/&gt;`__ if--------------Status======.. image:: https://github.com/unifyai/unifyai.github.io/blob/master/img/externally_linked/logos/supported/frameworks.png?raw=true   :width: 100%   :class: dark-light--------------Unified AI==========--------------Ivy is both an ML transpiler and a framework, currently supporting JAX,TensorFlow, PyTorch and Numpy.Ivy unifies all ML frameworks üí• enabling you not only to **write codethat can be used with any of these frameworks as the backend**, but alsoto **convert üîÑ any function, model or library written in any of them toyour preferred framework!**You can check out `Ivy as a transpiler &lt;#ivy-as-a-transpiler&gt;`__ and`Ivy as a framework &lt;#ivy-as-a-framework&gt;`__ to learn more about this,try out Ivy straight away going through the `Setting upIvy &lt;#setting-up-ivy&gt;`__ section, or dive deep into Ivy's`Documentation &lt;#documentation&gt;`__ and `Examples &lt;#examples&gt;`__!If you would like to contribute, you can join our growing`Community &lt;#community&gt;`__ üåç, check out our`Contributing &lt;#contributing&gt;`__ guide, and take a look at the `opentasks &lt;https://unify.ai/docs/ivy/overview/contributing/open_tasks.html&gt;`__if you'd like to dive straight in üßëüíª**Let's** `unify.ai &lt;https://unify.ai&gt;`__ **together ü¶æ**--------------Ivy as a transpiler-------------------Ivy's transpiler allows you to use code from any other framework (orfrom any other version of the same framework!) in your own code, by justadding one line of code. Under the hood, Ivy traces a computationalgraph and leverages the frontends and backends to link one framework toanother.This way, Ivy makes all ML-related projects available for you,independently of the framework you want to use to research, develop, ordeploy systems. Feel free to head over to the docs for the full APIreference, but the functions you'd most likely want to use are:.. code:: python   # Compiles a function into an efficient fully-functional graph, removing all wrapping and redundant code   ivy.compile()   # Converts framework-specific code to a different framework   ivy.transpile()   # Converts framework-specific code to Ivy   ivy.unify()These functions can be used eagerly or lazily. If you pass the necessaryarguments for function tracing, the compilation/transpilation step willhappen instantly (eagerly). Otherwise, the compilation/transpilationwill happen only when the returned function is first invoked... code:: python   import ivy   import jax   ivy.set_backend(&quot;jax&quot;)   # Simple JAX function to transpile   def test_fn(x):       return jax.numpy.sum(x)   x1 = ivy.array([1., 2.]).. code:: python   # Arguments are available -&gt; transpilation happens eagerly   eager_graph = ivy.transpile(test_fn, source=&quot;jax&quot;, to=&quot;torch&quot;, args=(x1,))   # eager_graph is now torch code and runs efficiently   ret = eager_graph(x1).. code:: python   # Arguments are not available -&gt; transpilation happens lazily   lazy_graph = ivy.transpile(test_fn, source=&quot;jax&quot;, to=&quot;torch&quot;)   # The transpiled graph is initialized, transpilation will happen here   ret = lazy_graph(x1)   # lazy_graph is now torch code and runs efficiently   ret = lazy_graph(x1)If you want to learn more, you can find more information in the `Ivy asa transpiler section of thedocs! &lt;https://unify.ai/docs/ivy/overview/design/ivy_as_a_transpiler.html&gt;`__When should I use Ivy as a transpiler?~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~If you want to use building blocks published in other frameworks (neuralnetworks, layers, array computing libraries, training pipelines...), youwant to integrate code developed in various frameworks, or maybestraight up move code from one framework to another, the transpiler isdefinitely the tool üîß for the job! As the output of transpilation isnative code in the target framework, you can use the converted code justas if it was code originally developed in that framework, applyingframework-specific optimizations or tools, instantly exposing yourproject to all of the unique perks of a different framework.Ivy as a framework------------------The Ivy framework is built on top of various essential components,mainly the `BackendHandler &lt;https://unify.ai/docs/ivy/overview/design/building_blocks.html#backend-handler&gt;`__,which manages what framework is being used behind the scenes and the`Backend FunctionalAPIs &lt;https://unify.ai/docs/ivy/overview/design/building_blocks.html#backend-functional-apis&gt;`__,which provide framework-specific implementations of the Ivy functions.Likewise, classes such as ``ivy.Container`` or ``ivy.Array`` are alsoavailable, facilitating the use of structured data and array-likeobjects (learn more about them`here! &lt;https://unify.ai/docs/ivy/overview/design/ivy_as_a_framework.html&gt;`__).All of the functionalities in Ivy are exposed through the``Ivy functional API`` and the ``Ivy stateful API``. All functions inthe `FunctionalAPI &lt;https://unify.ai/docs/ivy/overview/design/building_blocks.html#ivy-functional-api&gt;`__are **Framework Agnostic Functions**, which mean that we can use themlike this:.. code:: python   import ivy   import jax.numpy as jnp   import tensorflow as tf   import numpy as np   import torch   def mse_loss(y, target):       return ivy.mean((y - target)**2)   jax_mse   = mse_loss(jnp.ones((5,)), jnp.ones((5,)))   tf_mse    = mse_loss(tf.ones((5,)), tf.ones((5,)))   np_mse    = mse_loss(np.ones((5,)), np.ones((5,)))   torch_mse = mse_loss(torch.ones((5,)), torch.ones((5,)))In the example above we show how Ivy's functions are compatible withtensors from different frameworks. This is the same for ALL Ivyfunctions. They can accept tensors from any framework and return thecorrect result.The `Ivy StatefulAPI &lt;https://unify.ai/docs/ivy/overview/design/ivy_as_a_framework/ivy_stateful_api.html&gt;`__,on the other hand, allows you to define trainable modules and layers,which you can use alone or as a part of any other framework code!.. code:: python   import ivy   class Regressor(ivy.Module):       def __init__(self, input_dim, output_dim):           self.input_dim = input_dim           self.output_dim = output_dim           super().__init__()       def _build(self, *args, **kwargs):           self.linear0 = ivy.Linear(self.input_dim, 128)           self.linear1 = ivy.Linear(128, self.output_dim)       def _forward(self, x):           x = self.linear0(x)           x = ivy.functional.relu(x)           x = self.linear1(x)           return xIf we put it all together, we'll have something like this. This exampleuses PyTorch as the backend, but this can easily be changed to yourfavorite framework, such as TensorFlow, or JAX... code:: python   import ivy   class Regressor(ivy.Module):       def __init__(self, input_dim, output_dim):           self.input_dim = input_dim           self.output_dim = output_dim           super().__init__()       def _build(self, *args, **kwargs):           self.linear0 = ivy.Linear(input_dim, 128)           self.linear1 = ivy.Linear(128, output_dim)       def _forward(self, x):           x = self.linear0(x)           x = ivy.functional.relu(x)           x = self.linear1(x)           return x   ivy.set_backend('torch')  # set backend to PyTorch (or any other backend!)   model = Regressor(input_dim=1, output_dim=1)   optimizer = ivy.Adam(0.3)   n_training_examples = 2000   noise = ivy.random.random_normal(shape=(n_training_examples, 1), mean=0, std=0.1)   x = ivy.linspace(-6, 3, n_training_examples).reshape((n_training_examples, 1))   y = 0.2 * x ** 2 + 0.5 * x + 0.1 + noise   def loss_fn(pred, target):       return ivy.mean((pred - target) ** 2)   for epoch in range(40):       # forward pass       pred = model(x)       # compute loss and gradients       loss, grads = ivy.execute_with_gradients(lambda v: loss_fn(pred, y), model.v)       # update parameters       model.v = optimizer.step(model.v, grads)       # print current loss       print(f'Epoch: {epoch + 1:2d} --- Loss: {ivy.to_numpy(loss).item():.5f}')   print('Finished training!')The model's output can be visualized as follows:Last but not least, we are also working on specific extension totallywritten in Ivy and therefore usable within any framework, coveringtopics like `Mechanics &lt;https://github.com/unifyai/mech&gt;`__, `ComputerVision &lt;https://github.com/unifyai/vision&gt;`__,`Robotics &lt;https://github.com/unifyai/robot&gt;`__, a `ReinforcementLearning Gym &lt;https://github.com/unifyai/gym&gt;`__,`Memory &lt;https://github.com/unifyai/memory&gt;`__ and implementation ofvarious `Models &lt;https://github.com/unifyai/models&gt;`__ or `Buildertools &lt;https://github.com/unifyai/builder&gt;`__ with trainers, dataloaders and more!As always, you can find more information about `Ivy as a framework inthedocs! &lt;https://unify.ai/docs/ivy/overview/design/ivy_as_a_framework.html&gt;`__When should I use Ivy as a framework?~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~As Ivy supports multiple backends, writing code in Ivy breaks you freefrom framework limitations. If you want to publish highly flexible codefor everyone to use, independently of the framework they are using, oryou plan to develop ML-related tools and want them to be interoperablewith not only the already existing frameworks, but also with futureframeworks, then Ivy is for you!Setting up Ivy--------------There are various ways to use Ivy, depending on your preferredenvironment:Installing using pip~~~~~~~~~~~~~~~~~~~~The easiest way to set up Ivy is to install it using pip with thefollowing command:.. code:: bash   pip install ivy-coreor alternatively:.. code:: bash   python3 -m pip install ivy-coreDocker~~~~~~If you prefer to use containers, we also have pre-built Docker imageswith all the supported frameworks and some relevant packages alreadyinstalled, which you can pull from:.. code:: bash   docker pull unifyai/ivy:latestIf you are working on a GPU device, you can pull from:.. code:: bash   docker pull unifyai/ivy:latest-gpuInstalling from source~~~~~~~~~~~~~~~~~~~~~~You can also install Ivy from source if you want to take advantage ofthe latest changes, but we can't ensure everything will work asexpected. :sweat_smile:.. code:: bash   git clone https://github.com/unifyai/ivy.git   cd ivy    pip install --user -e .or alternatively, for the last step:.. code:: bash   python3 -m pip install --user -e .If you want to set up testing and various frameworks it's probably bestto check out the `Contributing - SettingUp &lt;https://unify.ai/docs/ivy/overview/contributing/setting_up.html#setting-up&gt;`__page, where OS-specific and IDE-specific instructions and videotutorials to do so are available!Using Ivy~~~~~~~~~You can find quite a lot more examples in the corresponding sectionbelow, but using Ivy is as simple as:.. code:: python   import ivy   import torch   import jax   ivy.set_backend(&quot;jax&quot;)   x = jax.numpy.array([1, 2, 3])   y = jax.numpy.array([3, 2, 1])   z = ivy.add(x, y)   ivy.set_backend('torch')   x = torch.tensor([1, 2, 3])   y = torch.tensor([3, 2, 1])   z = ivy.add(x, y).. code:: python   import ivy   import torch   import jax   def jax_fn(x):       a = jax.numpy.dot(x, x)       b = jax.numpy.mean(x)       return x * a + b   jax_x = jax.numpy.array([1, 2, 3])   torch_x = torch.tensor([1, 2, 3])   torch_fn = ivy.transpile(jax_fn, source=&quot;jax&quot;, to=&quot;torch&quot;, args=(jax_x,))   ret = torch_fn(torch_x)Documentation-------------The `Ivy Docs page &lt;https://unify.ai/docs/ivy/&gt;`__ holds all therelevant information about Ivy's and it's framework API reference.There, you will find the`Design &lt;https://unify.ai/docs/ivy/overview/design.html&gt;`__ page, whichis a user-focused guide about the architecture and the building blocksof Ivy. Likewise, you can take a look at the `Deepdive &lt;https://unify.ai/docs/ivy/overview/deep_dive.html&gt;`__, which isoriented towards potential contributors of the code base and explainsthe nuances of Ivy in full detail üîéAnother important sections of the docs is`Background &lt;https://unify.ai/docs/ivy/overview/background.html&gt;`__,which contextualises the problem Ivy is trying to solve and the current`MLExplosion &lt;https://unify.ai/docs/ivy/overview/background/ml_explosion.html#ml-explosion&gt;`__,explaining both (1) why is important `to solve thisproblem &lt;https://unify.ai/docs/ivy/overview/background/why_unify.html#why-unify&gt;`__and (2) how we are adhering to existing`standards &lt;https://unify.ai/docs/ivy/overview/background/standardization.html#standardization&gt;`__to make this happen.Lastly, you can also find there the `RelatedWork &lt;https://unify.ai/docs/ivy/overview/related_work.html&gt;`__ section,which paints a clear picture of the role Ivy plays in the ML stack,comparing it to other existing solutions in terms of functionalities andlevel.Examples--------The `Examples page &lt;https://unify.ai/demos/&gt;`__ features a wide range ofdemos and tutorials showcasing the functionalities of Ivy along withmultiple use cases, but feel free to check out some shorterframework-specific examples here ‚¨áÔ∏è      &lt;blockquote&gt;You can use Ivy to get PyTorch code from:.. code:: python   import ivy   import torch   import tensorflow as tf   # Get a pretrained keras model   eff_encoder = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(       include_top=False, weights=&quot;imagenet&quot;, input_shape=(224, 224, 3)   )   # Transpile it into a torch.nn.Module with the corresponding parameters   noise = tf.random.normal(shape=(1, 224, 224, 3))   torch_eff_encoder = ivy.transpile(eff_encoder, to=&quot;torch&quot;, args=(noise,))   # Build a classifier using the transpiled encoder   class Classifier(torch.nn.Module):       def __init__(self, num_classes=20):           super(Classifier, self).__init__()           self.encoder = torch_eff_encoder           self.fc = torch.nn.Linear(1280, num_classes)       def forward(self, x):           x = self.encoder(x)           return self.fc(x)   # Initialize a trainable, customizable, torch.nn.Module   classifier = Classifier()   ret = classifier(torch.rand((1, 244, 244, 3))).. code:: python   import ivy   import jax   import torch   # Get a pretrained haiku model   # https://unify.ai/demos/scripts/deepmind_perceiver_io.py   from deepmind_perceiver_io import key, perceiver_backbone   # Transpile it into a torch.nn.Module with the corresponding parameters   dummy_input = jax.random.uniform(key, shape=(1, 3, 224, 224))   params = perceiver_backbone.init(rng=key, images=dummy_input)   backbone = ivy.transpile(       perceiver_backbone, to=&quot;torch&quot;, params_v=params, kwargs={&quot;images&quot;: dummy_input}   )   # Build a classifier using the transpiled backbone   class PerceiverIOClassifier(torch.nn.Module):       def __init__(self, num_classes=20):           super(PerceiverIOClassifier, self).__init__()           self.backbone = backbone           self.max_pool = torch.nn.MaxPool2d((512, 1))           self.flatten = torch.nn.Flatten()           self.fc = torch.nn.Linear(1024, num_classes)       def forward(self, x):           x = self.backbone(images=x)           x = self.flatten(self.max_pool(x))           return self.fc(x)   # Initialize a trainable, customizable, torch.nn.Module   classifier = PerceiverIOClassifier()   ret = classifier(torch.rand((1, 3, 224, 224))).. code:: python   import ivy   import torch   import os   os.environ[&quot;SM_FRAMEWORK&quot;] = &quot;tf.keras&quot;   import segmentation_models as sm   # transpile sm from tensorflow to torch   torch_sm = ivy.transpile(sm, source=&quot;tensorflow&quot;, to=&quot;torch&quot;)   # get some image-like arrays   output = torch.rand((1, 3, 512, 512))   target = torch.rand((1, 3, 512, 512))   # and use the transpiled version of any function from the library!   out = torch_sm.metrics.iou_score(output, target).. code:: python   import ivy   import rax   import torch   # transpile rax from jax to torch   torch_rax = ivy.transpile(rax, source=&quot;jax&quot;, to=&quot;torch&quot;)   # get some arrays   scores = torch.tensor([2.2, 1.3, 5.4])   labels = torch.tensor([1.0, 0.0, 0.0])   # and use the transpiled version of any function from the library!   out = torch_rax.poly1_softmax_loss(scores, labels).. code:: python   import ivy   import torch   import madmom   # transpile madmon from numpy to torch   torch_madmom = ivy.transpile(madmom, source=&quot;numpy&quot;, to=&quot;torch&quot;)   # get some arrays   freqs = torch.arange(20) * 10   # and use the transpiled version of any function from the library!   out = torch_madmom.audio.filters.hz2midi(freqs).. code:: python   import ivy   import tensorflow as tf   import torch   def loss(predictions, targets):       return tf.sqrt(tf.reduce_mean(tf.square(predictions - targets)))   # transpile any function from tf to torch   torch_loss = ivy.transpile(loss, source=&quot;tensorflow&quot;, to=&quot;torch&quot;)   # get some arrays   p = torch.tensor([3.0, 2.0, 1.0])   t = torch.tensor([0.0, 0.0, 0.0])   # and use the transpiled version!   out = torch_loss(p, t).. code:: python   import ivy   import jax.numpy as jnp   import torch   def loss(predictions, targets):       return jnp.sqrt(jnp.mean((predictions - targets) ** 2))   # transpile any function from jax to torch   torch_loss = ivy.transpile(loss, source=&quot;jax&quot;, to=&quot;torch&quot;)   # get some arrays   p = torch.tensor([3.0, 2.0, 1.0])   t = torch.tensor([0.0, 0.0, 0.0])   # and use the transpiled version!   out = torch_loss(p, t).. code:: python   import ivy   import numpy as np   import torch   def loss(predictions, targets):       return np.sqrt(np.mean((predictions - targets) ** 2))   # transpile any function from numpy to torch   torch_loss = ivy.transpile(loss, source=&quot;numpy&quot;, to=&quot;torch&quot;)   # get some arrays   p = torch.tensor([3.0, 2.0, 1.0])   t = torch.tensor([0.0, 0.0, 0.0])   # and use the transpiled version!   out = torch_loss(p, t)   &lt;blockquote&gt;You can use Ivy to get TensorFlow code from:.. code:: python   import ivy   import torch   import timm   import tensorflow as tf   # Get a pretrained pytorch model   mlp_encoder = timm.create_model(&quot;mixer_b16_224&quot;, pretrained=True, num_classes=0)   # Transpile it into a keras.Model with the corresponding parameters   noise = torch.randn(1, 3, 224, 224)   mlp_encoder = ivy.transpile(mlp_encoder, to=&quot;tensorflow&quot;, args=(noise,))   # Build a classifier using the transpiled encoder   class Classifier(tf.keras.Model):       def __init__(self):           super(Classifier, self).__init__()           self.encoder = mlp_encoder           self.output_dense = tf.keras.layers.Dense(units=1000, activation=&quot;softmax&quot;)       def call(self, x):           x = self.encoder(x)           return self.output_dense(x)   # Transform the classifier and use it as a standard keras.Model   x = tf.random.normal(shape=(1, 3, 224, 224))   model = Classifier()   ret = model(x).. code:: python   import ivy   import jax   import tensorflow as tf   # Get a pretrained haiku model   # https://unify.ai/demos/scripts/deepmind_perceiver_io.py   from deepmind_perceiver_io import key, perceiver_backbone   # Transpile it into a tf.keras.Model with the corresponding parameters   dummy_input = jax.random.uniform(key, shape=(1, 3, 224, 224))   params = perceiver_backbone.init(rng=key, images=dummy_input)   backbone = ivy.transpile(       perceiver_backbone, to=&quot;tensorflow&quot;, params_v=params, args=(dummy_input,)   )   # Build a classifier using the transpiled backbone   class PerceiverIOClassifier(tf.keras.Model):       def __init__(self, num_classes=20):           super(PerceiverIOClassifier, self).__init__()           self.backbone = backbone           self.max_pool = tf.keras.layers.MaxPooling1D(pool_size=512)           self.flatten = tf.keras.layers.Flatten()           self.fc = tf.keras.layers.Dense(num_classes)       def call(self, x):           x = self.backbone(x)           x = self.flatten(self.max_pool(x))           return self.fc(x)   # Initialize a trainable, customizable, tf.keras.Model   x = tf.random.normal(shape=(1, 3, 224, 224))   classifier = PerceiverIOClassifier()   ret = classifier(x).. code:: python   import ivy   import kornia   import requests   import numpy as np   import tensorflow as tf   from PIL import Image   # transpile kornia from torch to tensorflow   tf_kornia = ivy.transpile(kornia, source=&quot;torch&quot;, to=&quot;tensorflow&quot;)   # get an image   url = &quot;http://images.cocodataset.org/train2017/000000000034.jpg&quot;   raw_img = Image.open(requests.get(url, stream=True).raw)   # convert it to the format expected by kornia   img = np.array(raw_img)   img = tf.transpose(tf.constant(img), (2, 0, 1))   img = tf.expand_dims(img, 0) / 255   # and use the transpiled version of any function from the library!   out = tf_kornia.enhance.sharpness(img, 5).. code:: python   import ivy   import rax   import tensorflow as tf   # transpile rax from jax to tensorflow   tf_rax = ivy.transpile(rax, source=&quot;jax&quot;, to=&quot;tensorflow&quot;)   # get some arrays   scores = tf.constant([2.2, 1.3, 5.4])   labels = tf.constant([1.0, 0.0, 0.0])   # and use the transpiled version of any function from the library!   out = tf_rax.poly1_softmax_loss(scores, labels).. code:: python   import ivy   import madmom   import tensorflow as tf   # transpile madmom from numpy to tensorflow   tf_madmom = ivy.transpile(madmom, source=&quot;numpy&quot;, to=&quot;tensorflow&quot;)   # get some arrays   freqs = tf.range(20) * 10   # and use the transpiled version of any function from the library!   out = tf_madmom.audio.filters.hz2midi(freqs).. code:: python   import ivy   import torch   import tensorflow as tf   def loss(predictions, targets):       return torch.sqrt(torch.mean((predictions - targets) ** 2))   # transpile any function from torch to tensorflow   tf_loss = ivy.transpile(loss, source=&quot;torch&quot;, to=&quot;tensorflow&quot;)   # get some arrays   p = tf.constant([3.0, 2.0, 1.0])   t = tf.constant([0.0, 0.0, 0.0])   # and use the transpiled version!   out = tf_loss(p, t).. code:: python   import ivy   import jax.numpy as jnp   import tensorflow as tf   def loss(predictions, targets):       return jnp.sqrt(jnp.mean((predictions - targets) ** 2))   # transpile any function from jax to tensorflow   tf_loss = ivy.transpile(loss, source=&quot;jax&quot;, to=&quot;tensorflow&quot;)   # get some arrays   p = tf.constant([3.0, 2.0, 1.0])   t = tf.constant([0.0, 0.0, 0.0])   # and use the transpiled version!   out = tf_loss(p, t).. code:: python   import ivy   import numpy as np   import tensorflow as tf   def loss(predictions, targets):       return np.sqrt(np.mean((predictions - targets) ** 2))   # transpile any function from numpy to tensorflow   tf_loss = ivy.transpile(loss, source=&quot;numpy&quot;, to=&quot;tensorflow&quot;)   # get some arrays   p = tf.constant([3.0, 2.0, 1.0])   t = tf.constant([0.0, 0.0, 0.0])   # and use the transpiled version!   out = tf_loss(p, t)   &lt;blockquote&gt;You can use Ivy to get JAX code from:.. code:: python   import ivy   import timm   import torch   import jax   import haiku as hk   # Get a pretrained pytorch model   mlp_encoder = timm.create_model(&quot;mixer_b16_224&quot;, pretrained=True, num_classes=0)   # Transpile it into a hk.Module with the corresponding parameters   noise = torch.randn(1, 3, 224, 224)   mlp_encoder = ivy.transpile(mlp_encoder, to=&quot;jax&quot;, args=(noise,))   # Build a classifier using the transpiled encoder   class Classifier(hk.Module):       def __init__(self, num_classes=1000):           super(Classifier, self).__init__()           self.encoder = mlp_encoder()           self.fc = hk.Linear(output_size=num_classes, with_bias=True)       def __call__(self, x):           x = self.encoder(x)           x = self.fc(x)           return x   def _forward_classifier(x):       module = Classifier()       return module(x)   # Transform the classifier and use it as a standard hk.Module   rng_key = jax.random.PRNGKey(42)   x = jax.random.uniform(key=rng_key, shape=(1, 3, 224, 224), dtype=jax.numpy.float32)   forward_classifier = hk.transform(_forward_classifier)   params = forward_classifier.init(rng=rng_key, x=x)   ret = forward_classifier.apply(params, None, x).. code:: python   import ivy   import jax   import haiku as hk   import tensorflow as tf   # Get a pretrained keras model   eff_encoder = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(       include_top=False, weights=&quot;imagenet&quot;, input_shape=(224, 224, 3)   )   # Transpile it into a hk.Module with the corresponding parameters   noise = tf.random.normal(shape=(1, 224, 224, 3))   hk_eff_encoder = ivy.transpile(eff_encoder, to=&quot;jax&quot;, args=(noise,))   # Build a classifier using the transpiled encoder   class Classifier(hk.Module):       def __init__(self, num_classes=1000):           super(Classifier, self).__init__()           self.encoder = hk_eff_encoder()           self.fc = hk.Linear(output_size=num_classes, with_bias=True)       def __call__(self, x):           x = self.encoder(x)           x = self.fc(x)           return x   def _forward_classifier(x):       module = Classifier()       return module(x)   # Transform the classifier and use it as a standard hk.Module   rng_key = jax.random.PRNGKey(42)   dummy_x = jax.random.uniform(key=rng_key, shape=(1, 224, 224, 3))   forward_classifier = hk.transform(_forward_classifier)   params = forward_classifier.init(rng=rng_key, x=dummy_x)   ret = forward_classifier.apply(params, None, dummy_x).. code:: python   import ivy   import kornia   import requests   import jax.numpy as jnp   from PIL import Image   # transpile kornia from torch to jax   jax_kornia = ivy.transpile(kornia, source=&quot;torch&quot;, to=&quot;jax&quot;)   # get an image   url = &quot;http://images.cocodataset.org/train2017/000000000034.jpg&quot;   raw_img = Image.open(requests.get(url, stream=True).raw)   # convert it to the format expected by kornia   img = jnp.transpose(jnp.array(raw_img), (2, 0, 1))   img = jnp.expand_dims(img, 0) / 255   # and use the transpiled version of any function from the library!   out = jax_kornia.enhance.sharpness(img, 5).. code:: python   import ivy   import jax   import os   os.environ[&quot;SM_FRAMEWORK&quot;] = &quot;tf.keras&quot;   import segmentation_models as sm   # transpile sm from tensorflow to jax   jax_sm = ivy.transpile(sm, source=&quot;tensorflow&quot;, to=&quot;jax&quot;)   # get some image-like arrays   key = jax.random.PRNGKey(23)   key1, key2 = jax.random.split(key)   output = jax.random.uniform(key1, (1, 3, 512, 512))   target = jax.random.uniform(key2, (1, 3, 512, 512))   # and use the transpiled version of any function from the library!   out = jax_sm.metrics.iou_score(output, target).. code:: python   import ivy   import madmom   import jax.numpy as jnp   # transpile madmon from numpy to jax   jax_madmom = ivy.transpile(madmom, source=&quot;numpy&quot;, to=&quot;jax&quot;)   # get some arrays   freqs = jnp.arange(20) * 10   # and use the transpiled version of any function from the library!   out = jax_madmom.audio.filters.hz2midi(freqs).. code:: python   import ivy   import torch   import jax.numpy as jnp   def loss(predictions, targets):       return torch.sqrt(torch.mean((predictions - targets) ** 2))   # transpile any function from torch to jax   jax_loss = ivy.transpile(loss, source=&quot;torch&quot;, to=&quot;jax&quot;)   # get some arrays   p = jnp.array([3.0, 2.0, 1.0])   t = jnp.array([0.0, 0.0, 0.0])   # and use the transpiled version!   out = jax_loss(p, t).. code:: python   import ivy   import tensorflow as tf   import jax.numpy as jnp   def loss(predictions, targets):       return tf.sqrt(tf.reduce_mean(tf.square(predictions - targets)))   # transpile any function from tf to jax   jax_loss = ivy.transpile(loss, source=&quot;tensorflow&quot;, to=&quot;jax&quot;)   # get some arrays   p = jnp.array([3.0, 2.0, 1.0])   t = jnp.array([0.0, 0.0, 0.0])   # and use the transpiled version!   out = jax_loss(p, t).. code:: python   import ivy   import numpy as np   import jax   import jax.numpy as jnp   jax.config.update('jax_enable_x64', True)   def loss(predictions, targets):       return np.sqrt(np.mean((predictions - targets) ** 2))   # transpile any function from numpy to jax   jax_loss = ivy.transpile(loss, source=&quot;numpy&quot;, to=&quot;jax&quot;)   # get some arrays   p = jnp.array([3.0, 2.0, 1.0])   t = jnp.array([0.0, 0.0, 0.0])   # and use the transpiled version!   out = jax_loss(p, t)   &lt;blockquote&gt;You can use Ivy to get NumPy code from:.. code:: python   import ivy   import kornia   import requests   import numpy as np   from PIL import Image   # transpile kornia from torch to np   np_kornia = ivy.transpile(kornia, source=&quot;torch&quot;, to=&quot;numpy&quot;)   # get an image   url = &quot;http://images.cocodataset.org/train2017/000000000034.jpg&quot;   raw_img = Image.open(requests.get(url, stream=True).raw)   # convert it to the format expected by kornia   img = np.transpose(np.array(raw_img), (2, 0, 1))   img = np.expand_dims(img, 0) / 255   # and use the transpiled version of any function from the library!   out = np_kornia.enhance.sharpness(img, 5).. code:: python   import ivy   import numpy as np   import os   os.environ[&quot;SM_FRAMEWORK&quot;] = &quot;tf.keras&quot;   import segmentation_models as sm   # transpile sm from tensorflow to numpy   np_sm = ivy.transpile(sm, source=&quot;tensorflow&quot;, to=&quot;numpy&quot;)   # get some image-like arrays   output = np.random.rand(1, 3, 512, 512).astype(dtype=np.float32)   target = np.random.rand(1, 3, 512, 512).astype(dtype=np.float32)   # and use the transpiled version of any function from the library!   out = np_sm.metrics.iou_score(output, target).. code:: python   import ivy   import rax   import numpy as np   # transpile rax from jax to numpy   np_rax = ivy.transpile(rax, source=&quot;jax&quot;, to=&quot;numpy&quot;)   # get some arrays   scores = np.array([2.2, 1.3, 5.4])   labels = np.array([1.0, 0.0, 0.0])   # and use the transpiled version of any function from the library!   out = np_rax.poly1_softmax_loss(scores, labels).. code:: python   import ivy   import torch   import numpy as np   def loss(predictions, targets):       return torch.sqrt(torch.mean((predictions - targets) ** 2))   # transpile any function from torch to numpy   np_loss = ivy.transpile(loss, source=&quot;torch&quot;, to=&quot;numpy&quot;)   # get some arrays   p = np.array([3.0, 2.0, 1.0])   t = np.array([0.0, 0.0, 0.0])   # and use the transpiled version!   out = np_loss(p, t).. code:: python   import ivy   import tensorflow as tf   import numpy as np   def loss(predictions, targets):       return tf.sqrt(tf.reduce_mean(tf.square(predictions - targets)))   # transpile any function from tf to numpy   np_loss = ivy.transpile(loss, source=&quot;tensorflow&quot;, to=&quot;numpy&quot;)   # get some arrays   p = np.array([3.0, 2.0, 1.0])   t = np.array([0.0, 0.0, 0.0])   # and use the transpiled version!   out = np_loss(p, t).. code:: python   import ivy   import jax.numpy as jnp   import numpy as np   def loss(predictions, targets):       return jnp.sqrt(jnp.mean((predictions - targets) ** 2))   # transpile any function from jax to numpy   np_loss = ivy.transpile(loss, source=&quot;jax&quot;, to=&quot;numpy&quot;)   # get some arrays   p = np.array([3.0, 2.0, 1.0])   t = np.array([0.0, 0.0, 0.0])   # and use the transpiled version!   out = np_loss(p, t)Or you can use Ivy as a framework, breaking yourself (and your code)free from deciding which community to support, allowing anyone to runyour code in their framework of choice!.. code:: python   import ivy   # a simple image classification model   class IvyNet(ivy.Module):       def __init__(           self,           h_w=(32, 32),           input_channels=3,           output_channels=512,           num_classes=2,           data_format=&quot;NCHW&quot;,           device=&quot;cpu&quot;,       ):           self.h_w = h_w           self.input_channels = input_channels           self.output_channels = output_channels           self.num_classes = num_classes           self.data_format = data_format           self.device = device           super().__init__()       def _build(self, *args, **kwargs):           self.extractor = ivy.Sequential(               ivy.Conv2D(self.input_channels, 6, [5, 5], 1, &quot;SAME&quot;, data_format=self.data_format),               ivy.GELU(),               ivy.Conv2D(6, 16, [5, 5], 1, &quot;SAME&quot;, data_format=self.data_format),               ivy.GELU(),               ivy.Conv2D(16, self.output_channels, [5, 5], 1, &quot;SAME&quot;, data_format=self.data_format),               ivy.GELU(),           )           self.classifier = ivy.Sequential(               # since padding is &quot;SAME&quot;, this would be image_height x image_width x output_channels               ivy.Linear(self.h_w[0] * self.h_w[1] * self.output_channels, 512),               ivy.GELU(),               ivy.Linear(512, self.num_classes),           )       def _forward(self, x):           x = self.extractor(x)           # flatten all dims except batch dim           x = ivy.flatten(x, start_dim=1, end_dim=-1)           logits = self.classifier(x)           probs = ivy.softmax(logits)           return logits, probsAfter building your model in Ivy, you can set your favourite frameworkas the backend to use its operations under the hood!.. code:: python   ivy.set_backend(&quot;torch&quot;)   model = IvyNet()   x = torch.randn(1, 3, 32, 32)   logits, probs = model(x).. code:: python   ivy.set_backend(&quot;tensorflow&quot;)   model = IvyNet()   x = tf.random.uniform(shape=(1, 3, 32, 32))   logits, probs = model(x).. code:: python   ivy.set_backend(&quot;jax&quot;)   model = IvyNet()   x = jax.random.uniform(key, shape=(1, 3, 32, 32))   logits, probs = model(x).. code:: python   ivy.set_backend(&quot;numpy&quot;)   model = IvyNet()   x = np.random.uniform(size=(1, 3, 32, 32))   logits, probs = model(x)Last but not least, we can also build the training pipeline in pure ivy‚¨áÔ∏è.. code:: python   # helper function for loading the dataset in batches   def generate_batches(images, classes, dataset_size, batch_size=32):       targets = {k: v for v, k in enumerate(np.unique(classes))}       y_train = [targets[classes[i]] for i in range(len(classes))]       if batch_size &gt; dataset_size:           raise ivy.utils.exceptions.IvyError(&quot;Use a smaller batch size&quot;)       for idx in range(0, dataset_size, batch_size):           yield ivy.stack(images[idx : min(idx + batch_size, dataset_size)]), ivy.array(               y_train[idx : min(idx + batch_size, dataset_size)]           )   # helper function to get the number of current predictions   def num_correct(preds, labels):       return (preds.argmax() == labels).sum().to_numpy().item()   # define a loss function   def loss_fn(params):       v, model, x, y = params       y_pred, probs = model(x)       return ivy.cross_entropy(y, probs), probs.. code:: python   # train the model on gpu if it's available   device = &quot;cuda:0&quot; if ivy.gpu_is_available() else &quot;cpu&quot;   model = IvyNet(       h_w=(28, 28),       input_channels=1,       output_channels=120,       num_classes=num_classes,       device=device,   )   model_name = type(model).__name__.lower()   # training hyperparams   optimizer= ivy.Adam(1e-4)   batch_size = 64    num_epochs = 20   num_classes = 10   # training loop   def train(images, classes, epochs, model, device, num_classes=10, batch_size=32):       # training metrics       epoch_loss = 0.0       running_loss = 0.0       fields = [&quot;epoch&quot;, &quot;epoch_loss&quot;, &quot;training_accuracy&quot;]       metrics = []       dataset_size = len(images)       for epoch in range(epochs):           train_loss, train_correct = 0, 0           train_loop = tqdm(               generate_batches(images, classes, len(images), batch_size=batch_size),               total=dataset_size // batch_size,               position=0,               leave=True,           )           for xbatch, ybatch in train_loop:               if device != &quot;cpu&quot;:                   xbatch, ybatch = xbatch.to_device(&quot;gpu:0&quot;), ybatch.to_device(&quot;gpu:0&quot;)               # since the cross entropy function expects the target classes to be in one-hot encoded format               ybatch_encoded = ivy.one_hot(ybatch, num_classes)               # update model params               loss_probs, grads = ivy.execute_with_gradients(                   loss_fn,                   (model.v, model, xbatch, ybatch_encoded),                   ret_grad_idxs=[[0]],                   xs_grad_idxs=[[0]],               )               model.v = optimizer.step(model.v, grads[&quot;0&quot;])               batch_loss = ivy.to_numpy(loss_probs[0]).mean().item()  # batch mean loss               epoch_loss += batch_loss * xbatch.shape[0]               train_correct += num_correct(loss_probs[1], ybatch)               train_loop.set_description(f&quot;Epoch [{epoch + 1:2d}/{epochs}]&quot;)               train_loop.set_postfix(                   running_loss=batch_loss,                   accuracy_percentage=(train_correct / dataset_size) * 100,               )           epoch_loss = epoch_loss / dataset_size           training_accuracy = train_correct / dataset_size           metrics.append([epoch, epoch_loss, training_accuracy])           train_loop.write(               f&quot;\nAverage training loss: {epoch_loss:.6f}, Train Correct: {train_correct}&quot;,               end=&quot;\n&quot;,           )       # write metrics for plotting       with open(f&quot;/{model_name}_train_summary.csv&quot;, &quot;w&quot;) as f:           f = csv.writer(f)           f.writerow(fields)           f.writerows(metrics)   # assuming the dataset(images and classes) are already prepared in a folder         train(images, classes, num_epochs, model, device, num_classes = num_classes, batch_size = batch_size)| Contributing------------We believe that everyone can contribute and make a difference. Whetherit's writing code üíª, fixing bugs üêõ, or simply sharing feedback üí¨,your contributions are definitely welcome and appreciated üôåCheck out all of our open tasks, and find out more info in our`Contributingguide &lt;https://unify.ai/docs/ivy/overview/contributing.html&gt;`__ in thedocs!Join our amazing community as a code contributor, and help accelerateour journey to unify all ML frameworks!| Community---------In order to achieve the ambitious goal of unifying AI we definitely needas many hands as possible on it! Whether you are a seasoned developer orjust starting out, you'll find a place here! Join the Ivy community inour `Discord &lt;https://discord.gg/sXyFF8tDtm&gt;`__ üëæ server, which is theperfect place to ask questions, share ideas, and get help from bothfellow developers and the Ivy Team directly!Also! Feel free to follow us in`Twitter &lt;https://twitter.com/letsunifyai&gt;`__ üê¶ as well, we use it toshare updates, sneak peeks, and all sorts of relevant news, certainly agreat way to stay in the loop üòÑCan't wait to see you there!Citation--------If you use Ivy for your work, please don't forget to give proper creditby including the accompanying`paper &lt;https://arxiv.org/abs/2102.02886&gt;`__ üìÑ in your references. It'sa small way to show appreciation and help to continue to support thisand other open source projects üôå::   @article{lenton2021ivy,     title={Ivy: Templated deep learning for inter-framework portability},     author={Lenton, Daniel and Pardo, Fabio and Falck, Fabian and James, Stephen and Clark, Ronald},     journal={arXiv preprint arXiv:2102.02886},     year={2021}   }</longdescription>
</pkgmetadata>