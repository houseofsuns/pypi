<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<maintainer type="person">
		<email>gentoo@houseofsuns.org</email>
		<name>Markus Walter</name>
	</maintainer>
	<longdescription>&lt;p align=&quot;center&quot;&gt;  &lt;img src=&quot;https://microsoft.github.io/aug-models/embgam_gif.gif&quot; width=&quot;18%&quot;&gt; &lt;img align=&quot;center&quot; width=40% src=&quot;https://csinva.io/imodelsX/imodelsx_logo.svg?sanitize=True&amp;kill_cache=1&quot;&gt; &lt;/img&gt;&lt;img src=&quot;https://microsoft.github.io/aug-models/embgam_gif.gif&quot; width=&quot;18%&quot;&gt;&lt;/p&gt;&lt;p align=&quot;center&quot;&gt;Library to explain &lt;i&gt;a dataset&lt;/i&gt; in natural language. &lt;/p&gt;&lt;p align=&quot;center&quot;&gt;  &lt;a href=&quot;https://github.com/csinva/imodelsX/tree/master/demo_notebooks&quot;&gt;ğŸ“– demo notebooks&lt;/a&gt;&lt;/p&gt;&lt;p align=&quot;center&quot;&gt;  &lt;img src=&quot;https://img.shields.io/badge/license-mit-blue.svg&quot;&gt;  &lt;img src=&quot;https://img.shields.io/badge/python-3.9+-blue&quot;&gt;  &lt;img src=&quot;https://img.shields.io/pypi/v/imodelsx?color=green&quot;&gt;  &lt;/p&gt;  | Model                       | Reference                                                    | Output  | Description                                                  || :-------------------------- | ------------------------------------------------------------ | ------- | ------------------------------------------------------------ || iPrompt            | [ğŸ“–](https://github.com/csinva/imodelsX/blob/master/demo_notebooks/iprompt.ipynb), [ğŸ—‚ï¸](http://csinva.io/imodelsX/iprompt/api.html#imodelsx.iprompt.api.explain_dataset_iprompt), [ğŸ”—](https://github.com/csinva/interpretable-autoprompting), [ğŸ“„](https://arxiv.org/abs/2210.01848) | Explanation | Generates a prompt that&lt;br/&gt;explains patterns in data (*Official*) || D3            | [ğŸ“–](https://github.com/csinva/imodelsX/blob/master/demo_notebooks/d3.ipynb), [ğŸ—‚ï¸](http://csinva.io/imodelsX/d3/d3.html#imodelsx.d3.d3.explain_dataset_d3), [ğŸ”—](https://github.com/ruiqi-zhong/DescribeDistributionalDifferences), [ğŸ“„](https://arxiv.org/abs/2201.12323) | Explanation | Explain the difference between two distributions || AutoPrompt            |  ã…¤ã…¤[ğŸ—‚ï¸](), [ğŸ”—](https://github.com/ucinlp/autoprompt), [ğŸ“„](https://arxiv.org/abs/2010.15980) | Explanation | Find a natural-language prompt&lt;br/&gt;using input-gradients (âŒ› In progress)|| Aug-GAM            | [ğŸ“–](https://github.com/csinva/imodelsX/blob/master/demo_notebooks/augmodels.ipynb), [ğŸ—‚ï¸](https://csinva.io/imodelsX/auggam/auggam.html), [ğŸ”—](https://github.com/microsoft/aug-models), [ğŸ“„](https://arxiv.org/abs/2209.11799) | Linear model | Fit better linear model using an LLM&lt;br/&gt;to extract embeddings (*Official*) || Aug-Tree            | [ğŸ“–](https://github.com/csinva/imodelsX/blob/master/demo_notebooks/augmodels.ipynb), [ğŸ—‚ï¸](https://csinva.io/imodelsX/augtree/augtree.html), [ğŸ”—](https://github.com/microsoft/aug-models), [ğŸ“„](https://arxiv.org/abs/2209.11799) | Decision tree | Fit better decision tree using an LLM&lt;br/&gt;to expand features (âŒ› In progress) || SASC            |  ã…¤ã…¤[ğŸ—‚ï¸](https://csinva.io/imodelsX/sasc/api.html), [ğŸ”—](https://github.com/microsoft/automated-explanations) | Explanation | Explain a black-box text module&lt;br/&gt;using an LLM (*Official*) || Linear Finetune  | [ğŸ“–](https://github.com/csinva/imodelsX/blob/master/demo_notebooks/linearfinetune.ipynb), [ğŸ—‚ï¸](https://csinva.io/imodelsX/linear_finetune.html) | Black-box model | Finetune a single linear layer&lt;br/&gt;on top of LLM embeddings |&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/csinva/imodelsX/tree/master/demo_notebooks&quot;&gt;ğŸ“–&lt;/a&gt;Demo notebooks &amp;emsp; &lt;a href=&quot;https://csinva.io/imodelsX/&quot;&gt;ğŸ—‚ï¸&lt;/a&gt; Doc &amp;emsp; ğŸ”— Reference code &amp;emsp; ğŸ“„ Research paper&lt;/br&gt;âŒ› We plan to support other interpretable algorithms like &lt;a href=&quot;https://arxiv.org/abs/2205.12548&quot;&gt;RLPrompt&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/abs/2007.04612&quot;&gt;CBMs&lt;/a&gt;, and &lt;a href=&quot;https://arxiv.org/abs/2004.00221&quot;&gt;NBDT&lt;/a&gt;. If you want to contribute an algorithm, feel free to open a PR ğŸ˜„&lt;/p&gt;# Quickstart**Installation**: `pip install imodelsx` (or, for more control, clone and install from source)**Demos**: see the [demo notebooks](https://github.com/csinva/imodelsX/tree/master/demo_notebooks)### iPrompt```pythonfrom imodelsx import explain_dataset_iprompt, get_add_two_numbers_dataset# get a simple dataset of adding two numbersinput_strings, output_strings = get_add_two_numbers_dataset(num_examples=100)for i in range(5):    print(repr(input_strings[i]), repr(output_strings[i]))# explain the relationship between the inputs and outputs# with a natural-language prompt stringprompts, metadata = explain_dataset_iprompt(    input_strings=input_strings,    output_strings=output_strings,    checkpoint='EleutherAI/gpt-j-6B', # which language model to use    num_learned_tokens=3, # how long of a prompt to learn    n_shots=3, # shots per example    n_epochs=15, # how many epochs to search    verbose=0, # how much to print    llm_float16=True, # whether to load the model in float_16)--------prompts is a list of found natural-language prompt strings```### D3 (DescribeDistributionalDifferences)```pythonimport imodelsxhypotheses, hypothesis_scores = imodelsx.explain_dataset_d3(    pos=positive_samples, # List[str] of positive examples    neg=negative_samples, # another List[str]    num_steps=100,    num_folds=2,    batch_size=64,)```### Aug-modelsUse these just a like a scikit-learn model. During training, they fit better features via LLMs, but at test-time they are extremely fast and completely transparent.```pythonfrom imodelsx import AugGAMClassifier, AugTreeClassifier, AugGAMRegressor, AugTreeRegressorimport datasetsimport numpy as np# set up datadset = datasets.load_dataset('rotten_tomatoes')['train']dset = dset.select(np.random.choice(len(dset), size=300, replace=False))dset_val = datasets.load_dataset('rotten_tomatoes')['validation']dset_val = dset_val.select(np.random.choice(len(dset_val), size=300, replace=False))# fit modelm = AugGAMClassifier(    checkpoint='textattack/distilbert-base-uncased-rotten-tomatoes',    ngrams=2, # use bigrams)m.fit(dset['text'], dset['label'])# predictpreds = m.predict(dset_val['text'])print('acc_val', np.mean(preds == dset_val['label']))# interpretprint('Total ngram coefficients: ', len(m.coefs_dict_))print('Most positive ngrams')for k, v in sorted(m.coefs_dict_.items(), key=lambda item: item[1], reverse=True)[:8]:    print('\t', k, round(v, 2))print('Most negative ngrams')for k, v in sorted(m.coefs_dict_.items(), key=lambda item: item[1])[:8]:    print('\t', k, round(v, 2))```### Linear finetuneAn easy-to-fit baseline that follows the same API.```python# fit a simple one-layer finetunem = LinearFinetuneClassifier(    checkpoint='distilbert-base-uncased',)m.fit(dset['text'], dset['label'])preds = m.predict(dset_val['text'])acc = (preds == dset_val['label']).mean()print('validation acc', acc)```### SASCHere, we explain a *module* rather than a dataset```python# a toy module that responds to the length of a stringmod = lambda str_list: np.array([len(s) for s in str_list])# a toy dataset where the longest strings are animalstext_str_list = [&quot;red&quot;, &quot;blue&quot;, &quot;x&quot;, &quot;1&quot;, &quot;2&quot;, &quot;hippopotamus&quot;, &quot;elephant&quot;, &quot;rhinoceros&quot;]explanation_dict = explain_module_sasc(    text_str_list,    mod,    ngrams=1,)```# Related work- imodels package (JOSS 2021 [github](https://github.com/csinva/imodels)) - interpretable ML package for concise, transparent, and accurate predictive modeling (sklearn-compatible).- Adaptive wavelet distillation (NeurIPS 2021 [pdf](https://arxiv.org/abs/2107.09145), [github](https://github.com/Yu-Group/adaptive-wavelets)) - distilling a neural network into a concise wavelet model- Transformation importance (ICLR 2020 workshop [pdf](https://arxiv.org/abs/2003.01926), [github](https://github.com/csinva/transformation-importance)) - using simple reparameterizations, allows for calculating disentangled importances to transformations of the input (e.g. assigning importances to different frequencies)- Hierarchical interpretations (ICLR 2019 [pdf](https://openreview.net/pdf?id=SkEqro0ctQ), [github](https://github.com/csinva/hierarchical-dnn-interpretations)) - extends CD to CNNs / arbitrary DNNs, and aggregates explanations into a hierarchy- Interpretation regularization (ICML 2020 [pdf](https://arxiv.org/abs/1909.13584), [github](https://github.com/laura-rieger/deep-explanation-penalization)) - penalizes CD / ACD scores during training to make models generalize better- PDR interpretability framework (PNAS 2019 [pdf](https://arxiv.org/abs/1901.04592)) - an overarching framewwork for guiding and framing interpretable machine learning</longdescription>
</pkgmetadata>